/home/yandex/AMNLP2021/shlomotannor/anaconda3/envs/amnlp/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: "sox" backend is being deprecated. The default backend will be changed to "sox_io" backend in 0.8.0 and "sox" backend will be removed in 0.9.0. Please migrate to "sox_io" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.
  '"sox" backend is being deprecated. '
Using custom data configuration default-bffd5994dba40be2
Reusing dataset sst (/home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Using custom data configuration default-e50d0bcc90555ae2
0 tables [00:00, ? tables/s]                              0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.72ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.71ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-35bfd9f04e6658c3.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-04edea8e5deaac23.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.66ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.66ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-80dea3fb3755f005.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1f098d744ad3e451.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.99ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.98ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-523194a38c7f88f6.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-487f6c90d30222c9.arrow
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running training *****
  Num examples = 627
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 790
  0%|          | 0/790 [00:00<?, ?it/s]  0%|          | 1/790 [00:17<3:49:24, 17.45s/it]  0%|          | 2/790 [00:17<1:36:54,  7.38s/it]  0%|          | 3/790 [00:18<54:24,  4.15s/it]    1%|          | 4/790 [00:18<34:27,  2.63s/it]  1%|          | 5/790 [00:18<23:26,  1.79s/it]  1%|          | 6/790 [00:18<16:48,  1.29s/it]  1%|          | 7/790 [00:19<12:35,  1.04it/s]  1%|          | 8/790 [00:19<09:50,  1.32it/s]  1%|          | 9/790 [00:19<07:59,  1.63it/s]  1%|â–         | 10/790 [00:20<06:44,  1.93it/s]  1%|â–         | 11/790 [00:20<05:52,  2.21it/s]  2%|â–         | 12/790 [00:20<05:17,  2.45it/s]  2%|â–         | 13/790 [00:21<04:53,  2.65it/s]  2%|â–         | 14/790 [00:21<04:35,  2.81it/s]  2%|â–         | 15/790 [00:21<04:24,  2.94it/s]  2%|â–         | 16/790 [00:22<04:15,  3.03it/s]  2%|â–         | 17/790 [00:22<04:09,  3.10it/s]  2%|â–         | 18/790 [00:22<04:05,  3.15it/s]  2%|â–         | 19/790 [00:22<04:02,  3.18it/s]  3%|â–Ž         | 20/790 [00:23<04:00,  3.21it/s]  3%|â–Ž         | 21/790 [00:23<03:58,  3.23it/s]  3%|â–Ž         | 22/790 [00:23<03:57,  3.23it/s]  3%|â–Ž         | 23/790 [00:24<03:57,  3.24it/s]  3%|â–Ž         | 24/790 [00:24<03:55,  3.25it/s]  3%|â–Ž         | 25/790 [00:24<03:54,  3.26it/s]  3%|â–Ž         | 26/790 [00:25<03:54,  3.26it/s]  3%|â–Ž         | 27/790 [00:25<03:53,  3.26it/s]  4%|â–Ž         | 28/790 [00:25<03:53,  3.26it/s]  4%|â–Ž         | 29/790 [00:26<03:53,  3.26it/s]  4%|â–         | 30/790 [00:26<03:52,  3.26it/s]  4%|â–         | 31/790 [00:26<03:52,  3.27it/s]  4%|â–         | 32/790 [00:26<03:52,  3.26it/s]  4%|â–         | 33/790 [00:27<03:51,  3.26it/s]  4%|â–         | 34/790 [00:27<03:51,  3.26it/s]  4%|â–         | 35/790 [00:27<03:51,  3.26it/s]  5%|â–         | 36/790 [00:28<03:50,  3.27it/s]  5%|â–         | 37/790 [00:28<03:50,  3.27it/s]  5%|â–         | 38/790 [00:28<03:50,  3.26it/s]  5%|â–         | 39/790 [00:29<03:49,  3.27it/s]  5%|â–Œ         | 40/790 [00:29<03:49,  3.27it/s]  5%|â–Œ         | 41/790 [00:29<03:49,  3.27it/s]  5%|â–Œ         | 42/790 [00:30<03:48,  3.27it/s]  5%|â–Œ         | 43/790 [00:30<03:54,  3.18it/s]  6%|â–Œ         | 44/790 [00:30<03:52,  3.20it/s]  6%|â–Œ         | 45/790 [00:30<03:51,  3.22it/s]  6%|â–Œ         | 46/790 [00:31<03:50,  3.22it/s]  6%|â–Œ         | 47/790 [00:31<03:49,  3.23it/s]  6%|â–Œ         | 48/790 [00:31<03:49,  3.24it/s]  6%|â–Œ         | 49/790 [00:32<03:48,  3.24it/s]  6%|â–‹         | 50/790 [00:32<03:47,  3.25it/s]  6%|â–‹         | 51/790 [00:32<03:47,  3.25it/s]  7%|â–‹         | 52/790 [00:33<03:46,  3.25it/s]  7%|â–‹         | 53/790 [00:33<03:46,  3.25it/s]  7%|â–‹         | 54/790 [00:33<03:46,  3.25it/s]  7%|â–‹         | 55/790 [00:34<03:45,  3.25it/s]  7%|â–‹         | 56/790 [00:34<03:45,  3.26it/s]  7%|â–‹         | 57/790 [00:34<03:45,  3.26it/s]  7%|â–‹         | 58/790 [00:34<03:44,  3.26it/s]  7%|â–‹         | 59/790 [00:35<03:49,  3.19it/s]  8%|â–Š         | 60/790 [00:35<03:47,  3.21it/s]  8%|â–Š         | 61/790 [00:35<03:46,  3.21it/s]  8%|â–Š         | 62/790 [00:36<03:45,  3.23it/s]  8%|â–Š         | 63/790 [00:36<03:44,  3.23it/s]  8%|â–Š         | 64/790 [00:36<03:44,  3.24it/s]  8%|â–Š         | 65/790 [00:37<03:43,  3.24it/s]  8%|â–Š         | 66/790 [00:37<03:43,  3.24it/s]  8%|â–Š         | 67/790 [00:37<03:42,  3.25it/s]  9%|â–Š         | 68/790 [00:38<03:42,  3.25it/s]  9%|â–Š         | 69/790 [00:38<03:41,  3.25it/s]  9%|â–‰         | 70/790 [00:38<03:41,  3.25it/s]  9%|â–‰         | 71/790 [00:38<03:41,  3.25it/s]  9%|â–‰         | 72/790 [00:39<03:40,  3.25it/s]  9%|â–‰         | 73/790 [00:39<03:40,  3.25it/s]  9%|â–‰         | 74/790 [00:39<03:40,  3.25it/s]  9%|â–‰         | 75/790 [00:40<03:40,  3.25it/s] 10%|â–‰         | 76/790 [00:40<03:39,  3.25it/s] 10%|â–‰         | 77/790 [00:40<03:39,  3.25it/s] 10%|â–‰         | 78/790 [00:41<03:39,  3.25it/s] 10%|â–ˆ         | 79/790 [00:41<03:05,  3.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 18.37it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 11.95it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 10.59it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.31it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.23it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.16it/s][A                                                
                                               [A 10%|â–ˆ         | 79/790 [00:42<03:05,  3.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.16it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-79
Configuration saved in sst_model/checkpoint-79/config.json
Model weights saved in sst_model/checkpoint-79/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-32] due to args.save_total_limit
 10%|â–ˆ         | 80/790 [01:19<2:17:31, 11.62s/it] 10%|â–ˆ         | 81/790 [01:19<1:37:13,  8.23s/it] 10%|â–ˆ         | 82/790 [01:20<1:09:02,  5.85s/it] 11%|â–ˆ         | 83/790 [01:20<49:20,  4.19s/it]   11%|â–ˆ         | 84/790 [01:20<35:34,  3.02s/it] 11%|â–ˆ         | 85/790 [01:20<25:58,  2.21s/it] 11%|â–ˆ         | 86/790 [01:21<19:13,  1.64s/it] 11%|â–ˆ         | 87/790 [01:21<14:31,  1.24s/it] 11%|â–ˆ         | 88/790 [01:21<11:13,  1.04it/s] 11%|â–ˆâ–        | 89/790 [01:22<08:55,  1.31it/s] 11%|â–ˆâ–        | 90/790 [01:22<07:19,  1.59it/s] 12%|â–ˆâ–        | 91/790 [01:22<06:11,  1.88it/s] 12%|â–ˆâ–        | 92/790 [01:23<05:23,  2.16it/s] 12%|â–ˆâ–        | 93/790 [01:23<04:50,  2.40it/s] 12%|â–ˆâ–        | 94/790 [01:23<04:27,  2.60it/s] 12%|â–ˆâ–        | 95/790 [01:24<04:11,  2.77it/s] 12%|â–ˆâ–        | 96/790 [01:24<03:59,  2.90it/s] 12%|â–ˆâ–        | 97/790 [01:24<03:51,  2.99it/s] 12%|â–ˆâ–        | 98/790 [01:24<03:45,  3.07it/s] 13%|â–ˆâ–Ž        | 99/790 [01:25<03:41,  3.12it/s] 13%|â–ˆâ–Ž        | 100/790 [01:25<03:38,  3.15it/s] 13%|â–ˆâ–Ž        | 101/790 [01:25<03:36,  3.18it/s] 13%|â–ˆâ–Ž        | 102/790 [01:26<03:34,  3.20it/s] 13%|â–ˆâ–Ž        | 103/790 [01:26<03:33,  3.21it/s] 13%|â–ˆâ–Ž        | 104/790 [01:26<03:32,  3.22it/s] 13%|â–ˆâ–Ž        | 105/790 [01:27<03:32,  3.23it/s] 13%|â–ˆâ–Ž        | 106/790 [01:27<03:31,  3.24it/s] 14%|â–ˆâ–Ž        | 107/790 [01:27<03:30,  3.24it/s] 14%|â–ˆâ–Ž        | 108/790 [01:28<03:30,  3.24it/s] 14%|â–ˆâ–        | 109/790 [01:28<03:30,  3.24it/s] 14%|â–ˆâ–        | 110/790 [01:28<03:30,  3.23it/s] 14%|â–ˆâ–        | 111/790 [01:28<03:29,  3.24it/s] 14%|â–ˆâ–        | 112/790 [01:29<03:28,  3.25it/s] 14%|â–ˆâ–        | 113/790 [01:29<03:29,  3.23it/s] 14%|â–ˆâ–        | 114/790 [01:29<03:29,  3.23it/s] 15%|â–ˆâ–        | 115/790 [01:30<03:28,  3.23it/s] 15%|â–ˆâ–        | 116/790 [01:30<03:28,  3.23it/s] 15%|â–ˆâ–        | 117/790 [01:30<03:30,  3.20it/s] 15%|â–ˆâ–        | 118/790 [01:31<03:29,  3.21it/s] 15%|â–ˆâ–Œ        | 119/790 [01:31<03:28,  3.22it/s] 15%|â–ˆâ–Œ        | 120/790 [01:31<03:27,  3.23it/s] 15%|â–ˆâ–Œ        | 121/790 [01:32<03:26,  3.24it/s] 15%|â–ˆâ–Œ        | 122/790 [01:32<03:26,  3.24it/s] 16%|â–ˆâ–Œ        | 123/790 [01:32<03:26,  3.23it/s] 16%|â–ˆâ–Œ        | 124/790 [01:32<03:28,  3.19it/s] 16%|â–ˆâ–Œ        | 125/790 [01:33<03:28,  3.18it/s] 16%|â–ˆâ–Œ        | 126/790 [01:33<03:27,  3.20it/s] 16%|â–ˆâ–Œ        | 127/790 [01:33<03:26,  3.20it/s] 16%|â–ˆâ–Œ        | 128/790 [01:34<03:25,  3.22it/s] 16%|â–ˆâ–‹        | 129/790 [01:34<03:24,  3.23it/s] 16%|â–ˆâ–‹        | 130/790 [01:34<03:24,  3.23it/s] 17%|â–ˆâ–‹        | 131/790 [01:35<03:25,  3.21it/s] 17%|â–ˆâ–‹        | 132/790 [01:35<03:25,  3.20it/s] 17%|â–ˆâ–‹        | 133/790 [01:35<03:24,  3.22it/s] 17%|â–ˆâ–‹        | 134/790 [01:36<03:23,  3.22it/s] 17%|â–ˆâ–‹        | 135/790 [01:36<03:22,  3.23it/s] 17%|â–ˆâ–‹        | 136/790 [01:36<03:23,  3.22it/s] 17%|â–ˆâ–‹        | 137/790 [01:37<03:22,  3.23it/s] 17%|â–ˆâ–‹        | 138/790 [01:37<03:21,  3.23it/s] 18%|â–ˆâ–Š        | 139/790 [01:37<03:21,  3.23it/s] 18%|â–ˆâ–Š        | 140/790 [01:37<03:21,  3.23it/s] 18%|â–ˆâ–Š        | 141/790 [01:38<03:20,  3.23it/s] 18%|â–ˆâ–Š        | 142/790 [01:38<03:20,  3.23it/s] 18%|â–ˆâ–Š        | 143/790 [01:38<03:19,  3.24it/s] 18%|â–ˆâ–Š        | 144/790 [01:39<03:19,  3.24it/s] 18%|â–ˆâ–Š        | 145/790 [01:39<03:20,  3.22it/s] 18%|â–ˆâ–Š        | 146/790 [01:39<03:19,  3.23it/s] 19%|â–ˆâ–Š        | 147/790 [01:40<03:19,  3.23it/s] 19%|â–ˆâ–Š        | 148/790 [01:40<03:18,  3.23it/s] 19%|â–ˆâ–‰        | 149/790 [01:40<03:18,  3.23it/s] 19%|â–ˆâ–‰        | 150/790 [01:41<03:18,  3.23it/s] 19%|â–ˆâ–‰        | 151/790 [01:41<03:17,  3.23it/s] 19%|â–ˆâ–‰        | 152/790 [01:41<03:17,  3.23it/s] 19%|â–ˆâ–‰        | 153/790 [01:41<03:17,  3.23it/s] 19%|â–ˆâ–‰        | 154/790 [01:42<03:18,  3.21it/s] 20%|â–ˆâ–‰        | 155/790 [01:42<03:18,  3.21it/s] 20%|â–ˆâ–‰        | 156/790 [01:42<03:17,  3.21it/s] 20%|â–ˆâ–‰        | 157/790 [01:43<03:16,  3.22it/s] 20%|â–ˆâ–ˆ        | 158/790 [01:43<02:46,  3.81it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 11.93it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.06it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.64it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.41it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.17it/s][A                                                 
                                               [A 20%|â–ˆâ–ˆ        | 158/790 [01:44<02:46,  3.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.17it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-158
Configuration saved in sst_model/checkpoint-158/config.json
Model weights saved in sst_model/checkpoint-158/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-79] due to args.save_total_limit
 20%|â–ˆâ–ˆ        | 159/790 [02:19<1:54:44, 10.91s/it] 20%|â–ˆâ–ˆ        | 160/790 [02:19<1:21:09,  7.73s/it] 20%|â–ˆâ–ˆ        | 161/790 [02:19<57:40,  5.50s/it]   21%|â–ˆâ–ˆ        | 162/790 [02:20<41:15,  3.94s/it] 21%|â–ˆâ–ˆ        | 163/790 [02:20<29:48,  2.85s/it] 21%|â–ˆâ–ˆ        | 164/790 [02:20<21:47,  2.09s/it] 21%|â–ˆâ–ˆ        | 165/790 [02:20<16:11,  1.55s/it] 21%|â–ˆâ–ˆ        | 166/790 [02:21<12:16,  1.18s/it] 21%|â–ˆâ–ˆ        | 167/790 [02:21<09:32,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 168/790 [02:21<07:37,  1.36it/s] 21%|â–ˆâ–ˆâ–       | 169/790 [02:22<06:16,  1.65it/s] 22%|â–ˆâ–ˆâ–       | 170/790 [02:22<05:20,  1.93it/s] 22%|â–ˆâ–ˆâ–       | 171/790 [02:22<04:40,  2.20it/s] 22%|â–ˆâ–ˆâ–       | 172/790 [02:23<04:13,  2.44it/s] 22%|â–ˆâ–ˆâ–       | 173/790 [02:23<03:54,  2.63it/s] 22%|â–ˆâ–ˆâ–       | 174/790 [02:23<03:40,  2.79it/s] 22%|â–ˆâ–ˆâ–       | 175/790 [02:24<03:31,  2.91it/s] 22%|â–ˆâ–ˆâ–       | 176/790 [02:24<03:24,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 177/790 [02:24<03:19,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 178/790 [02:24<03:16,  3.12it/s] 23%|â–ˆâ–ˆâ–Ž       | 179/790 [02:25<03:14,  3.15it/s] 23%|â–ˆâ–ˆâ–Ž       | 180/790 [02:25<03:11,  3.18it/s] 23%|â–ˆâ–ˆâ–Ž       | 181/790 [02:25<03:10,  3.20it/s] 23%|â–ˆâ–ˆâ–Ž       | 182/790 [02:26<03:09,  3.20it/s] 23%|â–ˆâ–ˆâ–Ž       | 183/790 [02:26<03:09,  3.20it/s] 23%|â–ˆâ–ˆâ–Ž       | 184/790 [02:26<03:08,  3.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 185/790 [02:27<03:07,  3.22it/s] 24%|â–ˆâ–ˆâ–Ž       | 186/790 [02:27<03:06,  3.23it/s] 24%|â–ˆâ–ˆâ–Ž       | 187/790 [02:27<03:07,  3.21it/s] 24%|â–ˆâ–ˆâ–       | 188/790 [02:28<03:06,  3.22it/s] 24%|â–ˆâ–ˆâ–       | 189/790 [02:28<03:06,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 190/790 [02:28<03:05,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 191/790 [02:28<03:03,  3.26it/s] 24%|â–ˆâ–ˆâ–       | 192/790 [02:29<03:04,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 193/790 [02:29<03:04,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 194/790 [02:29<03:03,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 195/790 [02:30<03:03,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 196/790 [02:30<03:03,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 197/790 [02:30<03:03,  3.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 198/790 [02:31<03:03,  3.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 199/790 [02:31<03:02,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 200/790 [02:31<03:02,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 201/790 [02:32<03:02,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 202/790 [02:32<03:01,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 203/790 [02:32<03:01,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 204/790 [02:33<03:01,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 205/790 [02:33<03:02,  3.20it/s] 26%|â–ˆâ–ˆâ–Œ       | 206/790 [02:33<03:01,  3.21it/s] 26%|â–ˆâ–ˆâ–Œ       | 207/790 [02:33<03:01,  3.22it/s] 26%|â–ˆâ–ˆâ–‹       | 208/790 [02:34<03:00,  3.22it/s] 26%|â–ˆâ–ˆâ–‹       | 209/790 [02:34<02:59,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 210/790 [02:34<03:00,  3.21it/s] 27%|â–ˆâ–ˆâ–‹       | 211/790 [02:35<02:59,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 212/790 [02:35<02:59,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 213/790 [02:35<02:58,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 214/790 [02:36<02:58,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 215/790 [02:36<02:58,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 216/790 [02:36<02:57,  3.24it/s] 27%|â–ˆâ–ˆâ–‹       | 217/790 [02:37<02:57,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 218/790 [02:37<02:59,  3.19it/s] 28%|â–ˆâ–ˆâ–Š       | 219/790 [02:37<02:58,  3.21it/s] 28%|â–ˆâ–ˆâ–Š       | 220/790 [02:37<02:57,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 221/790 [02:38<02:56,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 222/790 [02:38<02:56,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 223/790 [02:38<02:55,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 224/790 [02:39<02:55,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 225/790 [02:39<02:55,  3.23it/s] 29%|â–ˆâ–ˆâ–Š       | 226/790 [02:39<02:54,  3.23it/s] 29%|â–ˆâ–ˆâ–Š       | 227/790 [02:40<02:54,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 228/790 [02:40<02:55,  3.20it/s] 29%|â–ˆâ–ˆâ–‰       | 229/790 [02:40<02:55,  3.20it/s] 29%|â–ˆâ–ˆâ–‰       | 230/790 [02:41<02:54,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 231/790 [02:41<02:53,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 232/790 [02:41<02:53,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 233/790 [02:42<02:53,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 234/790 [02:42<02:52,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 235/790 [02:42<02:52,  3.23it/s] 30%|â–ˆâ–ˆâ–‰       | 236/790 [02:42<02:51,  3.23it/s] 30%|â–ˆâ–ˆâ–ˆ       | 237/790 [02:43<02:24,  3.82it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 11.99it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.09it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.64it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.36it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.14it/s][A                                                 
                                               [A 30%|â–ˆâ–ˆâ–ˆ       | 237/790 [02:44<02:24,  3.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.14it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-237
Configuration saved in sst_model/checkpoint-237/config.json
Model weights saved in sst_model/checkpoint-237/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-40] due to args.save_total_limit
 30%|â–ˆâ–ˆâ–ˆ       | 238/790 [02:58<44:38,  4.85s/it] 30%|â–ˆâ–ˆâ–ˆ       | 239/790 [02:58<32:02,  3.49s/it] 30%|â–ˆâ–ˆâ–ˆ       | 240/790 [02:59<23:14,  2.54s/it] 31%|â–ˆâ–ˆâ–ˆ       | 241/790 [02:59<17:05,  1.87s/it] 31%|â–ˆâ–ˆâ–ˆ       | 242/790 [02:59<12:47,  1.40s/it] 31%|â–ˆâ–ˆâ–ˆ       | 243/790 [03:00<09:46,  1.07s/it] 31%|â–ˆâ–ˆâ–ˆ       | 244/790 [03:00<07:40,  1.19it/s] 31%|â–ˆâ–ˆâ–ˆ       | 245/790 [03:00<06:12,  1.46it/s] 31%|â–ˆâ–ˆâ–ˆ       | 246/790 [03:01<05:10,  1.75it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 247/790 [03:01<04:27,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 248/790 [03:01<03:56,  2.29it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 249/790 [03:02<03:35,  2.51it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 250/790 [03:02<03:20,  2.69it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 251/790 [03:02<03:09,  2.84it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 252/790 [03:02<03:02,  2.94it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 253/790 [03:03<02:57,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 254/790 [03:03<02:54,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 255/790 [03:03<02:51,  3.12it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 256/790 [03:04<02:49,  3.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 257/790 [03:04<02:47,  3.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 258/790 [03:04<02:46,  3.20it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 259/790 [03:05<02:45,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 260/790 [03:05<02:45,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 261/790 [03:05<02:44,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 262/790 [03:06<02:44,  3.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 263/790 [03:06<02:43,  3.23it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 264/790 [03:06<02:43,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 265/790 [03:07<02:43,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 266/790 [03:07<02:42,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 267/790 [03:07<02:42,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 268/790 [03:07<02:42,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 269/790 [03:08<02:42,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 270/790 [03:08<02:42,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 271/790 [03:08<02:41,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 272/790 [03:09<02:41,  3.21it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 273/790 [03:09<02:41,  3.21it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 274/790 [03:09<02:40,  3.21it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 275/790 [03:10<02:40,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 276/790 [03:10<02:39,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 277/790 [03:10<02:39,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 278/790 [03:11<02:38,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 279/790 [03:11<02:38,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 280/790 [03:11<02:38,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 281/790 [03:11<02:38,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 282/790 [03:12<02:38,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 283/790 [03:12<02:38,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 284/790 [03:12<02:37,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 285/790 [03:13<02:36,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 286/790 [03:13<02:36,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 287/790 [03:13<02:36,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 288/790 [03:14<02:35,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 289/790 [03:14<02:35,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 290/790 [03:14<02:35,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 291/790 [03:15<02:34,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 292/790 [03:15<02:34,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 293/790 [03:15<02:34,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 294/790 [03:16<02:33,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 295/790 [03:16<02:33,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 296/790 [03:16<02:33,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 297/790 [03:16<02:32,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 298/790 [03:17<02:32,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 299/790 [03:17<02:32,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 300/790 [03:17<02:31,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 301/790 [03:18<02:31,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 302/790 [03:18<02:31,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 303/790 [03:18<02:31,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 304/790 [03:19<02:30,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 305/790 [03:19<02:30,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 306/790 [03:19<02:29,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 307/790 [03:20<02:29,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 308/790 [03:20<02:29,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 309/790 [03:20<02:29,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 310/790 [03:20<02:28,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 311/790 [03:21<02:28,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 312/790 [03:21<02:28,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 313/790 [03:21<02:27,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 314/790 [03:22<02:27,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 315/790 [03:22<02:27,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 316/790 [03:22<02:04,  3.82it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.04it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.10it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.65it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.40it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.14it/s][A                                                 
                                               [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 316/790 [03:23<02:04,  3.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.14it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-316
Configuration saved in sst_model/checkpoint-316/config.json
Model weights saved in sst_model/checkpoint-316/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-158] due to args.save_total_limit
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 317/790 [03:40<44:00,  5.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 318/790 [03:40<31:27,  4.00s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 319/790 [03:41<22:41,  2.89s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 320/790 [03:41<16:34,  2.12s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 321/790 [03:41<12:18,  1.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 322/790 [03:42<09:19,  1.20s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 323/790 [03:42<07:13,  1.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 324/790 [03:42<05:45,  1.35it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 325/790 [03:43<04:45,  1.63it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 326/790 [03:43<04:02,  1.91it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 327/790 [03:43<03:31,  2.18it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 328/790 [03:44<03:10,  2.42it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 329/790 [03:44<02:55,  2.62it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 330/790 [03:44<02:45,  2.77it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 331/790 [03:45<02:38,  2.90it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 332/790 [03:45<02:32,  3.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 333/790 [03:45<02:29,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 334/790 [03:45<02:26,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 335/790 [03:46<02:27,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 336/790 [03:46<02:25,  3.13it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 337/790 [03:46<02:23,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 338/790 [03:47<02:22,  3.18it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 339/790 [03:47<02:21,  3.20it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 340/790 [03:47<02:20,  3.20it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 341/790 [03:48<02:19,  3.21it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 342/790 [03:48<02:19,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 343/790 [03:48<02:18,  3.22it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 344/790 [03:49<02:17,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 345/790 [03:49<02:17,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 346/790 [03:49<02:16,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 347/790 [03:49<02:16,  3.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 348/790 [03:50<02:16,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 349/790 [03:50<02:16,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 350/790 [03:50<02:16,  3.23it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 351/790 [03:51<02:15,  3.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 352/790 [03:51<02:15,  3.24it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 353/790 [03:51<02:15,  3.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 354/790 [03:52<02:14,  3.24it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 355/790 [03:52<02:13,  3.25it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 356/790 [03:52<02:12,  3.27it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 357/790 [03:53<02:15,  3.20it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 358/790 [03:53<02:15,  3.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 359/790 [03:53<02:14,  3.21it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 360/790 [03:53<02:13,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 361/790 [03:54<02:13,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 362/790 [03:54<02:12,  3.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 363/790 [03:54<02:12,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 364/790 [03:55<02:12,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 365/790 [03:55<02:11,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 366/790 [03:55<02:11,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 367/790 [03:56<02:11,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 368/790 [03:56<02:11,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 369/790 [03:56<02:10,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 370/790 [03:57<02:10,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 371/790 [03:57<02:10,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 372/790 [03:57<02:10,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 373/790 [03:58<02:09,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 374/790 [03:58<02:09,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 375/790 [03:58<02:09,  3.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 376/790 [03:58<02:08,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 377/790 [03:59<02:07,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 378/790 [03:59<02:07,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 379/790 [03:59<02:06,  3.24it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 380/790 [04:00<02:06,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 381/790 [04:00<02:06,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 382/790 [04:00<02:05,  3.24it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 383/790 [04:01<02:05,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 384/790 [04:01<02:05,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 385/790 [04:01<02:05,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 386/790 [04:02<02:05,  3.22it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 387/790 [04:02<02:05,  3.22it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 388/790 [04:02<02:04,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 389/790 [04:02<02:04,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 390/790 [04:03<02:03,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 391/790 [04:03<02:03,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 392/790 [04:03<02:03,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 393/790 [04:04<02:02,  3.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 394/790 [04:04<02:02,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 395/790 [04:04<01:42,  3.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.97it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.55it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.22it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.68it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.41it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.25it/s][A                                                 
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 395/790 [04:05<01:42,  3.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.25it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-395
Configuration saved in sst_model/checkpoint-395/config.json
Model weights saved in sst_model/checkpoint-395/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-237] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 396/790 [04:37<1:05:55, 10.04s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 397/790 [04:37<46:38,  7.12s/it]   50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 398/790 [04:38<33:10,  5.08s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 399/790 [04:38<23:45,  3.65s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 400/790 [04:38<17:11,  2.64s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 401/790 [04:39<12:36,  1.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 402/790 [04:39<09:23,  1.45s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 403/790 [04:39<07:09,  1.11s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 404/790 [04:40<05:35,  1.15it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 405/790 [04:40<04:29,  1.43it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 406/790 [04:40<03:44,  1.71it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 407/790 [04:40<03:11,  2.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 408/790 [04:41<02:48,  2.26it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 409/790 [04:41<02:32,  2.50it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 410/790 [04:41<02:21,  2.69it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 411/790 [04:42<02:12,  2.85it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 412/790 [04:42<02:07,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 413/790 [04:42<02:03,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 414/790 [04:43<02:01,  3.10it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 415/790 [04:43<01:59,  3.15it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 416/790 [04:43<01:57,  3.18it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 417/790 [04:43<01:56,  3.21it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 418/790 [04:44<01:55,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 419/790 [04:44<01:55,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 420/790 [04:44<01:54,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 421/790 [04:45<01:54,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 422/790 [04:45<01:53,  3.23it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 423/790 [04:45<01:53,  3.24it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 424/790 [04:46<01:52,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 425/790 [04:46<01:52,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 426/790 [04:46<01:51,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 427/790 [04:47<01:51,  3.26it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 428/790 [04:47<01:51,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 429/790 [04:47<01:50,  3.26it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 430/790 [04:47<01:50,  3.26it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 431/790 [04:48<01:50,  3.25it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 432/790 [04:48<01:49,  3.26it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 433/790 [04:48<01:49,  3.25it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 434/790 [04:49<01:49,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 435/790 [04:49<01:49,  3.25it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 436/790 [04:49<01:49,  3.25it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 437/790 [04:50<01:48,  3.26it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 438/790 [04:50<01:47,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 439/790 [04:50<01:47,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 440/790 [04:51<01:47,  3.25it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 441/790 [04:51<01:47,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 442/790 [04:51<01:47,  3.25it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 443/790 [04:51<01:46,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 444/790 [04:52<01:46,  3.25it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 445/790 [04:52<01:46,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 446/790 [04:52<01:46,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 447/790 [04:53<01:45,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 448/790 [04:53<01:45,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 449/790 [04:53<01:45,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 450/790 [04:54<01:44,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 451/790 [04:54<01:44,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 452/790 [04:54<01:44,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 453/790 [04:55<01:43,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 454/790 [04:55<01:43,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 455/790 [04:55<01:43,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 456/790 [04:56<01:43,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 457/790 [04:56<01:43,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 458/790 [04:56<01:42,  3.22it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 459/790 [04:56<01:42,  3.22it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 460/790 [04:57<01:42,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 461/790 [04:57<01:41,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 462/790 [04:57<01:41,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 463/790 [04:58<01:41,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 464/790 [04:58<01:41,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 465/790 [04:58<01:40,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 466/790 [04:59<01:40,  3.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 467/790 [04:59<01:40,  3.20it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 468/790 [04:59<01:40,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 469/790 [05:00<01:39,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 470/790 [05:00<01:39,  3.22it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 471/790 [05:00<01:38,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 472/790 [05:00<01:38,  3.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 473/790 [05:01<01:37,  3.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 474/790 [05:01<01:23,  3.78it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.93it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.56it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.20it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.68it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.40it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.25it/s][A                                                 
                                               [A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 474/790 [05:02<01:23,  3.78it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.25it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-474
Configuration saved in sst_model/checkpoint-474/config.json
Model weights saved in sst_model/checkpoint-474/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-395] due to args.save_total_limit
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 475/790 [05:42<1:05:21, 12.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 476/790 [05:42<46:05,  8.81s/it]   60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 477/790 [05:42<32:37,  6.26s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 478/790 [05:43<23:14,  4.47s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 479/790 [05:43<16:41,  3.22s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 480/790 [05:43<12:07,  2.35s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 481/790 [05:44<08:56,  1.74s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 482/790 [05:44<06:42,  1.31s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 483/790 [05:44<05:09,  1.01s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 484/790 [05:45<04:03,  1.26it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 485/790 [05:45<03:17,  1.54it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 486/790 [05:45<02:45,  1.83it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 487/790 [05:45<02:23,  2.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 488/790 [05:46<02:07,  2.36it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 489/790 [05:46<01:56,  2.57it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 490/790 [05:46<01:48,  2.76it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 491/790 [05:47<01:43,  2.89it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 492/790 [05:47<01:39,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 493/790 [05:47<01:36,  3.08it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 494/790 [05:48<01:34,  3.14it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 495/790 [05:48<01:32,  3.18it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 496/790 [05:48<01:31,  3.21it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 497/790 [05:49<01:30,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 498/790 [05:49<01:30,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 499/790 [05:49<01:29,  3.25it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 500/790 [05:49<01:28,  3.27it/s]                                                  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 500/790 [05:49<01:28,  3.27it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 501/790 [05:50<01:28,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 502/790 [05:50<01:28,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 503/790 [05:50<01:28,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 504/790 [05:51<01:28,  3.23it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 505/790 [05:51<01:27,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 506/790 [05:51<01:27,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 507/790 [05:52<01:27,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 508/790 [05:52<01:27,  3.21it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 509/790 [05:52<01:26,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 510/790 [05:53<01:26,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 511/790 [05:53<01:26,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 512/790 [05:53<01:25,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 513/790 [05:53<01:25,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 514/790 [05:54<01:24,  3.26it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 515/790 [05:54<01:24,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 516/790 [05:54<01:24,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 517/790 [05:55<01:23,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 518/790 [05:55<01:23,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 519/790 [05:55<01:23,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 520/790 [05:56<01:23,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 521/790 [05:56<01:22,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 522/790 [05:56<01:22,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 523/790 [05:57<01:23,  3.21it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 524/790 [05:57<01:22,  3.21it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 525/790 [05:57<01:22,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 526/790 [05:57<01:21,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 527/790 [05:58<01:21,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 528/790 [05:58<01:20,  3.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 529/790 [06:07<11:58,  2.75s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 530/790 [06:07<08:53,  2.05s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 531/790 [06:07<06:36,  1.53s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 532/790 [06:08<05:01,  1.17s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 533/790 [06:08<03:54,  1.10it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 534/790 [06:08<03:07,  1.37it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 535/790 [06:09<02:34,  1.66it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 536/790 [06:09<02:10,  1.95it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 537/790 [06:09<01:54,  2.21it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 538/790 [06:09<01:43,  2.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 539/790 [06:10<01:35,  2.64it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 540/790 [06:10<01:29,  2.80it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 541/790 [06:10<01:25,  2.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 542/790 [06:11<01:22,  3.02it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 543/790 [06:11<01:19,  3.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 544/790 [06:11<01:18,  3.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 545/790 [06:12<01:17,  3.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 546/790 [06:12<01:16,  3.21it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 547/790 [06:12<01:15,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 548/790 [06:13<01:14,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 549/790 [06:13<01:14,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 550/790 [06:13<01:14,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 551/790 [06:13<01:13,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 552/790 [06:14<01:13,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 553/790 [06:14<01:01,  3.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.08it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.14it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.70it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.45it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A                                                 
                                               [A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 553/790 [06:15<01:01,  3.83it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-553
Configuration saved in sst_model/checkpoint-553/config.json
Model weights saved in sst_model/checkpoint-553/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-474] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 554/790 [06:36<26:38,  6.77s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 555/790 [06:36<18:55,  4.83s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 556/790 [06:36<13:33,  3.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 557/790 [06:37<09:47,  2.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 558/790 [06:37<07:10,  1.86s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 559/790 [06:37<05:21,  1.39s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 560/790 [06:38<04:04,  1.07s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 561/790 [06:38<03:11,  1.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 562/790 [06:38<02:34,  1.47it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 563/790 [06:39<02:08,  1.77it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 564/790 [06:39<01:50,  2.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 565/790 [06:39<01:37,  2.30it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 566/790 [06:40<01:28,  2.52it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 567/790 [06:40<01:22,  2.71it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 568/790 [06:40<01:17,  2.85it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 569/790 [06:40<01:14,  2.97it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 570/790 [06:41<01:12,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 571/790 [06:41<01:10,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 572/790 [06:41<01:08,  3.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 573/790 [06:42<01:08,  3.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 574/790 [06:42<01:07,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 575/790 [06:42<01:06,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 576/790 [06:43<01:06,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 577/790 [06:43<01:05,  3.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 578/790 [06:43<01:05,  3.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 579/790 [06:44<01:04,  3.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 580/790 [06:44<01:04,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 581/790 [06:44<01:04,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 582/790 [06:44<01:03,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 583/790 [06:45<01:03,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 584/790 [06:45<01:03,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 585/790 [06:45<01:02,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 586/790 [06:46<01:02,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 587/790 [06:46<01:02,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 588/790 [06:46<01:02,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 589/790 [06:47<01:02,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 590/790 [06:47<01:01,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 591/790 [06:47<01:01,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 592/790 [06:48<01:00,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 593/790 [06:48<01:00,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 594/790 [06:48<00:59,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 595/790 [06:48<00:59,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 596/790 [06:49<00:59,  3.28it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 597/790 [06:49<00:59,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 598/790 [06:49<00:59,  3.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 599/790 [06:50<00:58,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 600/790 [06:50<00:59,  3.20it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 601/790 [06:50<00:58,  3.21it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 602/790 [06:51<00:58,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 603/790 [06:51<00:57,  3.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 604/790 [06:51<00:57,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 605/790 [06:52<00:56,  3.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 606/790 [06:52<00:56,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 607/790 [06:52<00:56,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 608/790 [06:52<00:55,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 609/790 [06:53<00:55,  3.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 610/790 [06:53<00:55,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 611/790 [06:53<00:54,  3.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 612/790 [06:54<00:54,  3.25it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 613/790 [06:54<00:54,  3.26it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 614/790 [06:54<00:54,  3.26it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 615/790 [06:55<00:53,  3.26it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 616/790 [06:55<00:53,  3.26it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 617/790 [06:55<00:53,  3.25it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 618/790 [06:56<00:52,  3.26it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 619/790 [06:56<00:52,  3.25it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 620/790 [06:56<00:52,  3.25it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 621/790 [06:56<00:51,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 622/790 [06:57<00:51,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 623/790 [06:57<00:51,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 624/790 [06:57<00:51,  3.25it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 625/790 [06:58<00:50,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 626/790 [06:58<00:50,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 627/790 [06:58<00:49,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 628/790 [06:59<00:49,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 629/790 [06:59<00:49,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 630/790 [06:59<00:49,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 631/790 [07:00<00:48,  3.25it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 632/790 [07:00<00:41,  3.84it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.02it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.07it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.14it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.67it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.41it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.16it/s][A                                                 
                                               [A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 632/790 [07:01<00:41,  3.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.16it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-632
Configuration saved in sst_model/checkpoint-632/config.json
Model weights saved in sst_model/checkpoint-632/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-553] due to args.save_total_limit
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 633/790 [07:14<11:42,  4.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 634/790 [07:14<08:22,  3.22s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 635/790 [07:15<06:03,  2.35s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 636/790 [07:15<04:27,  1.74s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 637/790 [07:15<03:19,  1.31s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 638/790 [07:15<02:32,  1.01s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 639/790 [07:16<02:00,  1.26it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 640/790 [07:16<01:37,  1.54it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 641/790 [07:16<01:21,  1.83it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 642/790 [07:17<01:12,  2.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 643/790 [07:17<01:03,  2.30it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 644/790 [07:17<00:57,  2.53it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 645/790 [07:18<00:53,  2.71it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 646/790 [07:18<00:50,  2.86it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 647/790 [07:18<00:48,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 648/790 [07:19<00:46,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 649/790 [07:19<00:45,  3.12it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 650/790 [07:19<00:44,  3.15it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 651/790 [07:20<00:43,  3.18it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 652/790 [07:20<00:43,  3.16it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 653/790 [07:20<00:43,  3.16it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 654/790 [07:20<00:42,  3.19it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 655/790 [07:21<00:42,  3.21it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 656/790 [07:21<00:41,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 657/790 [07:21<00:41,  3.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 658/790 [07:22<00:40,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 659/790 [07:22<00:40,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 660/790 [07:22<00:40,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 661/790 [07:23<00:39,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 662/790 [07:23<00:39,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 663/790 [07:23<00:39,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 664/790 [07:24<00:38,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 665/790 [07:24<00:38,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 666/790 [07:24<00:38,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 667/790 [07:24<00:37,  3.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 668/790 [07:25<00:37,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 669/790 [07:25<00:37,  3.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 670/790 [07:25<00:36,  3.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 671/790 [07:26<00:36,  3.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 672/790 [07:26<00:36,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 673/790 [07:26<00:35,  3.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 674/790 [07:27<00:35,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 675/790 [07:27<00:35,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 676/790 [07:27<00:35,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 677/790 [07:28<00:34,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 678/790 [07:28<00:34,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 679/790 [07:28<00:33,  3.27it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 680/790 [07:28<00:33,  3.27it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 681/790 [07:29<00:33,  3.27it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 682/790 [07:29<00:33,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 683/790 [07:29<00:32,  3.26it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 684/790 [07:30<00:32,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 685/790 [07:30<00:32,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 686/790 [07:30<00:32,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 687/790 [07:31<00:31,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 688/790 [07:31<00:31,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 689/790 [07:31<00:31,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 690/790 [07:32<00:30,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 691/790 [07:32<00:30,  3.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 692/790 [07:32<00:30,  3.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 693/790 [07:32<00:29,  3.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 694/790 [07:33<00:29,  3.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 695/790 [07:33<00:29,  3.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 696/790 [07:33<00:28,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 697/790 [07:34<00:28,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 698/790 [07:34<00:28,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 699/790 [07:34<00:28,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 700/790 [07:35<00:27,  3.24it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 701/790 [07:35<00:27,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 702/790 [07:35<00:27,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 703/790 [07:36<00:26,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 704/790 [07:36<00:26,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 705/790 [07:36<00:26,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 706/790 [07:36<00:25,  3.24it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 707/790 [07:37<00:25,  3.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 708/790 [07:37<00:25,  3.25it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 709/790 [07:37<00:25,  3.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 710/790 [07:38<00:24,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 711/790 [07:38<00:20,  3.82it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.90it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.55it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.22it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.69it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.41it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.25it/s][A                                                 
                                               [A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 711/790 [07:39<00:20,  3.82it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.25it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-711
Configuration saved in sst_model/checkpoint-711/config.json
Model weights saved in sst_model/checkpoint-711/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-632] due to args.save_total_limit
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 712/790 [07:58<08:03,  6.20s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 713/790 [07:58<05:41,  4.43s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 714/790 [07:59<04:02,  3.20s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 715/790 [07:59<02:54,  2.33s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 716/790 [07:59<02:07,  1.72s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 717/790 [07:59<01:34,  1.30s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 718/790 [08:00<01:12,  1.00s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 719/790 [08:00<00:56,  1.26it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 720/790 [08:00<00:45,  1.55it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 721/790 [08:01<00:37,  1.82it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 722/790 [08:01<00:32,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 723/790 [08:01<00:28,  2.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 724/790 [08:02<00:25,  2.56it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 725/790 [08:02<00:23,  2.74it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 726/790 [08:02<00:22,  2.88it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 727/790 [08:03<00:21,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 728/790 [08:03<00:20,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 729/790 [08:03<00:19,  3.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 730/790 [08:03<00:18,  3.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 731/790 [08:04<00:18,  3.20it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 732/790 [08:04<00:18,  3.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 733/790 [08:04<00:17,  3.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 734/790 [08:05<00:17,  3.21it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 735/790 [08:05<00:17,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 736/790 [08:05<00:16,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 737/790 [08:06<00:16,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 738/790 [08:06<00:16,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 739/790 [08:06<00:15,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 740/790 [08:07<00:15,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 741/790 [08:07<00:15,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 742/790 [08:07<00:14,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 743/790 [08:07<00:14,  3.27it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 744/790 [08:08<00:14,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 745/790 [08:08<00:13,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 746/790 [08:08<00:13,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 747/790 [08:09<00:13,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 748/790 [08:09<00:12,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 749/790 [08:09<00:12,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 750/790 [08:10<00:12,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 751/790 [08:10<00:11,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 752/790 [08:10<00:11,  3.27it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 753/790 [08:11<00:11,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 754/790 [08:11<00:11,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 755/790 [08:11<00:10,  3.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 756/790 [08:11<00:10,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 757/790 [08:12<00:10,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 758/790 [08:12<00:09,  3.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 759/790 [08:12<00:09,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 760/790 [08:13<00:09,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 761/790 [08:13<00:08,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 762/790 [08:13<00:08,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 763/790 [08:14<00:08,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 764/790 [08:14<00:07,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 765/790 [08:14<00:07,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 766/790 [08:15<00:07,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 767/790 [08:15<00:07,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 768/790 [08:17<00:20,  1.07it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 769/790 [08:18<00:15,  1.35it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 770/790 [08:18<00:12,  1.64it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 771/790 [08:18<00:10,  1.89it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 772/790 [08:18<00:08,  2.16it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 773/790 [08:19<00:07,  2.41it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 774/790 [08:19<00:06,  2.61it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 775/790 [08:19<00:05,  2.77it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 776/790 [08:20<00:04,  2.89it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 777/790 [08:20<00:04,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 778/790 [08:20<00:03,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 779/790 [08:21<00:03,  3.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 780/790 [08:21<00:03,  3.13it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 781/790 [08:21<00:02,  3.15it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 782/790 [08:22<00:02,  3.17it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 783/790 [08:22<00:02,  3.20it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 784/790 [08:22<00:01,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 785/790 [08:23<00:01,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 786/790 [08:23<00:01,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 787/790 [08:23<00:00,  3.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 788/790 [08:23<00:00,  3.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 789/790 [08:24<00:00,  3.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790/790 [08:24<00:00,  3.83it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.96it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.59it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.25it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.25it/s][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790/790 [08:25<00:00,  3.83it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.25it/s][A
                                               [ASaving model checkpoint to sst_model/checkpoint-790
Configuration saved in sst_model/checkpoint-790/config.json
Model weights saved in sst_model/checkpoint-790/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-711] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from sst_model/checkpoint-316 (score: 0.64).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790/790 [08:51<00:00,  3.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790/790 [08:51<00:00,  1.49it/s]
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Using custom data configuration default-69afa26d3f696b84
0 tables [00:00, ? tables/s]                            loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.00ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.99ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-35bfd9f04e6658c3.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-04edea8e5deaac23.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-80dea3fb3755f005.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1f098d744ad3e451.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.41ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.41ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-523194a38c7f88f6.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-487f6c90d30222c9.arrow
PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running training *****
  Num examples = 704
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 880
  0%|          | 0/880 [00:00<?, ?it/s]  0%|          | 1/880 [00:00<05:48,  2.52it/s]  0%|          | 2/880 [00:00<05:03,  2.89it/s]  0%|          | 3/880 [00:01<04:45,  3.07it/s]  0%|          | 4/880 [00:01<04:37,  3.15it/s]  1%|          | 5/880 [00:01<04:33,  3.20it/s]  1%|          | 6/880 [00:01<04:30,  3.23it/s]  1%|          | 7/880 [00:02<04:28,  3.25it/s]  1%|          | 8/880 [00:02<04:26,  3.27it/s]  1%|          | 9/880 [00:02<04:26,  3.27it/s]  1%|          | 10/880 [00:03<04:25,  3.28it/s]  1%|â–         | 11/880 [00:03<04:24,  3.29it/s]  1%|â–         | 12/880 [00:03<04:24,  3.28it/s]  1%|â–         | 13/880 [00:04<04:23,  3.29it/s]  2%|â–         | 14/880 [00:04<04:23,  3.29it/s]  2%|â–         | 15/880 [00:04<04:23,  3.29it/s]  2%|â–         | 16/880 [00:04<04:22,  3.29it/s]  2%|â–         | 17/880 [00:05<04:22,  3.29it/s]  2%|â–         | 18/880 [00:05<04:23,  3.27it/s]  2%|â–         | 19/880 [00:05<04:22,  3.27it/s]  2%|â–         | 20/880 [00:06<04:22,  3.28it/s]  2%|â–         | 21/880 [00:06<04:21,  3.28it/s]  2%|â–Ž         | 22/880 [00:06<04:21,  3.28it/s]  3%|â–Ž         | 23/880 [00:07<04:20,  3.28it/s]  3%|â–Ž         | 24/880 [00:07<04:20,  3.28it/s]  3%|â–Ž         | 25/880 [00:07<04:19,  3.29it/s]  3%|â–Ž         | 26/880 [00:08<04:19,  3.29it/s]  3%|â–Ž         | 27/880 [00:08<04:19,  3.29it/s]  3%|â–Ž         | 28/880 [00:08<04:19,  3.28it/s]  3%|â–Ž         | 29/880 [00:08<04:19,  3.28it/s]  3%|â–Ž         | 30/880 [00:09<04:18,  3.29it/s]  4%|â–Ž         | 31/880 [00:09<04:18,  3.28it/s]  4%|â–Ž         | 32/880 [00:09<04:18,  3.28it/s]  4%|â–         | 33/880 [00:10<04:18,  3.28it/s]  4%|â–         | 34/880 [00:10<04:17,  3.28it/s]  4%|â–         | 35/880 [00:10<04:17,  3.28it/s]  4%|â–         | 36/880 [00:11<04:17,  3.28it/s]  4%|â–         | 37/880 [00:11<04:16,  3.28it/s]  4%|â–         | 38/880 [00:11<04:16,  3.28it/s]  4%|â–         | 39/880 [00:11<04:16,  3.28it/s]  5%|â–         | 40/880 [00:12<04:15,  3.28it/s]  5%|â–         | 41/880 [00:12<04:15,  3.28it/s]  5%|â–         | 42/880 [00:12<04:15,  3.27it/s]  5%|â–         | 43/880 [00:13<04:15,  3.28it/s]  5%|â–Œ         | 44/880 [00:13<04:16,  3.27it/s]  5%|â–Œ         | 45/880 [00:13<04:15,  3.27it/s]  5%|â–Œ         | 46/880 [00:14<04:15,  3.27it/s]  5%|â–Œ         | 47/880 [00:14<04:15,  3.26it/s]  5%|â–Œ         | 48/880 [00:14<04:14,  3.27it/s]  6%|â–Œ         | 49/880 [00:15<04:14,  3.27it/s]  6%|â–Œ         | 50/880 [00:15<04:14,  3.27it/s]  6%|â–Œ         | 51/880 [00:15<04:14,  3.26it/s]  6%|â–Œ         | 52/880 [00:15<04:14,  3.25it/s]  6%|â–Œ         | 53/880 [00:16<04:13,  3.26it/s]  6%|â–Œ         | 54/880 [00:16<04:13,  3.26it/s]  6%|â–‹         | 55/880 [00:16<04:12,  3.26it/s]  6%|â–‹         | 56/880 [00:17<04:12,  3.26it/s]  6%|â–‹         | 57/880 [00:17<04:12,  3.26it/s]  7%|â–‹         | 58/880 [00:17<04:12,  3.26it/s]  7%|â–‹         | 59/880 [00:18<04:11,  3.26it/s]  7%|â–‹         | 60/880 [00:18<04:11,  3.26it/s]  7%|â–‹         | 61/880 [00:18<04:11,  3.26it/s]  7%|â–‹         | 62/880 [00:19<04:11,  3.26it/s]  7%|â–‹         | 63/880 [00:19<04:10,  3.26it/s]  7%|â–‹         | 64/880 [00:19<04:10,  3.26it/s]  7%|â–‹         | 65/880 [00:19<04:11,  3.24it/s]  8%|â–Š         | 66/880 [00:20<04:11,  3.24it/s]  8%|â–Š         | 67/880 [00:20<04:10,  3.25it/s]  8%|â–Š         | 68/880 [00:20<04:09,  3.25it/s]  8%|â–Š         | 69/880 [00:21<04:09,  3.25it/s]  8%|â–Š         | 70/880 [00:21<04:09,  3.24it/s]  8%|â–Š         | 71/880 [00:21<04:09,  3.25it/s]  8%|â–Š         | 72/880 [00:22<04:08,  3.25it/s]  8%|â–Š         | 73/880 [00:22<04:08,  3.25it/s]  8%|â–Š         | 74/880 [00:22<04:10,  3.21it/s]  9%|â–Š         | 75/880 [00:23<04:09,  3.23it/s]  9%|â–Š         | 76/880 [00:23<04:08,  3.24it/s]  9%|â–‰         | 77/880 [00:23<04:07,  3.24it/s]  9%|â–‰         | 78/880 [00:23<04:07,  3.25it/s]  9%|â–‰         | 79/880 [00:24<04:06,  3.25it/s]  9%|â–‰         | 80/880 [00:24<04:06,  3.25it/s]  9%|â–‰         | 81/880 [00:24<04:05,  3.25it/s]  9%|â–‰         | 82/880 [00:25<04:05,  3.25it/s]  9%|â–‰         | 83/880 [00:25<04:05,  3.25it/s] 10%|â–‰         | 84/880 [00:25<04:05,  3.25it/s] 10%|â–‰         | 85/880 [00:26<04:05,  3.24it/s] 10%|â–‰         | 86/880 [00:26<04:04,  3.24it/s] 10%|â–‰         | 87/880 [00:26<04:04,  3.24it/s] 10%|â–ˆ         | 88/880 [00:27<04:03,  3.25it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.37it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.13it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 10.93it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.52it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.32it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.23it/s][A
                                               [A                                                
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.23it/s][A 10%|â–ˆ         | 88/880 [00:28<04:03,  3.25it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-88
Configuration saved in sst_model/checkpoint-88/config.json
Model weights saved in sst_model/checkpoint-88/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-316] due to args.save_total_limit
 10%|â–ˆ         | 89/880 [01:05<2:33:11, 11.62s/it] 10%|â–ˆ         | 90/880 [01:05<1:48:20,  8.23s/it] 10%|â–ˆ         | 91/880 [01:05<1:16:57,  5.85s/it] 10%|â–ˆ         | 92/880 [01:05<55:00,  4.19s/it]   11%|â–ˆ         | 93/880 [01:06<39:39,  3.02s/it] 11%|â–ˆ         | 94/880 [01:06<28:55,  2.21s/it] 11%|â–ˆ         | 95/880 [01:06<21:26,  1.64s/it] 11%|â–ˆ         | 96/880 [01:07<16:11,  1.24s/it] 11%|â–ˆ         | 97/880 [01:07<12:30,  1.04it/s] 11%|â–ˆ         | 98/880 [01:07<09:56,  1.31it/s] 11%|â–ˆâ–        | 99/880 [01:08<08:08,  1.60it/s] 11%|â–ˆâ–        | 100/880 [01:08<06:54,  1.88it/s] 11%|â–ˆâ–        | 101/880 [01:08<06:01,  2.15it/s] 12%|â–ˆâ–        | 102/880 [01:09<05:24,  2.40it/s] 12%|â–ˆâ–        | 103/880 [01:09<04:58,  2.60it/s] 12%|â–ˆâ–        | 104/880 [01:09<04:40,  2.77it/s] 12%|â–ˆâ–        | 105/880 [01:09<04:27,  2.90it/s] 12%|â–ˆâ–        | 106/880 [01:10<04:17,  3.00it/s] 12%|â–ˆâ–        | 107/880 [01:10<04:11,  3.08it/s] 12%|â–ˆâ–        | 108/880 [01:10<04:06,  3.13it/s] 12%|â–ˆâ–        | 109/880 [01:11<04:03,  3.16it/s] 12%|â–ˆâ–Ž        | 110/880 [01:11<04:01,  3.19it/s] 13%|â–ˆâ–Ž        | 111/880 [01:11<03:59,  3.21it/s] 13%|â–ˆâ–Ž        | 112/880 [01:12<03:58,  3.22it/s] 13%|â–ˆâ–Ž        | 113/880 [01:12<03:59,  3.21it/s] 13%|â–ˆâ–Ž        | 114/880 [01:12<03:58,  3.21it/s] 13%|â–ˆâ–Ž        | 115/880 [01:13<03:57,  3.22it/s] 13%|â–ˆâ–Ž        | 116/880 [01:13<03:56,  3.23it/s] 13%|â–ˆâ–Ž        | 117/880 [01:13<03:55,  3.24it/s] 13%|â–ˆâ–Ž        | 118/880 [01:13<03:56,  3.22it/s] 14%|â–ˆâ–Ž        | 119/880 [01:14<03:55,  3.23it/s] 14%|â–ˆâ–Ž        | 120/880 [01:14<03:54,  3.23it/s] 14%|â–ˆâ–        | 121/880 [01:14<03:54,  3.24it/s] 14%|â–ˆâ–        | 122/880 [01:15<03:53,  3.24it/s] 14%|â–ˆâ–        | 123/880 [01:15<03:54,  3.23it/s] 14%|â–ˆâ–        | 124/880 [01:15<03:53,  3.23it/s] 14%|â–ˆâ–        | 125/880 [01:16<03:53,  3.23it/s] 14%|â–ˆâ–        | 126/880 [01:16<03:52,  3.24it/s] 14%|â–ˆâ–        | 127/880 [01:16<03:52,  3.24it/s] 15%|â–ˆâ–        | 128/880 [01:17<03:52,  3.24it/s] 15%|â–ˆâ–        | 129/880 [01:17<03:51,  3.24it/s] 15%|â–ˆâ–        | 130/880 [01:17<03:51,  3.24it/s] 15%|â–ˆâ–        | 131/880 [01:17<03:53,  3.21it/s] 15%|â–ˆâ–Œ        | 132/880 [01:18<03:52,  3.21it/s] 15%|â–ˆâ–Œ        | 133/880 [01:18<03:51,  3.22it/s] 15%|â–ˆâ–Œ        | 134/880 [01:18<03:51,  3.23it/s] 15%|â–ˆâ–Œ        | 135/880 [01:19<03:50,  3.23it/s] 15%|â–ˆâ–Œ        | 136/880 [01:19<03:49,  3.24it/s] 16%|â–ˆâ–Œ        | 137/880 [01:19<03:50,  3.22it/s] 16%|â–ˆâ–Œ        | 138/880 [01:20<03:49,  3.23it/s] 16%|â–ˆâ–Œ        | 139/880 [01:20<03:48,  3.24it/s] 16%|â–ˆâ–Œ        | 140/880 [01:20<03:48,  3.23it/s] 16%|â–ˆâ–Œ        | 141/880 [01:21<03:49,  3.22it/s] 16%|â–ˆâ–Œ        | 142/880 [01:21<03:49,  3.22it/s] 16%|â–ˆâ–‹        | 143/880 [01:21<03:48,  3.22it/s] 16%|â–ˆâ–‹        | 144/880 [01:22<03:47,  3.23it/s] 16%|â–ˆâ–‹        | 145/880 [01:22<03:47,  3.23it/s] 17%|â–ˆâ–‹        | 146/880 [01:22<03:48,  3.22it/s] 17%|â–ˆâ–‹        | 147/880 [01:22<03:47,  3.23it/s] 17%|â–ˆâ–‹        | 148/880 [01:23<03:46,  3.23it/s] 17%|â–ˆâ–‹        | 149/880 [01:23<03:46,  3.23it/s] 17%|â–ˆâ–‹        | 150/880 [01:23<03:45,  3.24it/s] 17%|â–ˆâ–‹        | 151/880 [01:24<03:45,  3.24it/s] 17%|â–ˆâ–‹        | 152/880 [01:24<03:44,  3.24it/s] 17%|â–ˆâ–‹        | 153/880 [01:24<03:44,  3.24it/s] 18%|â–ˆâ–Š        | 154/880 [01:25<03:44,  3.24it/s] 18%|â–ˆâ–Š        | 155/880 [01:25<03:43,  3.24it/s] 18%|â–ˆâ–Š        | 156/880 [01:25<03:43,  3.24it/s] 18%|â–ˆâ–Š        | 157/880 [01:26<03:42,  3.24it/s] 18%|â–ˆâ–Š        | 158/880 [01:26<03:42,  3.24it/s] 18%|â–ˆâ–Š        | 159/880 [01:26<03:42,  3.23it/s] 18%|â–ˆâ–Š        | 160/880 [01:26<03:43,  3.23it/s] 18%|â–ˆâ–Š        | 161/880 [01:27<03:42,  3.23it/s] 18%|â–ˆâ–Š        | 162/880 [01:27<03:41,  3.23it/s] 19%|â–ˆâ–Š        | 163/880 [01:27<03:41,  3.23it/s] 19%|â–ˆâ–Š        | 164/880 [01:28<03:43,  3.20it/s] 19%|â–ˆâ–‰        | 165/880 [01:28<03:42,  3.21it/s] 19%|â–ˆâ–‰        | 166/880 [01:28<03:42,  3.22it/s] 19%|â–ˆâ–‰        | 167/880 [01:29<03:41,  3.23it/s] 19%|â–ˆâ–‰        | 168/880 [01:29<03:40,  3.23it/s] 19%|â–ˆâ–‰        | 169/880 [01:29<03:39,  3.23it/s] 19%|â–ˆâ–‰        | 170/880 [01:30<03:40,  3.22it/s] 19%|â–ˆâ–‰        | 171/880 [01:30<03:39,  3.23it/s] 20%|â–ˆâ–‰        | 172/880 [01:30<03:39,  3.23it/s] 20%|â–ˆâ–‰        | 173/880 [01:31<03:39,  3.23it/s] 20%|â–ˆâ–‰        | 174/880 [01:31<03:38,  3.22it/s] 20%|â–ˆâ–‰        | 175/880 [01:31<03:38,  3.23it/s] 20%|â–ˆâ–ˆ        | 176/880 [01:31<03:37,  3.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.01it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.00it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.10it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.60it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.39it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.17it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.17it/s][A 20%|â–ˆâ–ˆ        | 176/880 [01:33<03:37,  3.23it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-176
Configuration saved in sst_model/checkpoint-176/config.json
Model weights saved in sst_model/checkpoint-176/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-790] due to args.save_total_limit
 20%|â–ˆâ–ˆ        | 177/880 [01:58<1:35:51,  8.18s/it] 20%|â–ˆâ–ˆ        | 178/880 [01:58<1:08:06,  5.82s/it] 20%|â–ˆâ–ˆ        | 179/880 [01:59<48:40,  4.17s/it]   20%|â–ˆâ–ˆ        | 180/880 [01:59<35:06,  3.01s/it] 21%|â–ˆâ–ˆ        | 181/880 [01:59<25:36,  2.20s/it] 21%|â–ˆâ–ˆ        | 182/880 [02:00<18:58,  1.63s/it] 21%|â–ˆâ–ˆ        | 183/880 [02:00<14:22,  1.24s/it] 21%|â–ˆâ–ˆ        | 184/880 [02:00<11:07,  1.04it/s] 21%|â–ˆâ–ˆ        | 185/880 [02:00<08:50,  1.31it/s] 21%|â–ˆâ–ˆ        | 186/880 [02:01<07:14,  1.60it/s] 21%|â–ˆâ–ˆâ–       | 187/880 [02:01<06:08,  1.88it/s] 21%|â–ˆâ–ˆâ–       | 188/880 [02:01<05:24,  2.13it/s] 21%|â–ˆâ–ˆâ–       | 189/880 [02:02<04:50,  2.38it/s] 22%|â–ˆâ–ˆâ–       | 190/880 [02:02<04:27,  2.58it/s] 22%|â–ˆâ–ˆâ–       | 191/880 [02:02<04:10,  2.75it/s] 22%|â–ˆâ–ˆâ–       | 192/880 [02:03<04:00,  2.87it/s] 22%|â–ˆâ–ˆâ–       | 193/880 [02:03<03:51,  2.97it/s] 22%|â–ˆâ–ˆâ–       | 194/880 [02:03<03:45,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 195/880 [02:04<03:40,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 196/880 [02:04<03:37,  3.14it/s] 22%|â–ˆâ–ˆâ–       | 197/880 [02:04<03:35,  3.17it/s] 22%|â–ˆâ–ˆâ–Ž       | 198/880 [02:04<03:33,  3.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 199/880 [02:05<03:33,  3.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 200/880 [02:05<03:32,  3.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 201/880 [02:05<03:31,  3.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 202/880 [02:06<03:30,  3.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 203/880 [02:06<03:29,  3.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 204/880 [02:06<03:29,  3.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 205/880 [02:07<03:28,  3.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 206/880 [02:07<03:28,  3.23it/s] 24%|â–ˆâ–ˆâ–Ž       | 207/880 [02:07<03:28,  3.23it/s] 24%|â–ˆâ–ˆâ–Ž       | 208/880 [02:08<03:27,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 209/880 [02:08<03:27,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 210/880 [02:08<03:27,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 211/880 [02:09<03:27,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 212/880 [02:09<03:26,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 213/880 [02:09<03:26,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 214/880 [02:09<03:25,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 215/880 [02:10<03:25,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 216/880 [02:10<03:25,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 217/880 [02:10<03:24,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 218/880 [02:11<03:24,  3.23it/s] 25%|â–ˆâ–ˆâ–       | 219/880 [02:11<03:24,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 220/880 [02:11<03:23,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 221/880 [02:12<03:24,  3.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 222/880 [02:12<03:24,  3.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 223/880 [02:12<03:23,  3.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 224/880 [02:13<03:23,  3.22it/s] 26%|â–ˆâ–ˆâ–Œ       | 225/880 [02:13<03:23,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 226/880 [02:13<03:22,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 227/880 [02:13<03:22,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 228/880 [02:14<03:21,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 229/880 [02:14<03:21,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 230/880 [02:14<03:21,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 231/880 [02:15<03:21,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 232/880 [02:15<03:20,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 233/880 [02:15<03:20,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 234/880 [02:16<03:20,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 235/880 [02:16<03:20,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 236/880 [02:16<03:19,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 237/880 [02:17<03:19,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 238/880 [02:17<03:19,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 239/880 [02:17<03:18,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 240/880 [02:17<03:18,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 241/880 [02:18<03:18,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 242/880 [02:18<03:18,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 243/880 [02:18<03:17,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 244/880 [02:19<03:17,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 245/880 [02:19<03:17,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 246/880 [02:19<03:18,  3.19it/s] 28%|â–ˆâ–ˆâ–Š       | 247/880 [02:20<03:18,  3.19it/s] 28%|â–ˆâ–ˆâ–Š       | 248/880 [02:20<03:17,  3.20it/s] 28%|â–ˆâ–ˆâ–Š       | 249/880 [02:20<03:16,  3.21it/s] 28%|â–ˆâ–ˆâ–Š       | 250/880 [02:21<03:15,  3.22it/s] 29%|â–ˆâ–ˆâ–Š       | 251/880 [02:21<03:17,  3.19it/s] 29%|â–ˆâ–ˆâ–Š       | 252/880 [02:21<03:16,  3.19it/s] 29%|â–ˆâ–ˆâ–‰       | 253/880 [02:22<03:15,  3.20it/s] 29%|â–ˆâ–ˆâ–‰       | 254/880 [02:22<03:15,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 255/880 [02:22<03:14,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 256/880 [02:22<03:14,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 257/880 [02:23<03:13,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 258/880 [02:23<03:13,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 259/880 [02:23<03:13,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 260/880 [02:24<03:12,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 261/880 [02:24<03:12,  3.21it/s] 30%|â–ˆâ–ˆâ–‰       | 262/880 [02:24<03:12,  3.21it/s] 30%|â–ˆâ–ˆâ–‰       | 263/880 [02:25<03:11,  3.21it/s] 30%|â–ˆâ–ˆâ–ˆ       | 264/880 [02:25<03:13,  3.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.96it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.57it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.18it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.68it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.39it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.17it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.17it/s][A 30%|â–ˆâ–ˆâ–ˆ       | 264/880 [02:26<03:13,  3.18it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-264
Configuration saved in sst_model/checkpoint-264/config.json
Model weights saved in sst_model/checkpoint-264/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-88] due to args.save_total_limit
 30%|â–ˆâ–ˆâ–ˆ       | 265/880 [02:55<1:34:06,  9.18s/it] 30%|â–ˆâ–ˆâ–ˆ       | 266/880 [02:55<1:06:42,  6.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 267/880 [02:55<47:33,  4.66s/it]   30%|â–ˆâ–ˆâ–ˆ       | 268/880 [02:56<34:10,  3.35s/it] 31%|â–ˆâ–ˆâ–ˆ       | 269/880 [02:56<24:49,  2.44s/it] 31%|â–ˆâ–ˆâ–ˆ       | 270/880 [02:56<18:17,  1.80s/it] 31%|â–ˆâ–ˆâ–ˆ       | 271/880 [02:57<13:43,  1.35s/it] 31%|â–ˆâ–ˆâ–ˆ       | 272/880 [02:57<10:32,  1.04s/it] 31%|â–ˆâ–ˆâ–ˆ       | 273/880 [02:57<08:18,  1.22it/s] 31%|â–ˆâ–ˆâ–ˆ       | 274/880 [02:58<06:44,  1.50it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 275/880 [02:58<05:38,  1.79it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 276/880 [02:58<04:51,  2.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 277/880 [02:59<04:19,  2.32it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 278/880 [02:59<03:57,  2.54it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 279/880 [02:59<03:41,  2.71it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 280/880 [02:59<03:30,  2.86it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 281/880 [03:00<03:22,  2.96it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 282/880 [03:00<03:16,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 283/880 [03:00<03:12,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 284/880 [03:01<03:10,  3.13it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 285/880 [03:01<03:09,  3.14it/s] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 286/880 [03:01<03:07,  3.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 287/880 [03:02<03:05,  3.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 288/880 [03:02<03:04,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 289/880 [03:02<03:03,  3.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 290/880 [03:03<03:03,  3.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 291/880 [03:03<03:02,  3.23it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 292/880 [03:03<03:02,  3.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 293/880 [03:04<03:01,  3.23it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 294/880 [03:04<03:01,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 295/880 [03:04<03:01,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 296/880 [03:04<03:00,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 297/880 [03:05<03:00,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 298/880 [03:05<02:59,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 299/880 [03:05<02:59,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 300/880 [03:06<02:59,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 301/880 [03:06<02:59,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 302/880 [03:06<02:58,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 303/880 [03:07<02:58,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 304/880 [03:07<02:57,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 305/880 [03:07<02:57,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 306/880 [03:08<02:58,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 307/880 [03:08<02:57,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 308/880 [03:08<02:57,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 309/880 [03:08<02:57,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 310/880 [03:09<02:57,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 311/880 [03:09<02:56,  3.22it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 312/880 [03:09<02:56,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 313/880 [03:10<02:55,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 314/880 [03:10<02:55,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 315/880 [03:10<02:56,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 316/880 [03:11<02:56,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 317/880 [03:11<02:55,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 318/880 [03:11<02:55,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 319/880 [03:12<02:54,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 320/880 [03:12<02:54,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 321/880 [03:12<02:54,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 322/880 [03:13<02:53,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 323/880 [03:13<02:53,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 324/880 [03:13<02:52,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 325/880 [03:13<02:52,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 326/880 [03:14<02:51,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 327/880 [03:14<02:51,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 328/880 [03:14<02:50,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 329/880 [03:15<02:50,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 330/880 [03:15<02:50,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 331/880 [03:15<02:50,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 332/880 [03:16<02:50,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 333/880 [03:16<02:50,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 334/880 [03:16<02:49,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 335/880 [03:17<02:49,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 336/880 [03:17<02:49,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 337/880 [03:17<02:49,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 338/880 [03:17<02:48,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 339/880 [03:18<02:48,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 340/880 [03:18<02:48,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 341/880 [03:18<02:48,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 342/880 [03:19<02:47,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 343/880 [03:19<02:46,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 344/880 [03:19<02:46,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 345/880 [03:20<02:46,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 346/880 [03:20<02:45,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 347/880 [03:20<02:45,  3.22it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 348/880 [03:21<02:45,  3.22it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 349/880 [03:21<02:45,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 350/880 [03:21<02:45,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 351/880 [03:22<02:45,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 352/880 [03:22<02:44,  3.20it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 20.00it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.58it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.23it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.70it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.42it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.25it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.25it/s][A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 352/880 [03:23<02:44,  3.20it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-352
Configuration saved in sst_model/checkpoint-352/config.json
Model weights saved in sst_model/checkpoint-352/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-176] due to args.save_total_limit
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 353/880 [04:10<2:09:27, 14.74s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 354/880 [04:11<1:31:15, 10.41s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 355/880 [04:11<1:04:34,  7.38s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 356/880 [04:24<1:18:53,  9.03s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 357/880 [04:24<56:16,  6.46s/it]   41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358/880 [04:25<40:06,  4.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 359/880 [04:25<28:49,  3.32s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 360/880 [04:25<20:56,  2.42s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 361/880 [04:25<15:25,  1.78s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 362/880 [04:26<11:34,  1.34s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 363/880 [04:26<08:52,  1.03s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 364/880 [04:26<06:59,  1.23it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 365/880 [04:27<05:40,  1.51it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 366/880 [04:27<04:45,  1.80it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 367/880 [04:27<04:29,  1.90it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 368/880 [04:28<03:55,  2.17it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 369/880 [04:28<03:31,  2.41it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 370/880 [04:28<03:16,  2.59it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 371/880 [04:29<03:04,  2.76it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 372/880 [04:29<02:55,  2.89it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 373/880 [04:29<02:49,  2.99it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 374/880 [04:30<02:44,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 375/880 [04:30<02:41,  3.13it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 376/880 [04:30<02:39,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 377/880 [04:30<02:36,  3.21it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 378/880 [04:31<02:35,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 379/880 [04:31<02:34,  3.24it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 380/880 [04:31<02:34,  3.24it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 381/880 [04:32<02:33,  3.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 382/880 [04:32<02:33,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 383/880 [04:32<02:33,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 384/880 [04:33<02:32,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 385/880 [04:33<02:32,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 386/880 [04:33<02:32,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 387/880 [04:34<02:31,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 388/880 [04:34<02:31,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 389/880 [04:34<02:31,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 390/880 [04:34<02:30,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 391/880 [04:35<02:30,  3.24it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 392/880 [04:35<02:30,  3.24it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 393/880 [04:35<02:42,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 394/880 [04:36<02:38,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 395/880 [04:36<02:35,  3.12it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 396/880 [04:36<02:33,  3.16it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 397/880 [04:37<02:31,  3.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 398/880 [04:37<02:30,  3.20it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 399/880 [04:37<02:30,  3.20it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 400/880 [04:38<02:29,  3.20it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 401/880 [04:38<02:29,  3.21it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 402/880 [04:38<02:29,  3.21it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 403/880 [04:39<02:28,  3.21it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 404/880 [04:40<04:50,  1.64it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 405/880 [04:40<04:07,  1.92it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 406/880 [04:41<03:36,  2.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 407/880 [04:41<03:14,  2.43it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 408/880 [04:41<02:59,  2.62it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 409/880 [04:42<03:01,  2.60it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 410/880 [04:42<02:50,  2.76it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 411/880 [04:42<02:42,  2.89it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 412/880 [04:42<02:36,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 413/880 [04:43<02:32,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 414/880 [04:43<02:29,  3.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 415/880 [04:43<02:28,  3.14it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 416/880 [04:44<02:29,  3.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 417/880 [04:44<02:27,  3.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 418/880 [04:44<02:25,  3.17it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 419/880 [04:45<02:24,  3.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 420/880 [04:45<02:27,  3.12it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 421/880 [04:45<02:25,  3.16it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 422/880 [04:46<02:24,  3.18it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 423/880 [04:46<02:23,  3.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 424/880 [04:46<02:22,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 425/880 [04:47<02:21,  3.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 426/880 [04:47<02:21,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 427/880 [04:47<02:20,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 428/880 [04:47<02:19,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 429/880 [04:48<02:19,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 430/880 [04:48<02:19,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 431/880 [04:48<02:19,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 432/880 [04:49<02:18,  3.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 433/880 [04:49<02:18,  3.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 434/880 [04:49<02:17,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 435/880 [04:50<02:17,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 436/880 [04:50<02:17,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 437/880 [04:50<02:17,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 438/880 [04:51<02:16,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 439/880 [04:51<02:16,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 440/880 [04:51<02:16,  3.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.94it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.59it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.27it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.44it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.28it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.28it/s][A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 440/880 [04:52<02:16,  3.22it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-440
Configuration saved in sst_model/checkpoint-440/config.json
Model weights saved in sst_model/checkpoint-440/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-264] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 441/880 [05:06<35:03,  4.79s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 442/880 [05:07<25:09,  3.45s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 443/880 [05:07<18:14,  2.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 444/880 [05:07<13:24,  1.85s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 445/880 [05:08<10:02,  1.38s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 446/880 [05:08<07:40,  1.06s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 447/880 [05:08<06:01,  1.20it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 448/880 [05:09<04:51,  1.48it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 449/880 [05:09<04:03,  1.77it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 450/880 [05:09<03:29,  2.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 451/880 [05:09<03:06,  2.30it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 452/880 [05:10<02:50,  2.51it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 453/880 [05:10<02:42,  2.63it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 454/880 [05:10<02:32,  2.79it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 455/880 [05:11<02:26,  2.91it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 456/880 [05:11<02:21,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 457/880 [05:11<02:17,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 458/880 [05:12<02:15,  3.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 459/880 [05:12<02:13,  3.16it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 460/880 [05:12<02:11,  3.19it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 461/880 [05:13<02:10,  3.20it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 462/880 [05:13<02:09,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 463/880 [05:13<02:09,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 464/880 [05:14<02:08,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 465/880 [05:14<02:08,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 466/880 [05:14<02:08,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 467/880 [05:14<02:07,  3.24it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 468/880 [05:15<02:06,  3.25it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 469/880 [05:15<02:06,  3.26it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 470/880 [05:15<02:06,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 471/880 [05:16<02:05,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 472/880 [05:16<02:05,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473/880 [05:16<02:04,  3.26it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/880 [05:17<02:04,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 475/880 [05:17<02:04,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 476/880 [05:17<02:04,  3.26it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 477/880 [05:18<02:04,  3.24it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 478/880 [05:18<02:03,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 479/880 [05:18<02:03,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 480/880 [05:18<02:03,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 481/880 [05:19<02:03,  3.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 482/880 [05:19<02:03,  3.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 483/880 [05:19<02:03,  3.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 484/880 [05:20<02:02,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 485/880 [05:20<02:03,  3.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 486/880 [05:20<02:02,  3.21it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 487/880 [05:21<02:28,  2.64it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 488/880 [05:21<02:20,  2.79it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 489/880 [05:21<02:14,  2.91it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 490/880 [05:22<02:10,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 491/880 [05:22<02:07,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 492/880 [05:22<02:04,  3.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 493/880 [05:23<02:02,  3.16it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 494/880 [05:23<02:01,  3.18it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 495/880 [05:23<02:00,  3.18it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 496/880 [05:24<01:59,  3.21it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 497/880 [05:24<01:59,  3.21it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 498/880 [05:24<01:58,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 499/880 [05:25<01:58,  3.22it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 500/880 [05:25<01:57,  3.23it/s]                                                  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 500/880 [05:25<01:57,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 501/880 [05:25<01:57,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 502/880 [05:26<01:56,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 503/880 [05:26<01:55,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 504/880 [05:26<01:55,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 505/880 [05:26<01:55,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 506/880 [05:27<01:54,  3.26it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 507/880 [05:27<01:54,  3.26it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 508/880 [05:27<01:54,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 509/880 [05:28<01:54,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 510/880 [05:28<01:54,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 511/880 [05:28<01:54,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 512/880 [05:29<01:53,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 513/880 [05:29<01:53,  3.23it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 514/880 [05:29<01:52,  3.24it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 515/880 [05:30<01:52,  3.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 516/880 [05:30<01:52,  3.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 517/880 [05:30<01:52,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 518/880 [05:30<01:52,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 519/880 [05:31<01:52,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 520/880 [05:31<01:52,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 521/880 [05:31<01:53,  3.17it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 522/880 [05:32<01:52,  3.18it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 523/880 [05:32<01:53,  3.14it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 524/880 [05:32<01:52,  3.16it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 525/880 [05:33<01:51,  3.17it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 526/880 [05:33<01:50,  3.19it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 527/880 [05:33<01:50,  3.20it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 528/880 [05:34<01:49,  3.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.86it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.51it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.17it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.21it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s][A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 528/880 [05:35<01:49,  3.21it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-528
Configuration saved in sst_model/checkpoint-528/config.json
Model weights saved in sst_model/checkpoint-528/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-440] due to args.save_total_limit
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 529/880 [05:50<29:32,  5.05s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 530/880 [05:50<21:09,  3.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 531/880 [05:50<15:18,  2.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 532/880 [05:51<11:13,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 533/880 [05:51<08:21,  1.45s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 534/880 [05:51<06:23,  1.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 535/880 [05:52<04:59,  1.15it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 536/880 [05:52<04:00,  1.43it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 537/880 [05:52<03:19,  1.72it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 538/880 [05:52<02:51,  2.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 539/880 [05:53<02:30,  2.26it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 540/880 [05:53<02:16,  2.49it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 541/880 [05:53<02:06,  2.67it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 542/880 [05:54<01:59,  2.82it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 543/880 [05:54<01:54,  2.93it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 544/880 [05:54<01:51,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 545/880 [05:55<01:48,  3.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 546/880 [05:55<01:47,  3.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 547/880 [05:55<01:45,  3.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 548/880 [05:56<01:44,  3.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 549/880 [05:56<01:43,  3.20it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 550/880 [05:56<01:42,  3.21it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 551/880 [05:56<01:42,  3.21it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 552/880 [05:57<01:41,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 553/880 [05:57<01:41,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 554/880 [05:57<01:41,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 555/880 [05:58<01:40,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 556/880 [05:58<01:39,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 557/880 [05:58<01:39,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 558/880 [05:59<01:39,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 559/880 [05:59<01:38,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 560/880 [05:59<01:38,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 561/880 [06:00<01:38,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 562/880 [06:00<01:37,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 563/880 [06:00<01:37,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 564/880 [06:00<01:37,  3.23it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 565/880 [06:01<01:37,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 566/880 [06:01<01:36,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 567/880 [06:01<01:36,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 568/880 [06:02<01:36,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 569/880 [06:02<01:35,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 570/880 [06:02<01:35,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 571/880 [06:03<01:35,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 572/880 [06:03<01:34,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 573/880 [06:03<01:34,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 574/880 [06:04<01:34,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 575/880 [06:04<01:33,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 576/880 [06:04<01:33,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 577/880 [06:05<01:33,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 578/880 [06:05<01:33,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 579/880 [06:05<01:32,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 580/880 [06:05<01:32,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 581/880 [06:06<01:32,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 582/880 [06:06<01:32,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 583/880 [06:06<01:32,  3.23it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 584/880 [06:07<01:31,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 585/880 [06:07<01:30,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 586/880 [06:07<01:30,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 587/880 [06:08<01:30,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 588/880 [06:08<01:30,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 589/880 [06:08<01:29,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 590/880 [06:09<01:29,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 591/880 [06:09<01:29,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 592/880 [06:09<01:29,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 593/880 [06:09<01:28,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 594/880 [06:10<01:28,  3.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 595/880 [06:10<01:28,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 596/880 [06:10<01:27,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 597/880 [06:11<01:27,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 598/880 [06:11<01:27,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 599/880 [06:11<01:27,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 600/880 [06:12<01:26,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 601/880 [06:12<01:26,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 602/880 [06:12<01:26,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 603/880 [06:13<01:25,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 604/880 [06:13<01:25,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 605/880 [06:13<01:24,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 606/880 [06:13<01:24,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 607/880 [06:14<01:24,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 608/880 [06:14<01:24,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 609/880 [06:14<01:23,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 610/880 [06:15<01:23,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 611/880 [06:15<01:23,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 612/880 [06:15<01:22,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 613/880 [06:16<01:22,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 614/880 [06:16<01:22,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 615/880 [06:16<01:21,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 616/880 [06:17<01:21,  3.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.85it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.53it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.20it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.38it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.20it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.20it/s][A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 616/880 [06:18<01:21,  3.23it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-616
Configuration saved in sst_model/checkpoint-616/config.json
Model weights saved in sst_model/checkpoint-616/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-528] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 617/880 [06:32<20:55,  4.77s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 618/880 [06:32<14:59,  3.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 619/880 [06:32<10:51,  2.50s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 620/880 [06:33<07:58,  1.84s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 621/880 [06:33<05:57,  1.38s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 622/880 [06:33<04:32,  1.06s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 623/880 [06:34<03:33,  1.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 624/880 [06:34<02:52,  1.48it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 625/880 [06:34<02:23,  1.77it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 626/880 [06:35<02:04,  2.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 627/880 [06:35<01:50,  2.30it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 628/880 [06:35<01:39,  2.52it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 629/880 [06:35<01:32,  2.71it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 630/880 [06:36<01:27,  2.84it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 631/880 [06:36<01:24,  2.95it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 632/880 [06:36<01:21,  3.03it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 633/880 [06:37<01:20,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 634/880 [06:37<01:18,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 635/880 [06:37<01:17,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 636/880 [06:38<01:16,  3.20it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 637/880 [06:38<01:15,  3.22it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 638/880 [06:38<01:15,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 639/880 [06:39<01:14,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 640/880 [06:39<01:14,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 641/880 [06:39<01:13,  3.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 642/880 [06:39<01:13,  3.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 643/880 [06:40<01:13,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 644/880 [06:40<01:12,  3.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 645/880 [06:40<01:12,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 646/880 [06:41<01:12,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 647/880 [06:41<01:12,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 648/880 [06:41<01:11,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 649/880 [06:42<01:11,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 650/880 [06:42<01:11,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 651/880 [06:42<01:10,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 652/880 [06:43<01:10,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 653/880 [06:43<01:10,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 654/880 [06:43<01:09,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 655/880 [06:43<01:09,  3.23it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 656/880 [06:44<01:09,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 657/880 [06:44<01:08,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 658/880 [06:44<01:08,  3.23it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 659/880 [06:45<01:08,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 660/880 [06:45<01:07,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 661/880 [06:45<01:07,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 662/880 [06:46<01:07,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 663/880 [06:46<01:07,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 664/880 [06:46<01:06,  3.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 665/880 [06:47<01:06,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 666/880 [06:47<01:06,  3.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 667/880 [06:47<01:05,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 668/880 [06:47<01:05,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 669/880 [06:48<01:04,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 670/880 [06:48<01:04,  3.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 671/880 [06:48<01:04,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 672/880 [06:49<01:04,  3.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 673/880 [06:58<10:15,  2.97s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 674/880 [06:58<07:33,  2.20s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 675/880 [06:59<05:33,  1.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 676/880 [06:59<04:11,  1.23s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 677/880 [06:59<03:13,  1.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 678/880 [07:00<02:33,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 679/880 [07:00<02:05,  1.60it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 680/880 [07:00<01:46,  1.88it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 681/880 [07:00<01:32,  2.15it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 682/880 [07:01<01:22,  2.40it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 683/880 [07:01<01:15,  2.61it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 684/880 [07:01<01:17,  2.53it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 685/880 [07:02<01:12,  2.71it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 686/880 [07:02<01:08,  2.85it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 687/880 [07:02<01:05,  2.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 688/880 [07:03<01:03,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 689/880 [07:03<01:01,  3.09it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 690/880 [07:03<01:00,  3.14it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 691/880 [07:04<00:59,  3.16it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 692/880 [07:04<00:59,  3.18it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 693/880 [07:04<00:58,  3.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 694/880 [07:05<00:58,  3.21it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 695/880 [07:05<00:57,  3.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 696/880 [07:05<00:57,  3.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 697/880 [07:05<00:56,  3.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 698/880 [07:06<00:56,  3.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 699/880 [07:06<00:55,  3.24it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 700/880 [07:06<00:55,  3.24it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 701/880 [07:07<00:55,  3.23it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 702/880 [07:07<00:55,  3.23it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 703/880 [07:07<00:54,  3.23it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 704/880 [07:08<00:54,  3.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.96it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.58it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.25it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.26it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.26it/s][A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 704/880 [07:09<00:54,  3.21it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-704
Configuration saved in sst_model/checkpoint-704/config.json
Model weights saved in sst_model/checkpoint-704/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-616] due to args.save_total_limit
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 705/880 [07:29<19:16,  6.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 706/880 [07:29<13:40,  4.72s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 707/880 [07:30<09:47,  3.39s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 708/880 [07:30<07:04,  2.47s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 709/880 [07:30<05:11,  1.82s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 710/880 [07:30<03:52,  1.37s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 711/880 [07:31<02:57,  1.05s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 712/880 [07:31<02:18,  1.21it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 713/880 [07:31<01:51,  1.49it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 714/880 [07:32<01:33,  1.78it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 715/880 [07:32<01:20,  2.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 716/880 [07:32<01:10,  2.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 717/880 [07:33<01:04,  2.53it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 718/880 [07:33<00:59,  2.71it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 719/880 [07:33<00:56,  2.85it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 720/880 [07:34<00:54,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 721/880 [07:34<00:52,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 722/880 [07:34<00:50,  3.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 723/880 [07:34<00:49,  3.14it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 724/880 [07:35<00:49,  3.17it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 725/880 [07:35<00:48,  3.20it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 726/880 [07:35<00:47,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 727/880 [07:36<00:47,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 728/880 [07:36<00:47,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 729/880 [07:36<00:46,  3.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 730/880 [07:37<00:46,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 731/880 [07:37<00:46,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 732/880 [07:37<00:45,  3.25it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 733/880 [07:38<00:45,  3.25it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 734/880 [07:38<00:45,  3.18it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 735/880 [07:38<00:45,  3.19it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 736/880 [07:39<00:44,  3.20it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 737/880 [07:39<00:44,  3.22it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 738/880 [07:39<00:43,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 739/880 [07:39<00:43,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 740/880 [07:40<00:43,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 741/880 [07:40<00:42,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 742/880 [07:40<00:42,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 743/880 [07:41<00:42,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 744/880 [07:41<00:41,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 745/880 [07:41<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 746/880 [07:42<00:41,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 747/880 [07:42<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 748/880 [07:42<00:40,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 749/880 [07:43<00:40,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 750/880 [07:43<00:40,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 751/880 [07:43<00:39,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 752/880 [07:43<00:39,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 753/880 [07:44<00:39,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 754/880 [07:44<00:38,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 755/880 [07:44<00:38,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 756/880 [07:45<00:38,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 757/880 [07:45<00:37,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 758/880 [07:45<00:37,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 759/880 [07:46<00:37,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 760/880 [07:46<00:36,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 761/880 [07:46<00:36,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 762/880 [07:47<00:36,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 763/880 [07:47<00:36,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 764/880 [07:47<00:35,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 765/880 [07:47<00:35,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 766/880 [07:48<00:35,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 767/880 [07:48<00:34,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 768/880 [07:48<00:34,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 769/880 [07:49<00:34,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 770/880 [07:49<00:34,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 771/880 [07:49<00:33,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 772/880 [07:50<00:33,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 773/880 [07:50<00:32,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 774/880 [07:50<00:32,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 775/880 [07:51<00:32,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 776/880 [07:51<00:32,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 777/880 [07:51<00:31,  3.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 778/880 [07:51<00:31,  3.24it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 779/880 [07:52<00:31,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 780/880 [07:52<00:31,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 781/880 [07:52<00:30,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 782/880 [07:53<00:30,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 783/880 [07:53<00:30,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 784/880 [07:53<00:29,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 785/880 [07:54<00:29,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 786/880 [07:54<00:29,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 787/880 [07:54<00:29,  3.21it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 788/880 [07:55<00:28,  3.22it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 789/880 [07:55<00:28,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 790/880 [07:55<00:27,  3.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 791/880 [07:56<00:27,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 792/880 [07:56<00:27,  3.23it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.87it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.50it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.13it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.62it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.21it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s][A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 792/880 [07:57<00:27,  3.23it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-792
Configuration saved in sst_model/checkpoint-792/config.json
Model weights saved in sst_model/checkpoint-792/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-704] due to args.save_total_limit
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 793/880 [08:21<11:15,  7.77s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 794/880 [08:21<07:55,  5.53s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 795/880 [08:22<05:36,  3.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 796/880 [08:22<04:00,  2.87s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 797/880 [08:22<02:54,  2.10s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 798/880 [08:23<02:07,  1.56s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 799/880 [08:23<01:36,  1.19s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 800/880 [08:23<01:13,  1.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 801/880 [08:23<00:58,  1.35it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 802/880 [08:24<00:47,  1.64it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 803/880 [08:24<00:39,  1.93it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 804/880 [08:24<00:34,  2.20it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 805/880 [08:25<00:30,  2.44it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 806/880 [08:25<00:28,  2.64it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 807/880 [08:25<00:26,  2.79it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 808/880 [08:26<00:24,  2.91it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 809/880 [08:26<00:23,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 810/880 [08:26<00:22,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 811/880 [08:27<00:22,  3.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 812/880 [08:27<00:21,  3.17it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 813/880 [08:27<00:21,  3.19it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 814/880 [08:27<00:20,  3.21it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 815/880 [08:28<00:20,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 816/880 [08:28<00:19,  3.20it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 817/880 [08:28<00:19,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 818/880 [08:29<00:19,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 819/880 [08:29<00:18,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 820/880 [08:29<00:18,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 821/880 [08:30<00:18,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 822/880 [08:30<00:17,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 823/880 [08:30<00:17,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 824/880 [08:31<00:17,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 825/880 [08:31<00:16,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 826/880 [08:31<00:16,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 827/880 [08:31<00:16,  3.21it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 828/880 [08:32<00:16,  3.23it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 829/880 [08:32<00:15,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 830/880 [08:32<00:15,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 831/880 [08:33<00:15,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 832/880 [08:33<00:14,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 833/880 [08:33<00:14,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 834/880 [08:34<00:14,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 835/880 [08:34<00:13,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 836/880 [08:34<00:13,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 837/880 [08:35<00:13,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 838/880 [08:35<00:12,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 839/880 [08:35<00:12,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 840/880 [08:35<00:12,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 841/880 [08:36<00:11,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 842/880 [08:36<00:11,  3.22it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 843/880 [08:36<00:11,  3.22it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 844/880 [08:37<00:11,  3.22it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 845/880 [08:37<00:10,  3.21it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 846/880 [08:37<00:10,  3.16it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 847/880 [08:38<00:10,  3.17it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 848/880 [08:38<00:10,  3.19it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 849/880 [08:38<00:09,  3.20it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 850/880 [08:39<00:09,  3.22it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 851/880 [08:39<00:09,  3.21it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 852/880 [08:39<00:08,  3.21it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 853/880 [08:40<00:08,  3.22it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 854/880 [08:40<00:08,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 855/880 [08:40<00:07,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 856/880 [08:40<00:07,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 857/880 [08:41<00:07,  3.24it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 858/880 [08:41<00:06,  3.24it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 859/880 [08:41<00:06,  3.24it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 860/880 [08:42<00:06,  3.25it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 861/880 [08:42<00:05,  3.24it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 862/880 [08:42<00:05,  3.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 863/880 [08:43<00:05,  3.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 864/880 [08:43<00:04,  3.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 865/880 [08:43<00:04,  3.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 866/880 [08:44<00:04,  3.24it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 867/880 [08:44<00:04,  3.24it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 868/880 [08:44<00:03,  3.20it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 869/880 [08:44<00:03,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 870/880 [08:45<00:03,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 871/880 [08:45<00:02,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 872/880 [08:45<00:02,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 873/880 [08:46<00:02,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 874/880 [08:46<00:01,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 875/880 [08:46<00:01,  3.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 876/880 [08:47<00:01,  3.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 877/880 [08:47<00:00,  3.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 878/880 [08:47<00:00,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 879/880 [08:48<00:00,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880/880 [08:48<00:00,  3.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.84it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.49it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.17it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.39it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.24it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.24it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880/880 [08:49<00:00,  3.21it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-880
Configuration saved in sst_model/checkpoint-880/config.json
Model weights saved in sst_model/checkpoint-880/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-792] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from sst_model/checkpoint-352 (score: 0.69).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880/880 [09:30<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880/880 [09:30<00:00,  1.54it/s]
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Using custom data configuration default-c75dde8cee8d8fa9
0 tables [00:00, ? tables/s]                            loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.73ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.72ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-35bfd9f04e6658c3.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-04edea8e5deaac23.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.71ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.71ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-80dea3fb3755f005.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1f098d744ad3e451.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.93ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.93ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-523194a38c7f88f6.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-487f6c90d30222c9.arrow
PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running training *****
  Num examples = 550
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 690
  0%|          | 0/690 [00:00<?, ?it/s]  0%|          | 1/690 [00:00<04:56,  2.32it/s]  0%|          | 2/690 [00:00<04:04,  2.82it/s]  0%|          | 3/690 [00:01<03:46,  3.03it/s]  1%|          | 4/690 [00:01<03:39,  3.13it/s]  1%|          | 5/690 [00:01<03:34,  3.19it/s]  1%|          | 6/690 [00:01<03:35,  3.18it/s]  1%|          | 7/690 [00:02<03:32,  3.22it/s]  1%|          | 8/690 [00:02<03:30,  3.24it/s]  1%|â–         | 9/690 [00:02<03:28,  3.26it/s]  1%|â–         | 10/690 [00:03<03:27,  3.27it/s]  2%|â–         | 11/690 [00:03<03:27,  3.28it/s]  2%|â–         | 12/690 [00:03<03:26,  3.28it/s]  2%|â–         | 13/690 [00:04<03:27,  3.27it/s]  2%|â–         | 14/690 [00:04<03:26,  3.27it/s]  2%|â–         | 15/690 [00:04<03:26,  3.27it/s]  2%|â–         | 16/690 [00:04<03:25,  3.28it/s]  2%|â–         | 17/690 [00:05<03:25,  3.28it/s]  3%|â–Ž         | 18/690 [00:05<03:24,  3.29it/s]  3%|â–Ž         | 19/690 [00:05<03:24,  3.29it/s]  3%|â–Ž         | 20/690 [00:06<03:23,  3.29it/s]  3%|â–Ž         | 21/690 [00:06<03:23,  3.29it/s]  3%|â–Ž         | 22/690 [00:06<03:23,  3.29it/s]  3%|â–Ž         | 23/690 [00:07<03:22,  3.29it/s]  3%|â–Ž         | 24/690 [00:07<03:23,  3.28it/s]  4%|â–Ž         | 25/690 [00:07<03:22,  3.28it/s]  4%|â–         | 26/690 [00:08<03:22,  3.28it/s]  4%|â–         | 27/690 [00:08<03:22,  3.28it/s]  4%|â–         | 28/690 [00:08<03:22,  3.27it/s]  4%|â–         | 29/690 [00:08<03:21,  3.27it/s]  4%|â–         | 30/690 [00:09<03:21,  3.28it/s]  4%|â–         | 31/690 [00:09<03:21,  3.28it/s]  5%|â–         | 32/690 [00:09<03:20,  3.28it/s]  5%|â–         | 33/690 [00:10<03:20,  3.28it/s]  5%|â–         | 34/690 [00:10<03:20,  3.28it/s]  5%|â–Œ         | 35/690 [00:10<03:19,  3.28it/s]  5%|â–Œ         | 36/690 [00:11<03:19,  3.28it/s]  5%|â–Œ         | 37/690 [00:11<03:19,  3.28it/s]  6%|â–Œ         | 38/690 [00:11<03:19,  3.27it/s]  6%|â–Œ         | 39/690 [00:12<03:18,  3.28it/s]  6%|â–Œ         | 40/690 [00:12<03:18,  3.28it/s]  6%|â–Œ         | 41/690 [00:12<03:18,  3.28it/s]  6%|â–Œ         | 42/690 [00:12<03:17,  3.27it/s]  6%|â–Œ         | 43/690 [00:13<03:17,  3.27it/s]  6%|â–‹         | 44/690 [00:13<03:17,  3.27it/s]  7%|â–‹         | 45/690 [00:13<03:17,  3.27it/s]  7%|â–‹         | 46/690 [00:14<03:16,  3.27it/s]  7%|â–‹         | 47/690 [00:14<03:16,  3.27it/s]  7%|â–‹         | 48/690 [00:14<03:17,  3.24it/s]  7%|â–‹         | 49/690 [00:15<03:17,  3.25it/s]  7%|â–‹         | 50/690 [00:15<03:16,  3.25it/s]  7%|â–‹         | 51/690 [00:15<03:15,  3.26it/s]  8%|â–Š         | 52/690 [00:15<03:15,  3.26it/s]  8%|â–Š         | 53/690 [00:16<03:17,  3.23it/s]  8%|â–Š         | 54/690 [00:16<03:16,  3.24it/s]  8%|â–Š         | 55/690 [00:16<03:15,  3.25it/s]  8%|â–Š         | 56/690 [00:17<03:14,  3.26it/s]  8%|â–Š         | 57/690 [00:17<03:14,  3.26it/s]  8%|â–Š         | 58/690 [00:17<03:16,  3.22it/s]  9%|â–Š         | 59/690 [00:18<03:14,  3.24it/s]  9%|â–Š         | 60/690 [00:18<03:14,  3.24it/s]  9%|â–‰         | 61/690 [00:18<03:14,  3.24it/s]  9%|â–‰         | 62/690 [00:19<03:13,  3.24it/s]  9%|â–‰         | 63/690 [00:19<03:13,  3.25it/s]  9%|â–‰         | 64/690 [00:19<03:12,  3.25it/s]  9%|â–‰         | 65/690 [00:20<03:12,  3.25it/s] 10%|â–‰         | 66/690 [00:20<03:12,  3.25it/s] 10%|â–‰         | 67/690 [00:20<03:12,  3.24it/s] 10%|â–‰         | 68/690 [00:20<03:16,  3.16it/s] 10%|â–ˆ         | 69/690 [00:21<03:08,  3.29it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 18.79it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.20it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.04it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.64it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.45it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.33it/s][A
                                               [A                                                
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.33it/s][A 10%|â–ˆ         | 69/690 [00:22<03:08,  3.29it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-69
Configuration saved in sst_model/checkpoint-69/config.json
Model weights saved in sst_model/checkpoint-69/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-352] due to args.save_total_limit
 10%|â–ˆ         | 70/690 [01:30<3:36:40, 20.97s/it] 10%|â–ˆ         | 71/690 [01:30<2:32:22, 14.77s/it] 10%|â–ˆ         | 72/690 [01:31<1:47:25, 10.43s/it] 11%|â–ˆ         | 73/690 [01:31<1:16:01,  7.39s/it] 11%|â–ˆ         | 74/690 [01:31<54:04,  5.27s/it]   11%|â–ˆ         | 75/690 [01:31<38:43,  3.78s/it] 11%|â–ˆ         | 76/690 [01:32<27:59,  2.74s/it] 11%|â–ˆ         | 77/690 [01:32<20:32,  2.01s/it] 11%|â–ˆâ–        | 78/690 [01:32<15:17,  1.50s/it] 11%|â–ˆâ–        | 79/690 [01:33<11:37,  1.14s/it] 12%|â–ˆâ–        | 80/690 [01:33<09:03,  1.12it/s] 12%|â–ˆâ–        | 81/690 [01:33<07:16,  1.40it/s] 12%|â–ˆâ–        | 82/690 [01:34<06:00,  1.69it/s] 12%|â–ˆâ–        | 83/690 [01:34<05:07,  1.97it/s] 12%|â–ˆâ–        | 84/690 [01:34<04:30,  2.24it/s] 12%|â–ˆâ–        | 85/690 [01:35<04:04,  2.48it/s] 12%|â–ˆâ–        | 86/690 [01:35<03:45,  2.68it/s] 13%|â–ˆâ–Ž        | 87/690 [01:35<03:34,  2.81it/s] 13%|â–ˆâ–Ž        | 88/690 [01:35<03:25,  2.93it/s] 13%|â–ˆâ–Ž        | 89/690 [01:36<03:18,  3.02it/s] 13%|â–ˆâ–Ž        | 90/690 [01:36<03:14,  3.09it/s] 13%|â–ˆâ–Ž        | 91/690 [01:36<03:10,  3.15it/s] 13%|â–ˆâ–Ž        | 92/690 [01:37<03:08,  3.18it/s] 13%|â–ˆâ–Ž        | 93/690 [01:37<03:06,  3.21it/s] 14%|â–ˆâ–Ž        | 94/690 [01:37<03:04,  3.22it/s] 14%|â–ˆâ–        | 95/690 [01:38<03:03,  3.24it/s] 14%|â–ˆâ–        | 96/690 [01:38<03:02,  3.25it/s] 14%|â–ˆâ–        | 97/690 [01:38<03:02,  3.25it/s] 14%|â–ˆâ–        | 98/690 [01:39<03:02,  3.25it/s] 14%|â–ˆâ–        | 99/690 [01:39<03:01,  3.26it/s] 14%|â–ˆâ–        | 100/690 [01:39<03:01,  3.26it/s] 15%|â–ˆâ–        | 101/690 [01:39<03:00,  3.26it/s] 15%|â–ˆâ–        | 102/690 [01:40<03:02,  3.23it/s] 15%|â–ˆâ–        | 103/690 [01:40<03:01,  3.23it/s] 15%|â–ˆâ–Œ        | 104/690 [01:40<03:00,  3.25it/s] 15%|â–ˆâ–Œ        | 105/690 [01:41<02:59,  3.25it/s] 15%|â–ˆâ–Œ        | 106/690 [01:41<02:59,  3.25it/s] 16%|â–ˆâ–Œ        | 107/690 [01:41<03:00,  3.23it/s] 16%|â–ˆâ–Œ        | 108/690 [01:42<02:59,  3.24it/s] 16%|â–ˆâ–Œ        | 109/690 [01:42<02:58,  3.25it/s] 16%|â–ˆâ–Œ        | 110/690 [01:42<02:58,  3.25it/s] 16%|â–ˆâ–Œ        | 111/690 [01:43<02:57,  3.26it/s] 16%|â–ˆâ–Œ        | 112/690 [01:43<02:57,  3.25it/s] 16%|â–ˆâ–‹        | 113/690 [01:43<02:57,  3.25it/s] 17%|â–ˆâ–‹        | 114/690 [01:43<02:57,  3.25it/s] 17%|â–ˆâ–‹        | 115/690 [01:44<02:58,  3.21it/s] 17%|â–ˆâ–‹        | 116/690 [01:44<02:59,  3.20it/s] 17%|â–ˆâ–‹        | 117/690 [01:44<02:58,  3.21it/s] 17%|â–ˆâ–‹        | 118/690 [01:45<02:57,  3.23it/s] 17%|â–ˆâ–‹        | 119/690 [01:45<02:56,  3.24it/s] 17%|â–ˆâ–‹        | 120/690 [01:45<02:55,  3.24it/s] 18%|â–ˆâ–Š        | 121/690 [01:46<02:55,  3.24it/s] 18%|â–ˆâ–Š        | 122/690 [01:46<02:55,  3.24it/s] 18%|â–ˆâ–Š        | 123/690 [01:46<02:54,  3.24it/s] 18%|â–ˆâ–Š        | 124/690 [01:47<02:54,  3.25it/s] 18%|â–ˆâ–Š        | 125/690 [01:47<02:54,  3.25it/s] 18%|â–ˆâ–Š        | 126/690 [01:47<02:53,  3.25it/s] 18%|â–ˆâ–Š        | 127/690 [01:47<02:53,  3.25it/s] 19%|â–ˆâ–Š        | 128/690 [01:48<02:53,  3.25it/s] 19%|â–ˆâ–Š        | 129/690 [01:48<02:52,  3.25it/s] 19%|â–ˆâ–‰        | 130/690 [01:48<02:52,  3.25it/s] 19%|â–ˆâ–‰        | 131/690 [01:49<02:52,  3.24it/s] 19%|â–ˆâ–‰        | 132/690 [01:49<02:52,  3.24it/s] 19%|â–ˆâ–‰        | 133/690 [01:49<02:51,  3.24it/s] 19%|â–ˆâ–‰        | 134/690 [01:50<02:51,  3.24it/s] 20%|â–ˆâ–‰        | 135/690 [01:50<02:51,  3.23it/s] 20%|â–ˆâ–‰        | 136/690 [01:50<02:51,  3.23it/s] 20%|â–ˆâ–‰        | 137/690 [01:51<02:50,  3.23it/s] 20%|â–ˆâ–ˆ        | 138/690 [01:51<02:40,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.13it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.14it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.18it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.73it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.47it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.23it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.23it/s][A 20%|â–ˆâ–ˆ        | 138/690 [01:52<02:40,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-138
Configuration saved in sst_model/checkpoint-138/config.json
Model weights saved in sst_model/checkpoint-138/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-880] due to args.save_total_limit
 20%|â–ˆâ–ˆ        | 139/690 [02:25<1:36:38, 10.52s/it] 20%|â–ˆâ–ˆ        | 140/690 [02:25<1:08:22,  7.46s/it] 20%|â–ˆâ–ˆ        | 141/690 [02:26<48:36,  5.31s/it]   21%|â–ˆâ–ˆ        | 142/690 [02:26<34:48,  3.81s/it] 21%|â–ˆâ–ˆ        | 143/690 [02:26<25:09,  2.76s/it] 21%|â–ˆâ–ˆ        | 144/690 [02:27<18:25,  2.02s/it] 21%|â–ˆâ–ˆ        | 145/690 [02:27<13:42,  1.51s/it] 21%|â–ˆâ–ˆ        | 146/690 [02:27<10:24,  1.15s/it] 21%|â–ˆâ–ˆâ–       | 147/690 [02:28<08:06,  1.12it/s] 21%|â–ˆâ–ˆâ–       | 148/690 [02:28<06:30,  1.39it/s] 22%|â–ˆâ–ˆâ–       | 149/690 [02:28<05:22,  1.68it/s] 22%|â–ˆâ–ˆâ–       | 150/690 [02:29<04:35,  1.96it/s] 22%|â–ˆâ–ˆâ–       | 151/690 [02:29<04:02,  2.23it/s] 22%|â–ˆâ–ˆâ–       | 152/690 [02:29<03:39,  2.46it/s] 22%|â–ˆâ–ˆâ–       | 153/690 [02:29<03:22,  2.65it/s] 22%|â–ˆâ–ˆâ–       | 154/690 [02:30<03:13,  2.77it/s] 22%|â–ˆâ–ˆâ–       | 155/690 [02:30<03:04,  2.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 156/690 [02:30<02:58,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 157/690 [02:31<02:54,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 158/690 [02:31<02:50,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 159/690 [02:31<02:49,  3.14it/s] 23%|â–ˆâ–ˆâ–Ž       | 160/690 [02:32<02:47,  3.17it/s] 23%|â–ˆâ–ˆâ–Ž       | 161/690 [02:32<02:46,  3.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 162/690 [02:32<02:45,  3.20it/s] 24%|â–ˆâ–ˆâ–Ž       | 163/690 [02:33<02:44,  3.21it/s] 24%|â–ˆâ–ˆâ–       | 164/690 [02:33<02:43,  3.22it/s] 24%|â–ˆâ–ˆâ–       | 165/690 [02:33<02:42,  3.22it/s] 24%|â–ˆâ–ˆâ–       | 166/690 [02:34<02:42,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 167/690 [02:34<02:41,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 168/690 [02:34<02:41,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 169/690 [02:34<02:40,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 170/690 [02:35<02:41,  3.23it/s] 25%|â–ˆâ–ˆâ–       | 171/690 [02:35<02:40,  3.23it/s] 25%|â–ˆâ–ˆâ–       | 172/690 [02:35<02:40,  3.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 173/690 [02:36<02:39,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 174/690 [02:36<02:39,  3.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 175/690 [02:36<02:39,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 176/690 [02:37<02:39,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 177/690 [02:37<02:38,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 178/690 [02:37<02:38,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 179/690 [02:38<02:38,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 180/690 [02:38<02:37,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 181/690 [02:38<02:37,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 182/690 [02:38<02:37,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 183/690 [02:39<02:36,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 184/690 [02:39<02:36,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 185/690 [02:39<02:36,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 186/690 [02:40<02:36,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 187/690 [02:40<02:35,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 188/690 [02:40<02:35,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 189/690 [02:41<02:35,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 190/690 [02:41<02:34,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 191/690 [02:41<02:34,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 192/690 [02:42<02:34,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 193/690 [02:42<02:34,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 194/690 [02:42<02:34,  3.21it/s] 28%|â–ˆâ–ˆâ–Š       | 195/690 [02:43<02:33,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 196/690 [02:43<02:33,  3.22it/s] 29%|â–ˆâ–ˆâ–Š       | 197/690 [02:43<02:32,  3.22it/s] 29%|â–ˆâ–ˆâ–Š       | 198/690 [02:43<02:33,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 199/690 [02:44<02:32,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 200/690 [02:44<02:32,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 201/690 [02:44<02:31,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 202/690 [02:45<02:31,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 203/690 [02:45<02:31,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 204/690 [02:45<02:30,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 205/690 [02:46<02:30,  3.22it/s] 30%|â–ˆâ–ˆâ–‰       | 206/690 [02:46<02:30,  3.22it/s] 30%|â–ˆâ–ˆâ–ˆ       | 207/690 [02:46<02:21,  3.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.00it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.06it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.12it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.67it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.43it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.20it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.20it/s][A 30%|â–ˆâ–ˆâ–ˆ       | 207/690 [02:47<02:21,  3.42it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-207
Configuration saved in sst_model/checkpoint-207/config.json
Model weights saved in sst_model/checkpoint-207/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-69] due to args.save_total_limit
 30%|â–ˆâ–ˆâ–ˆ       | 208/690 [03:25<1:35:54, 11.94s/it] 30%|â–ˆâ–ˆâ–ˆ       | 209/690 [03:26<1:07:44,  8.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 210/690 [03:26<48:03,  6.01s/it]   31%|â–ˆâ–ˆâ–ˆ       | 211/690 [03:26<34:18,  4.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 212/690 [03:27<24:44,  3.10s/it] 31%|â–ˆâ–ˆâ–ˆ       | 213/690 [03:27<18:01,  2.27s/it] 31%|â–ˆâ–ˆâ–ˆ       | 214/690 [03:27<13:18,  1.68s/it] 31%|â–ˆâ–ˆâ–ˆ       | 215/690 [03:27<10:01,  1.27s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 216/690 [03:28<07:43,  1.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 217/690 [03:28<06:07,  1.29it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 218/690 [03:28<05:00,  1.57it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 219/690 [03:29<04:13,  1.86it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 220/690 [03:29<03:39,  2.14it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 221/690 [03:29<03:16,  2.39it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 222/690 [03:30<03:00,  2.59it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 223/690 [03:30<02:49,  2.76it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 224/690 [03:30<02:41,  2.89it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 225/690 [03:31<02:35,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 226/690 [03:31<02:31,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 227/690 [03:31<02:28,  3.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 228/690 [03:31<02:26,  3.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 229/690 [03:32<02:24,  3.18it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 230/690 [03:32<02:23,  3.20it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 231/690 [03:32<02:23,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 232/690 [03:33<02:22,  3.21it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 233/690 [03:33<02:21,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 234/690 [03:33<02:21,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 235/690 [03:34<02:20,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 236/690 [03:34<02:20,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 237/690 [03:34<02:19,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 238/690 [03:35<02:19,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 239/690 [03:35<02:19,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 240/690 [03:35<02:18,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 241/690 [03:35<02:18,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 242/690 [03:36<02:18,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 243/690 [03:36<02:17,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 244/690 [03:36<02:17,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 245/690 [03:37<02:16,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 246/690 [03:37<02:16,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 247/690 [03:37<02:17,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 248/690 [03:38<02:16,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 249/690 [03:38<02:16,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 250/690 [03:38<02:16,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 251/690 [03:39<02:15,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 252/690 [03:39<02:15,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 253/690 [03:39<02:15,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 254/690 [03:39<02:14,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 255/690 [03:40<02:14,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 256/690 [03:40<02:14,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 257/690 [03:40<02:13,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 258/690 [03:41<02:13,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 259/690 [03:41<02:13,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 260/690 [03:41<02:12,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 261/690 [03:42<02:12,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 262/690 [03:42<02:12,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 263/690 [03:42<02:12,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 264/690 [03:43<02:11,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 265/690 [03:43<02:11,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 266/690 [03:43<02:11,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 267/690 [03:44<02:10,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 268/690 [03:44<02:10,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 269/690 [03:44<02:10,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 270/690 [03:44<02:10,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 271/690 [03:45<02:09,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 272/690 [03:45<02:09,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 273/690 [03:45<02:08,  3.24it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 274/690 [03:46<02:08,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 275/690 [03:46<02:08,  3.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 276/690 [03:46<02:00,  3.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.97it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.57it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.24it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.44it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.29it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.29it/s][A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 276/690 [03:47<02:00,  3.43it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-276
Configuration saved in sst_model/checkpoint-276/config.json
Model weights saved in sst_model/checkpoint-276/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-207] due to args.save_total_limit
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 277/690 [04:17<1:05:25,  9.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 278/690 [04:18<46:18,  6.74s/it]   40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 279/690 [04:19<35:51,  5.23s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 280/690 [04:20<25:40,  3.76s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 281/690 [04:20<18:33,  2.72s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 282/690 [04:20<13:34,  2.00s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 283/690 [04:20<10:06,  1.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 284/690 [04:21<07:57,  1.18s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 285/690 [04:21<06:10,  1.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 286/690 [04:22<04:55,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 287/690 [04:22<04:03,  1.66it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 288/690 [04:22<03:26,  1.95it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 289/690 [04:22<03:00,  2.22it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 290/690 [04:23<02:43,  2.45it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 291/690 [04:23<02:30,  2.65it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 292/690 [04:23<02:22,  2.80it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 293/690 [04:24<02:15,  2.93it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 294/690 [04:24<02:20,  2.81it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 295/690 [04:24<02:14,  2.93it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 296/690 [04:25<02:10,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 297/690 [04:25<02:07,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 298/690 [04:25<02:04,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 299/690 [04:26<02:03,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 300/690 [04:26<02:02,  3.20it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 301/690 [04:26<02:01,  3.20it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 302/690 [04:27<02:00,  3.22it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 303/690 [04:27<01:59,  3.23it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 304/690 [04:27<01:59,  3.23it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 305/690 [04:27<01:58,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 306/690 [04:28<01:58,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 307/690 [04:28<01:57,  3.27it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 308/690 [04:28<01:56,  3.27it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 309/690 [04:29<01:56,  3.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/690 [04:29<01:56,  3.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 311/690 [04:29<01:56,  3.25it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 312/690 [04:30<01:56,  3.25it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 313/690 [04:30<01:55,  3.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 314/690 [04:31<02:49,  2.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 315/690 [04:31<02:32,  2.46it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 316/690 [04:31<02:21,  2.64it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 317/690 [04:32<02:12,  2.81it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 318/690 [04:32<02:07,  2.92it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 319/690 [04:32<02:03,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 320/690 [04:33<02:00,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 321/690 [04:33<01:58,  3.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 322/690 [04:33<01:56,  3.15it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 323/690 [04:33<01:55,  3.18it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 324/690 [04:34<01:54,  3.20it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 325/690 [04:34<01:53,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 326/690 [04:34<01:53,  3.21it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 327/690 [04:35<01:52,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 328/690 [04:35<01:52,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 329/690 [04:35<01:51,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 330/690 [04:36<01:51,  3.24it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 331/690 [04:36<01:50,  3.25it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 332/690 [04:36<01:50,  3.25it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 333/690 [04:37<01:50,  3.24it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 334/690 [04:37<01:50,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 335/690 [04:37<01:49,  3.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 336/690 [04:37<01:49,  3.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 337/690 [04:38<01:49,  3.24it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 338/690 [04:38<01:49,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 339/690 [04:38<01:48,  3.22it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 340/690 [04:39<01:48,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 341/690 [04:39<01:47,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 342/690 [04:39<01:47,  3.22it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 343/690 [04:40<01:47,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 344/690 [04:40<01:46,  3.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 345/690 [04:40<01:39,  3.45it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.95it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.60it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.27it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.75it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.47it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.30it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.30it/s][A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 345/690 [04:41<01:39,  3.45it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-345
Configuration saved in sst_model/checkpoint-345/config.json
Model weights saved in sst_model/checkpoint-345/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-276] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 346/690 [05:30<1:27:30, 15.26s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 347/690 [05:31<1:01:35, 10.78s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 348/690 [05:31<43:30,  7.63s/it]   51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 349/690 [05:31<30:53,  5.43s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 350/690 [05:32<22:04,  3.89s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 351/690 [05:32<15:55,  2.82s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 352/690 [05:32<11:37,  2.06s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 353/690 [05:33<08:37,  1.54s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 354/690 [05:33<06:32,  1.17s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 355/690 [05:33<05:03,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 356/690 [05:33<04:02,  1.38it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 357/690 [05:34<03:19,  1.67it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 358/690 [05:34<02:49,  1.96it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 359/690 [05:34<02:28,  2.23it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 360/690 [05:35<02:13,  2.47it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 361/690 [05:35<02:03,  2.67it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 362/690 [05:35<01:55,  2.83it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 363/690 [05:36<01:50,  2.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 364/690 [05:36<01:46,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 365/690 [05:36<01:44,  3.12it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 366/690 [05:36<01:42,  3.17it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 367/690 [05:37<01:40,  3.21it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 368/690 [05:37<01:39,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 369/690 [05:37<01:38,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 370/690 [05:38<01:38,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 371/690 [05:38<01:37,  3.27it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 372/690 [05:38<01:37,  3.27it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 373/690 [05:39<01:36,  3.28it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 374/690 [05:39<01:36,  3.29it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 375/690 [05:39<01:35,  3.29it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 376/690 [05:39<01:35,  3.30it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 377/690 [05:40<01:35,  3.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 378/690 [05:40<01:35,  3.28it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 379/690 [05:40<01:34,  3.28it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 380/690 [05:41<01:34,  3.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 381/690 [05:41<01:33,  3.29it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 382/690 [05:41<01:33,  3.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 383/690 [05:42<01:33,  3.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 384/690 [05:42<01:32,  3.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 385/690 [05:42<01:32,  3.29it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 386/690 [05:43<01:32,  3.28it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 387/690 [05:43<01:32,  3.28it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 388/690 [05:43<01:32,  3.27it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 389/690 [05:43<01:31,  3.28it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 390/690 [05:44<01:31,  3.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 391/690 [05:44<01:30,  3.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 392/690 [05:44<01:30,  3.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 393/690 [05:45<01:30,  3.30it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 394/690 [05:45<01:29,  3.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 395/690 [05:45<01:29,  3.29it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 396/690 [05:46<01:29,  3.29it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 397/690 [05:46<01:29,  3.29it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 398/690 [05:46<01:29,  3.28it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 399/690 [05:46<01:29,  3.27it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 400/690 [05:47<01:29,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 401/690 [05:47<01:28,  3.26it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 402/690 [05:47<01:28,  3.27it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 403/690 [05:48<01:27,  3.27it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 404/690 [05:48<01:27,  3.28it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 405/690 [05:48<01:27,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 406/690 [05:49<01:27,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 407/690 [05:49<01:26,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 408/690 [05:49<01:26,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 409/690 [05:50<01:26,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 410/690 [05:50<01:26,  3.25it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 411/690 [05:50<01:25,  3.26it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 412/690 [05:50<01:25,  3.27it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 413/690 [05:51<01:24,  3.27it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 414/690 [05:51<01:19,  3.48it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.10it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.11it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.14it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.69it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.44it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 414/690 [05:52<01:19,  3.48it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-414
Configuration saved in sst_model/checkpoint-414/config.json
Model weights saved in sst_model/checkpoint-414/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-138] due to args.save_total_limit
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 415/690 [06:57<1:32:07, 20.10s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 416/690 [06:58<1:04:39, 14.16s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 417/690 [06:58<45:30, 10.00s/it]   61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 418/690 [06:58<32:08,  7.09s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 419/690 [06:59<22:49,  5.05s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 420/690 [06:59<16:19,  3.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 421/690 [06:59<11:47,  2.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 422/690 [06:59<08:37,  1.93s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 423/690 [07:00<06:25,  1.44s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 424/690 [07:00<04:52,  1.10s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 425/690 [07:00<03:48,  1.16it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 426/690 [07:01<03:03,  1.44it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 427/690 [07:01<02:31,  1.73it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 428/690 [07:01<02:09,  2.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 429/690 [07:02<01:53,  2.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 430/690 [07:02<01:42,  2.52it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 431/690 [07:02<01:35,  2.71it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 432/690 [07:02<01:29,  2.87it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 433/690 [07:03<01:26,  2.99it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 434/690 [07:03<01:23,  3.07it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 435/690 [07:03<01:21,  3.13it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 436/690 [07:04<01:19,  3.18it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 437/690 [07:04<01:18,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 438/690 [07:04<01:17,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 439/690 [07:05<01:16,  3.27it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 440/690 [07:05<01:16,  3.28it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 441/690 [07:05<01:15,  3.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 442/690 [07:06<01:15,  3.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 443/690 [07:06<01:15,  3.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 444/690 [07:06<01:14,  3.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 445/690 [07:06<01:14,  3.28it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 446/690 [07:07<01:14,  3.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 447/690 [07:07<01:13,  3.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 448/690 [07:07<01:13,  3.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 449/690 [07:08<01:13,  3.30it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 450/690 [07:08<01:13,  3.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 451/690 [07:08<01:12,  3.28it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 452/690 [07:09<01:12,  3.28it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 453/690 [07:09<01:11,  3.29it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 454/690 [07:09<01:11,  3.30it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 455/690 [07:09<01:11,  3.29it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 456/690 [07:10<01:10,  3.30it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 457/690 [07:10<01:10,  3.30it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 458/690 [07:10<01:10,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 459/690 [07:11<01:10,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 460/690 [07:11<01:09,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 461/690 [07:11<01:09,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 462/690 [07:12<01:09,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 463/690 [07:12<01:08,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 464/690 [07:12<01:08,  3.30it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 465/690 [07:13<01:08,  3.29it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 466/690 [07:13<01:08,  3.29it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 467/690 [07:13<01:07,  3.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 468/690 [07:13<01:07,  3.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 469/690 [07:14<01:06,  3.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 470/690 [07:14<01:06,  3.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 471/690 [07:14<01:06,  3.30it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 472/690 [07:15<01:06,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 473/690 [07:15<01:06,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 474/690 [07:15<01:05,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 475/690 [07:16<01:05,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 476/690 [07:16<01:05,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 477/690 [07:16<01:04,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 478/690 [07:16<01:04,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 479/690 [07:17<01:05,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 480/690 [07:17<01:04,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 481/690 [07:17<01:04,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 482/690 [07:18<01:03,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 483/690 [07:21<04:05,  1.18s/it]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.20it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.23it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.24it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.79it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.54it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.29it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.29it/s][A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 483/690 [07:23<04:05,  1.18s/it]
                                               [ASaving model checkpoint to sst_model/checkpoint-483
Configuration saved in sst_model/checkpoint-483/config.json
Model weights saved in sst_model/checkpoint-483/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-345] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 484/690 [07:37<19:22,  5.64s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 485/690 [07:37<13:48,  4.04s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 486/690 [07:38<09:55,  2.92s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 487/690 [07:38<07:13,  2.13s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 488/690 [07:38<05:19,  1.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 489/690 [07:38<04:01,  1.20s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 490/690 [07:39<03:06,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 491/690 [07:39<02:28,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 492/690 [07:39<02:01,  1.63it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 493/690 [07:40<01:42,  1.93it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 494/690 [07:40<01:28,  2.21it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 495/690 [07:40<01:21,  2.40it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 496/690 [07:41<01:14,  2.61it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 497/690 [07:41<01:09,  2.77it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 498/690 [07:41<01:06,  2.91it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 499/690 [07:42<01:03,  3.00it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 500/690 [07:42<01:01,  3.08it/s]                                                  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 500/690 [07:42<01:01,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 501/690 [07:42<01:00,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 502/690 [07:42<00:58,  3.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 503/690 [07:43<00:58,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 504/690 [07:43<00:57,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 505/690 [07:43<00:56,  3.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 506/690 [07:44<00:56,  3.25it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 507/690 [07:44<00:56,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 508/690 [07:44<00:55,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 509/690 [07:45<00:55,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 510/690 [07:45<00:55,  3.27it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 511/690 [07:45<00:54,  3.27it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 512/690 [07:46<00:54,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 513/690 [07:46<00:54,  3.27it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 514/690 [07:46<00:53,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 515/690 [07:46<00:53,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 516/690 [07:47<00:53,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 517/690 [07:47<00:52,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 518/690 [07:47<00:52,  3.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 519/690 [07:48<00:51,  3.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 520/690 [07:48<00:51,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 521/690 [07:48<00:51,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 522/690 [07:49<00:50,  3.30it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 523/690 [07:49<00:50,  3.30it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 524/690 [07:49<00:50,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 525/690 [07:49<00:50,  3.27it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 526/690 [07:50<00:50,  3.27it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 527/690 [07:50<00:50,  3.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 528/690 [07:50<00:49,  3.26it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 529/690 [07:51<00:49,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 530/690 [07:51<00:48,  3.28it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 531/690 [07:51<00:48,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 532/690 [07:52<00:48,  3.28it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 533/690 [07:52<00:47,  3.28it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 534/690 [07:52<00:47,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 535/690 [07:53<00:47,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 536/690 [07:53<00:46,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 537/690 [07:53<00:46,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 538/690 [07:53<00:46,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 539/690 [07:54<00:45,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 540/690 [07:54<00:45,  3.29it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 541/690 [07:54<00:45,  3.28it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 542/690 [07:55<00:45,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 543/690 [07:55<00:44,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 544/690 [07:55<00:44,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 545/690 [07:56<00:44,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 546/690 [07:56<00:43,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 547/690 [07:56<00:43,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 548/690 [07:57<00:43,  3.27it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 549/690 [07:57<00:43,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 550/690 [07:57<00:43,  3.25it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 551/690 [07:57<00:42,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 552/690 [07:58<00:39,  3.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.09it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.15it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.70it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.45it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 552/690 [07:59<00:39,  3.47it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-552
Configuration saved in sst_model/checkpoint-552/config.json
Model weights saved in sst_model/checkpoint-552/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-414] due to args.save_total_limit
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 553/690 [08:13<10:53,  4.77s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 554/690 [08:13<07:46,  3.43s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 555/690 [08:14<05:36,  2.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 556/690 [08:14<04:06,  1.84s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 557/690 [08:14<03:03,  1.38s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 558/690 [08:14<02:19,  1.05s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 559/690 [08:15<01:48,  1.21it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 560/690 [08:15<01:27,  1.49it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 561/690 [08:15<01:12,  1.78it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 562/690 [08:16<01:01,  2.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 563/690 [08:16<00:54,  2.33it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 564/690 [08:16<00:49,  2.55it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 565/690 [08:17<00:45,  2.73it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 566/690 [08:17<00:43,  2.88it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 567/690 [08:17<00:41,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 568/690 [08:17<00:39,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 569/690 [08:18<00:38,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 570/690 [08:18<00:37,  3.16it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 571/690 [08:18<00:37,  3.20it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 572/690 [08:19<00:36,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 573/690 [08:19<00:36,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 574/690 [08:19<00:35,  3.25it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 575/690 [08:20<00:35,  3.26it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 576/690 [08:20<00:34,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 577/690 [08:20<00:34,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 578/690 [08:21<00:34,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 579/690 [08:21<00:34,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 580/690 [08:21<00:34,  3.22it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 581/690 [08:21<00:33,  3.23it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 582/690 [08:22<00:33,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 583/690 [08:22<00:33,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 584/690 [08:22<00:32,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 585/690 [08:23<00:32,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 586/690 [08:23<00:32,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 587/690 [08:23<00:31,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 588/690 [08:24<00:31,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 589/690 [08:24<00:31,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 590/690 [08:24<00:30,  3.25it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 591/690 [08:25<00:30,  3.27it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 592/690 [08:25<00:30,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 593/690 [08:25<00:29,  3.27it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 594/690 [08:25<00:29,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 595/690 [08:26<00:29,  3.26it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 596/690 [08:26<00:28,  3.26it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 597/690 [08:26<00:28,  3.27it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 598/690 [08:27<00:28,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 599/690 [08:27<00:27,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 600/690 [08:27<00:27,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 601/690 [08:28<00:27,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 602/690 [08:28<00:27,  3.26it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 603/690 [08:28<00:26,  3.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 604/690 [08:29<00:26,  3.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 605/690 [08:29<00:26,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 606/690 [08:29<00:25,  3.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 607/690 [08:29<00:25,  3.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 608/690 [08:30<00:25,  3.21it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 609/690 [08:30<00:25,  3.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 610/690 [08:30<00:24,  3.20it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 611/690 [08:31<00:24,  3.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 612/690 [08:31<00:24,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 613/690 [08:31<00:23,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 614/690 [08:32<00:23,  3.20it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 615/690 [08:32<00:23,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 616/690 [08:32<00:22,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 617/690 [08:33<00:22,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 618/690 [08:33<00:22,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 619/690 [08:33<00:21,  3.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 620/690 [08:33<00:21,  3.25it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 621/690 [08:34<00:20,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.49it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.46it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.08it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.51it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.31it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.12it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.12it/s][A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 621/690 [08:35<00:20,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-621
Configuration saved in sst_model/checkpoint-621/config.json
Model weights saved in sst_model/checkpoint-621/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-483] due to args.save_total_limit
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 622/690 [08:49<05:32,  4.89s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 623/690 [08:50<03:55,  3.52s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 624/690 [08:50<02:48,  2.55s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 625/690 [08:50<02:02,  1.88s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 626/690 [08:51<01:30,  1.41s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 627/690 [08:51<01:07,  1.08s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 628/690 [08:51<00:52,  1.18it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 629/690 [08:52<00:41,  1.46it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 630/690 [08:52<00:34,  1.76it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 631/690 [08:52<00:28,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 632/690 [08:52<00:25,  2.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 633/690 [08:53<00:22,  2.53it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 634/690 [08:53<00:20,  2.71it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 635/690 [08:53<00:19,  2.86it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 636/690 [08:54<00:18,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 637/690 [08:54<00:17,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 638/690 [08:54<00:16,  3.13it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 639/690 [08:55<00:16,  3.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 640/690 [08:55<00:15,  3.19it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 641/690 [08:55<00:15,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 642/690 [08:55<00:14,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 643/690 [08:56<00:14,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 644/690 [08:56<00:14,  3.25it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 645/690 [08:56<00:13,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 646/690 [08:57<00:13,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 647/690 [08:57<00:13,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 648/690 [08:57<00:13,  3.23it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 649/690 [08:58<00:12,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 650/690 [08:58<00:12,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 651/690 [08:58<00:11,  3.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 652/690 [08:59<00:11,  3.20it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 653/690 [08:59<00:11,  3.21it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 654/690 [08:59<00:11,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 655/690 [08:59<00:10,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 656/690 [09:00<00:10,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 657/690 [09:00<00:10,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 658/690 [09:00<00:09,  3.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 659/690 [09:01<00:09,  3.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 660/690 [09:01<00:09,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 661/690 [09:01<00:08,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 662/690 [09:02<00:08,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 663/690 [09:02<00:08,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 664/690 [09:02<00:07,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 665/690 [09:03<00:07,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 666/690 [09:03<00:07,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 667/690 [09:03<00:07,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 668/690 [09:03<00:06,  3.27it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 669/690 [09:04<00:06,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 670/690 [09:04<00:06,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 671/690 [09:04<00:05,  3.27it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 672/690 [09:05<00:05,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 673/690 [09:05<00:05,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 674/690 [09:05<00:04,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 675/690 [09:06<00:04,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 676/690 [09:06<00:04,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 677/690 [09:06<00:03,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 678/690 [09:07<00:03,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 679/690 [09:07<00:03,  3.28it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 680/690 [09:07<00:03,  3.29it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 681/690 [09:07<00:02,  3.27it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 682/690 [09:08<00:02,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 683/690 [09:08<00:02,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 684/690 [09:08<00:01,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 685/690 [09:09<00:01,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 686/690 [09:09<00:01,  3.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 687/690 [09:09<00:00,  3.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 688/690 [09:10<00:00,  3.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 689/690 [09:10<00:00,  3.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [09:10<00:00,  3.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.83it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.31it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.10it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.60it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.34it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.19it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.19it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [09:11<00:00,  3.40it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-690
Configuration saved in sst_model/checkpoint-690/config.json
Model weights saved in sst_model/checkpoint-690/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-552] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from sst_model/checkpoint-621 (score: 0.68).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [09:50<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [09:50<00:00,  1.17it/s]
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Using custom data configuration default-85bff0f227322e09
0 tables [00:00, ? tables/s]                            loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.03ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.01ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-35bfd9f04e6658c3.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-04edea8e5deaac23.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.23ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.23ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-80dea3fb3755f005.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1f098d744ad3e451.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.48ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.48ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-523194a38c7f88f6.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-487f6c90d30222c9.arrow
PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running training *****
  Num examples = 550
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 690
  0%|          | 0/690 [00:00<?, ?it/s]  0%|          | 1/690 [00:00<04:17,  2.68it/s]  0%|          | 2/690 [00:00<03:46,  3.04it/s]  0%|          | 3/690 [00:00<03:43,  3.08it/s]  1%|          | 4/690 [00:01<03:36,  3.17it/s]  1%|          | 5/690 [00:01<03:32,  3.22it/s]  1%|          | 6/690 [00:01<03:30,  3.25it/s]  1%|          | 7/690 [00:02<03:29,  3.27it/s]  1%|          | 8/690 [00:02<03:27,  3.28it/s]  1%|â–         | 9/690 [00:02<03:26,  3.29it/s]  1%|â–         | 10/690 [00:03<03:26,  3.30it/s]  2%|â–         | 11/690 [00:03<03:25,  3.30it/s]  2%|â–         | 12/690 [00:03<03:25,  3.30it/s]  2%|â–         | 13/690 [00:04<03:25,  3.30it/s]  2%|â–         | 14/690 [00:04<03:24,  3.30it/s]  2%|â–         | 15/690 [00:04<03:24,  3.30it/s]  2%|â–         | 16/690 [00:04<03:24,  3.30it/s]  2%|â–         | 17/690 [00:05<03:23,  3.30it/s]  3%|â–Ž         | 18/690 [00:05<03:23,  3.30it/s]  3%|â–Ž         | 19/690 [00:05<03:23,  3.30it/s]  3%|â–Ž         | 20/690 [00:06<03:22,  3.30it/s]  3%|â–Ž         | 21/690 [00:06<03:22,  3.30it/s]  3%|â–Ž         | 22/690 [00:06<03:22,  3.29it/s]  3%|â–Ž         | 23/690 [00:07<03:22,  3.29it/s]  3%|â–Ž         | 24/690 [00:07<03:22,  3.29it/s]  4%|â–Ž         | 25/690 [00:07<03:22,  3.29it/s]  4%|â–         | 26/690 [00:07<03:22,  3.29it/s]  4%|â–         | 27/690 [00:08<03:21,  3.28it/s]  4%|â–         | 28/690 [00:08<03:22,  3.26it/s]  4%|â–         | 29/690 [00:08<03:22,  3.27it/s]  4%|â–         | 30/690 [00:09<03:24,  3.22it/s]  4%|â–         | 31/690 [00:09<03:23,  3.24it/s]  5%|â–         | 32/690 [00:09<03:22,  3.25it/s]  5%|â–         | 33/690 [00:10<03:21,  3.26it/s]  5%|â–         | 34/690 [00:10<03:23,  3.22it/s]  5%|â–Œ         | 35/690 [00:10<03:23,  3.23it/s]  5%|â–Œ         | 36/690 [00:11<03:21,  3.24it/s]  5%|â–Œ         | 37/690 [00:11<03:20,  3.26it/s]  6%|â–Œ         | 38/690 [00:11<03:19,  3.27it/s]  6%|â–Œ         | 39/690 [00:11<03:19,  3.27it/s]  6%|â–Œ         | 40/690 [00:12<03:18,  3.27it/s]  6%|â–Œ         | 41/690 [00:12<03:18,  3.27it/s]  6%|â–Œ         | 42/690 [00:12<03:18,  3.27it/s]  6%|â–Œ         | 43/690 [00:13<03:17,  3.27it/s]  6%|â–‹         | 44/690 [00:13<03:17,  3.27it/s]  7%|â–‹         | 45/690 [00:13<03:17,  3.27it/s]  7%|â–‹         | 46/690 [00:14<03:16,  3.27it/s]  7%|â–‹         | 47/690 [00:14<03:17,  3.26it/s]  7%|â–‹         | 48/690 [00:14<03:16,  3.26it/s]  7%|â–‹         | 49/690 [00:15<03:16,  3.26it/s]  7%|â–‹         | 50/690 [00:15<03:16,  3.27it/s]  7%|â–‹         | 51/690 [00:15<03:15,  3.27it/s]  8%|â–Š         | 52/690 [00:15<03:15,  3.27it/s]  8%|â–Š         | 53/690 [00:16<03:14,  3.27it/s]  8%|â–Š         | 54/690 [00:16<03:14,  3.28it/s]  8%|â–Š         | 55/690 [00:16<03:13,  3.28it/s]  8%|â–Š         | 56/690 [00:17<03:13,  3.28it/s]  8%|â–Š         | 57/690 [00:17<03:13,  3.28it/s]  8%|â–Š         | 58/690 [00:17<03:12,  3.27it/s]  9%|â–Š         | 59/690 [00:18<03:12,  3.27it/s]  9%|â–Š         | 60/690 [00:18<03:12,  3.27it/s]  9%|â–‰         | 61/690 [00:18<03:12,  3.27it/s]  9%|â–‰         | 62/690 [00:18<03:12,  3.27it/s]  9%|â–‰         | 63/690 [00:19<03:12,  3.26it/s]  9%|â–‰         | 64/690 [00:19<03:12,  3.26it/s]  9%|â–‰         | 65/690 [00:19<03:11,  3.26it/s] 10%|â–‰         | 66/690 [00:20<03:11,  3.26it/s] 10%|â–‰         | 67/690 [00:20<03:10,  3.26it/s] 10%|â–‰         | 68/690 [00:20<03:10,  3.27it/s] 10%|â–ˆ         | 69/690 [00:21<02:58,  3.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.10it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.42it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.26it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.49it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.37it/s][A
                                               [A                                                
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.37it/s][A 10%|â–ˆ         | 69/690 [00:22<02:58,  3.47it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-69
Configuration saved in sst_model/checkpoint-69/config.json
Model weights saved in sst_model/checkpoint-69/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-621] due to args.save_total_limit
 10%|â–ˆ         | 70/690 [00:52<1:39:44,  9.65s/it] 10%|â–ˆ         | 71/690 [00:52<1:10:39,  6.85s/it] 10%|â–ˆ         | 72/690 [00:53<50:18,  4.88s/it]   11%|â–ˆ         | 73/690 [00:53<36:05,  3.51s/it] 11%|â–ˆ         | 74/690 [00:53<26:10,  2.55s/it] 11%|â–ˆ         | 75/690 [00:54<19:13,  1.88s/it] 11%|â–ˆ         | 76/690 [00:54<14:22,  1.40s/it] 11%|â–ˆ         | 77/690 [00:54<10:58,  1.07s/it] 11%|â–ˆâ–        | 78/690 [00:55<08:36,  1.18it/s] 11%|â–ˆâ–        | 79/690 [00:55<06:56,  1.47it/s] 12%|â–ˆâ–        | 80/690 [00:55<05:47,  1.76it/s] 12%|â–ˆâ–        | 81/690 [00:55<04:58,  2.04it/s] 12%|â–ˆâ–        | 82/690 [00:56<04:24,  2.30it/s] 12%|â–ˆâ–        | 83/690 [00:56<04:00,  2.52it/s] 12%|â–ˆâ–        | 84/690 [00:56<03:43,  2.71it/s] 12%|â–ˆâ–        | 85/690 [00:57<03:31,  2.86it/s] 12%|â–ˆâ–        | 86/690 [00:57<03:23,  2.97it/s] 13%|â–ˆâ–Ž        | 87/690 [00:57<03:17,  3.06it/s] 13%|â–ˆâ–Ž        | 88/690 [00:58<03:13,  3.12it/s] 13%|â–ˆâ–Ž        | 89/690 [00:58<03:10,  3.16it/s] 13%|â–ˆâ–Ž        | 90/690 [00:58<03:08,  3.19it/s] 13%|â–ˆâ–Ž        | 91/690 [00:58<03:06,  3.21it/s] 13%|â–ˆâ–Ž        | 92/690 [00:59<03:05,  3.23it/s] 13%|â–ˆâ–Ž        | 93/690 [00:59<03:04,  3.24it/s] 14%|â–ˆâ–Ž        | 94/690 [00:59<03:05,  3.21it/s] 14%|â–ˆâ–        | 95/690 [01:00<03:07,  3.18it/s] 14%|â–ˆâ–        | 96/690 [01:00<03:05,  3.20it/s] 14%|â–ˆâ–        | 97/690 [01:00<03:04,  3.22it/s] 14%|â–ˆâ–        | 98/690 [01:01<03:03,  3.22it/s] 14%|â–ˆâ–        | 99/690 [01:01<03:02,  3.23it/s] 14%|â–ˆâ–        | 100/690 [01:01<03:09,  3.11it/s] 15%|â–ˆâ–        | 101/690 [01:02<03:07,  3.13it/s] 15%|â–ˆâ–        | 102/690 [01:02<03:05,  3.18it/s] 15%|â–ˆâ–        | 103/690 [01:02<03:03,  3.20it/s] 15%|â–ˆâ–Œ        | 104/690 [01:03<03:01,  3.22it/s] 15%|â–ˆâ–Œ        | 105/690 [01:03<03:00,  3.23it/s] 15%|â–ˆâ–Œ        | 106/690 [01:03<02:59,  3.25it/s] 16%|â–ˆâ–Œ        | 107/690 [01:03<02:59,  3.25it/s] 16%|â–ˆâ–Œ        | 108/690 [01:04<02:58,  3.26it/s] 16%|â–ˆâ–Œ        | 109/690 [01:04<03:00,  3.22it/s] 16%|â–ˆâ–Œ        | 110/690 [01:04<03:01,  3.20it/s] 16%|â–ˆâ–Œ        | 111/690 [01:05<02:59,  3.23it/s] 16%|â–ˆâ–Œ        | 112/690 [01:05<02:58,  3.24it/s] 16%|â–ˆâ–‹        | 113/690 [01:05<02:57,  3.24it/s] 17%|â–ˆâ–‹        | 114/690 [01:06<02:57,  3.25it/s] 17%|â–ˆâ–‹        | 115/690 [01:06<02:56,  3.25it/s] 17%|â–ˆâ–‹        | 116/690 [01:06<02:56,  3.26it/s] 17%|â–ˆâ–‹        | 117/690 [01:07<02:55,  3.26it/s] 17%|â–ˆâ–‹        | 118/690 [01:07<02:55,  3.26it/s] 17%|â–ˆâ–‹        | 119/690 [01:07<02:55,  3.26it/s] 17%|â–ˆâ–‹        | 120/690 [01:07<02:54,  3.26it/s] 18%|â–ˆâ–Š        | 121/690 [01:08<02:54,  3.26it/s] 18%|â–ˆâ–Š        | 122/690 [01:08<02:53,  3.26it/s] 18%|â–ˆâ–Š        | 123/690 [01:08<02:53,  3.27it/s] 18%|â–ˆâ–Š        | 124/690 [01:09<02:53,  3.27it/s] 18%|â–ˆâ–Š        | 125/690 [01:09<02:52,  3.27it/s] 18%|â–ˆâ–Š        | 126/690 [01:09<02:53,  3.25it/s] 18%|â–ˆâ–Š        | 127/690 [01:10<02:53,  3.24it/s] 19%|â–ˆâ–Š        | 128/690 [01:10<02:53,  3.25it/s] 19%|â–ˆâ–Š        | 129/690 [01:10<02:53,  3.24it/s] 19%|â–ˆâ–‰        | 130/690 [01:11<02:52,  3.24it/s] 19%|â–ˆâ–‰        | 131/690 [01:11<02:52,  3.24it/s] 19%|â–ˆâ–‰        | 132/690 [01:11<02:51,  3.24it/s] 19%|â–ˆâ–‰        | 133/690 [01:11<02:51,  3.25it/s] 19%|â–ˆâ–‰        | 134/690 [01:12<02:50,  3.25it/s] 20%|â–ˆâ–‰        | 135/690 [01:12<02:50,  3.26it/s] 20%|â–ˆâ–‰        | 136/690 [01:12<02:50,  3.25it/s] 20%|â–ˆâ–‰        | 137/690 [01:13<02:50,  3.25it/s] 20%|â–ˆâ–ˆ        | 138/690 [01:13<02:39,  3.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.09it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.12it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.18it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.73it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.49it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.25it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.25it/s][A 20%|â–ˆâ–ˆ        | 138/690 [01:14<02:39,  3.46it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-138
Configuration saved in sst_model/checkpoint-138/config.json
Model weights saved in sst_model/checkpoint-138/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-690] due to args.save_total_limit
 20%|â–ˆâ–ˆ        | 139/690 [01:48<1:39:41, 10.86s/it] 20%|â–ˆâ–ˆ        | 140/690 [01:49<1:10:30,  7.69s/it] 20%|â–ˆâ–ˆ        | 141/690 [01:49<50:06,  5.48s/it]   21%|â–ˆâ–ˆ        | 142/690 [01:49<35:50,  3.93s/it] 21%|â–ˆâ–ˆ        | 143/690 [01:50<25:53,  2.84s/it] 21%|â–ˆâ–ˆ        | 144/690 [01:50<18:55,  2.08s/it] 21%|â–ˆâ–ˆ        | 145/690 [01:50<14:03,  1.55s/it] 21%|â–ˆâ–ˆ        | 146/690 [01:51<10:39,  1.18s/it] 21%|â–ˆâ–ˆâ–       | 147/690 [01:51<08:16,  1.09it/s] 21%|â–ˆâ–ˆâ–       | 148/690 [01:51<06:36,  1.37it/s] 22%|â–ˆâ–ˆâ–       | 149/690 [01:52<05:27,  1.65it/s] 22%|â–ˆâ–ˆâ–       | 150/690 [01:52<04:38,  1.94it/s] 22%|â–ˆâ–ˆâ–       | 151/690 [01:52<04:04,  2.21it/s] 22%|â–ˆâ–ˆâ–       | 152/690 [01:52<03:40,  2.44it/s] 22%|â–ˆâ–ˆâ–       | 153/690 [01:53<03:23,  2.64it/s] 22%|â–ˆâ–ˆâ–       | 154/690 [01:53<03:11,  2.80it/s] 22%|â–ˆâ–ˆâ–       | 155/690 [01:53<03:03,  2.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 156/690 [01:54<02:58,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 157/690 [01:54<02:54,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 158/690 [01:54<02:51,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 159/690 [01:55<02:48,  3.14it/s] 23%|â–ˆâ–ˆâ–Ž       | 160/690 [01:55<02:46,  3.17it/s] 23%|â–ˆâ–ˆâ–Ž       | 161/690 [01:55<02:45,  3.20it/s] 23%|â–ˆâ–ˆâ–Ž       | 162/690 [01:56<02:44,  3.21it/s] 24%|â–ˆâ–ˆâ–Ž       | 163/690 [01:56<02:44,  3.21it/s] 24%|â–ˆâ–ˆâ–       | 164/690 [01:56<02:43,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 165/690 [01:56<02:42,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 166/690 [01:57<02:42,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 167/690 [01:57<02:41,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 168/690 [01:57<02:41,  3.23it/s] 24%|â–ˆâ–ˆâ–       | 169/690 [01:58<02:41,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 170/690 [01:58<02:40,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 171/690 [01:58<02:39,  3.25it/s] 25%|â–ˆâ–ˆâ–       | 172/690 [01:59<02:39,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 173/690 [01:59<02:39,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 174/690 [01:59<02:39,  3.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 175/690 [02:00<02:39,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 176/690 [02:00<02:39,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 177/690 [02:00<02:38,  3.23it/s] 26%|â–ˆâ–ˆâ–Œ       | 178/690 [02:00<02:38,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 179/690 [02:01<02:37,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 180/690 [02:01<02:37,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 181/690 [02:01<02:36,  3.24it/s] 26%|â–ˆâ–ˆâ–‹       | 182/690 [02:02<02:36,  3.24it/s] 27%|â–ˆâ–ˆâ–‹       | 183/690 [02:02<02:36,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 184/690 [02:02<02:35,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 185/690 [02:03<02:35,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 186/690 [02:03<02:35,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 187/690 [02:03<02:34,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 188/690 [02:04<02:34,  3.25it/s] 27%|â–ˆâ–ˆâ–‹       | 189/690 [02:04<02:34,  3.25it/s] 28%|â–ˆâ–ˆâ–Š       | 190/690 [02:04<02:34,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 191/690 [02:04<02:34,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 192/690 [02:05<02:33,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 193/690 [02:05<02:33,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 194/690 [02:05<02:33,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 195/690 [02:06<02:32,  3.24it/s] 28%|â–ˆâ–ˆâ–Š       | 196/690 [02:06<02:32,  3.24it/s] 29%|â–ˆâ–ˆâ–Š       | 197/690 [02:06<02:32,  3.24it/s] 29%|â–ˆâ–ˆâ–Š       | 198/690 [02:07<02:32,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 199/690 [02:07<02:31,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 200/690 [02:07<02:31,  3.24it/s] 29%|â–ˆâ–ˆâ–‰       | 201/690 [02:08<02:31,  3.24it/s] 29%|â–ˆâ–ˆâ–‰       | 202/690 [02:08<02:30,  3.24it/s] 29%|â–ˆâ–ˆâ–‰       | 203/690 [02:08<02:30,  3.24it/s] 30%|â–ˆâ–ˆâ–‰       | 204/690 [02:09<02:30,  3.24it/s] 30%|â–ˆâ–ˆâ–‰       | 205/690 [02:09<02:29,  3.24it/s] 30%|â–ˆâ–ˆâ–‰       | 206/690 [02:09<02:29,  3.24it/s] 30%|â–ˆâ–ˆâ–ˆ       | 207/690 [02:09<02:20,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.96it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.58it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.28it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.76it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.49it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.33it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.33it/s][A 30%|â–ˆâ–ˆâ–ˆ       | 207/690 [02:11<02:20,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-207
Configuration saved in sst_model/checkpoint-207/config.json
Model weights saved in sst_model/checkpoint-207/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-138] due to args.save_total_limit
 30%|â–ˆâ–ˆâ–ˆ       | 208/690 [02:38<1:10:11,  8.74s/it] 30%|â–ˆâ–ˆâ–ˆ       | 209/690 [02:38<49:45,  6.21s/it]   30%|â–ˆâ–ˆâ–ˆ       | 210/690 [02:38<35:29,  4.44s/it] 31%|â–ˆâ–ˆâ–ˆ       | 211/690 [02:39<25:31,  3.20s/it] 31%|â–ˆâ–ˆâ–ˆ       | 212/690 [02:39<18:33,  2.33s/it] 31%|â–ˆâ–ˆâ–ˆ       | 213/690 [02:39<13:42,  1.72s/it] 31%|â–ˆâ–ˆâ–ˆ       | 214/690 [02:40<10:18,  1.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 215/690 [02:40<07:55,  1.00s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 216/690 [02:40<06:15,  1.26it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 217/690 [02:41<05:06,  1.55it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 218/690 [02:41<04:17,  1.84it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 219/690 [02:41<03:43,  2.11it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 220/690 [02:42<03:18,  2.36it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 221/690 [02:42<03:02,  2.58it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 222/690 [02:42<02:50,  2.75it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 223/690 [02:42<02:41,  2.89it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 224/690 [02:43<02:35,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 225/690 [02:43<02:31,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 226/690 [02:43<02:28,  3.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 227/690 [02:44<02:26,  3.16it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 228/690 [02:44<02:25,  3.18it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 229/690 [02:44<02:23,  3.20it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 230/690 [02:45<02:23,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 231/690 [02:45<02:22,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 232/690 [02:45<02:21,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 233/690 [02:45<02:21,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 234/690 [02:46<02:20,  3.25it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 235/690 [02:46<02:20,  3.25it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 236/690 [02:46<02:19,  3.25it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 237/690 [02:47<02:19,  3.25it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 238/690 [02:47<02:19,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 239/690 [02:47<02:18,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 240/690 [02:48<02:18,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 241/690 [02:48<02:18,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 242/690 [02:48<02:17,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 243/690 [02:49<02:17,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 244/690 [02:49<02:16,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 245/690 [02:49<02:16,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 246/690 [02:49<02:16,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 247/690 [02:50<02:16,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 248/690 [02:50<02:16,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 249/690 [02:50<02:16,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 250/690 [02:51<02:15,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 251/690 [02:51<02:15,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 252/690 [02:51<02:15,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 253/690 [02:52<02:14,  3.25it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 254/690 [02:52<02:14,  3.24it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 255/690 [02:52<02:13,  3.26it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 256/690 [02:53<02:13,  3.25it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 257/690 [02:53<02:13,  3.25it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 258/690 [02:53<02:13,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 259/690 [02:54<02:12,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 260/690 [02:54<02:12,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 261/690 [02:54<02:12,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 262/690 [02:54<02:11,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 263/690 [02:55<02:11,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 264/690 [02:55<02:11,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 265/690 [02:55<02:11,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 266/690 [02:56<02:10,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 267/690 [02:56<02:10,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 268/690 [02:56<02:10,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 269/690 [02:57<02:09,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 270/690 [02:57<02:09,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 271/690 [02:57<02:09,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 272/690 [02:58<02:08,  3.24it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 273/690 [02:58<02:08,  3.25it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 274/690 [02:58<02:07,  3.26it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 275/690 [02:58<02:07,  3.26it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 276/690 [02:59<01:59,  3.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.95it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.58it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.26it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.74it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.46it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.29it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.29it/s][A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 276/690 [03:00<01:59,  3.47it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-276
Configuration saved in sst_model/checkpoint-276/config.json
Model weights saved in sst_model/checkpoint-276/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-207] due to args.save_total_limit
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 277/690 [03:15<34:58,  5.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 278/690 [03:15<25:03,  3.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 279/690 [03:16<18:06,  2.64s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 280/690 [03:16<13:16,  1.94s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 281/690 [03:16<09:53,  1.45s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 282/690 [03:16<07:32,  1.11s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 283/690 [03:17<05:53,  1.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 284/690 [03:17<04:44,  1.43it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 285/690 [03:17<03:55,  1.72it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 286/690 [03:18<03:21,  2.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 287/690 [03:18<02:58,  2.26it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 288/690 [03:18<02:41,  2.49it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 289/690 [03:19<02:30,  2.67it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 290/690 [03:19<02:21,  2.82it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 291/690 [03:19<02:16,  2.93it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 292/690 [03:20<02:11,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 293/690 [03:20<02:07,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 294/690 [03:20<02:05,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 295/690 [03:20<02:04,  3.18it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 296/690 [03:21<02:02,  3.21it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 297/690 [03:21<02:01,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 298/690 [03:21<02:00,  3.24it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 299/690 [03:22<02:00,  3.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 300/690 [03:22<01:59,  3.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 301/690 [03:22<01:59,  3.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 302/690 [03:23<01:59,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 303/690 [03:23<01:58,  3.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 304/690 [03:23<01:58,  3.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 305/690 [03:24<01:57,  3.27it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 306/690 [03:24<01:57,  3.28it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 307/690 [03:24<01:56,  3.28it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 308/690 [03:24<01:56,  3.28it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 309/690 [03:25<01:56,  3.27it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/690 [03:25<01:56,  3.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 311/690 [03:25<01:56,  3.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 312/690 [03:26<01:56,  3.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 313/690 [03:26<01:55,  3.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 314/690 [03:26<01:55,  3.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 315/690 [03:27<01:55,  3.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 316/690 [03:27<01:55,  3.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 317/690 [03:27<01:55,  3.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 318/690 [03:28<01:54,  3.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 319/690 [03:28<01:54,  3.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 320/690 [03:28<01:53,  3.26it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 321/690 [03:28<01:53,  3.26it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 322/690 [03:29<01:53,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 323/690 [03:29<01:53,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 324/690 [03:29<01:53,  3.24it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 325/690 [03:30<01:52,  3.24it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 326/690 [03:30<01:52,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 327/690 [03:30<01:53,  3.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 328/690 [03:31<01:53,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 329/690 [03:31<01:52,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 330/690 [03:31<01:51,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 331/690 [03:32<01:52,  3.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 332/690 [03:32<01:52,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 333/690 [03:32<01:51,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 334/690 [03:32<01:51,  3.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 335/690 [03:33<01:50,  3.20it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 336/690 [03:33<01:50,  3.20it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 337/690 [03:33<01:50,  3.18it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 338/690 [03:34<01:50,  3.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 339/690 [03:34<01:50,  3.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 340/690 [03:34<01:49,  3.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 341/690 [03:35<01:49,  3.18it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 342/690 [03:35<01:49,  3.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 343/690 [03:35<01:48,  3.21it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 344/690 [03:36<01:47,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 345/690 [03:36<01:40,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.87it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.54it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.18it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.68it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.43it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.28it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.28it/s][A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 345/690 [03:37<01:40,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-345
Configuration saved in sst_model/checkpoint-345/config.json
Model weights saved in sst_model/checkpoint-345/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-276] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 346/690 [03:51<26:41,  4.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 347/690 [03:51<19:09,  3.35s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 348/690 [03:51<13:53,  2.44s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 349/690 [03:52<10:12,  1.80s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 350/690 [03:52<07:38,  1.35s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 351/690 [03:52<05:51,  1.04s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 352/690 [03:53<04:36,  1.22it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 353/690 [03:53<03:43,  1.51it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 354/690 [03:53<03:07,  1.79it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 355/690 [03:53<02:41,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 356/690 [03:54<02:22,  2.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 357/690 [03:54<02:10,  2.55it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 358/690 [03:54<02:01,  2.73it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 359/690 [03:55<01:55,  2.86it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 360/690 [03:55<01:51,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 361/690 [03:55<01:48,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 362/690 [03:56<01:45,  3.10it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 363/690 [03:56<01:43,  3.15it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 364/690 [03:56<01:42,  3.19it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 365/690 [03:57<01:41,  3.21it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 366/690 [03:57<01:40,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 367/690 [03:57<01:40,  3.22it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 368/690 [03:57<01:39,  3.23it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 369/690 [03:58<01:39,  3.23it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 370/690 [03:58<01:38,  3.24it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 371/690 [03:58<01:38,  3.24it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 372/690 [03:59<01:37,  3.25it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 373/690 [03:59<01:37,  3.26it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 374/690 [03:59<01:39,  3.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 375/690 [04:00<01:39,  3.16it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 376/690 [04:00<01:40,  3.13it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 377/690 [04:00<01:38,  3.17it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 378/690 [04:01<01:37,  3.19it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 379/690 [04:01<01:36,  3.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 380/690 [04:01<01:35,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 381/690 [04:01<01:35,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 382/690 [04:02<01:35,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 383/690 [04:02<01:34,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 384/690 [04:02<01:34,  3.23it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 385/690 [04:03<01:34,  3.23it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 386/690 [04:03<01:34,  3.22it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 387/690 [04:03<01:33,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 388/690 [04:04<01:33,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 389/690 [04:04<01:32,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 390/690 [04:04<01:32,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 391/690 [04:05<01:32,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 392/690 [04:05<01:31,  3.25it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 393/690 [04:05<01:31,  3.26it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 394/690 [04:05<01:30,  3.26it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 395/690 [04:06<01:30,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 396/690 [04:06<01:30,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 397/690 [04:06<01:30,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 398/690 [04:07<01:29,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 399/690 [04:07<01:29,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 400/690 [04:07<01:29,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 401/690 [04:08<01:29,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 402/690 [04:08<01:28,  3.25it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 403/690 [04:08<01:28,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 404/690 [04:09<01:27,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 405/690 [04:09<01:27,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 406/690 [04:09<01:27,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 407/690 [04:09<01:26,  3.26it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 408/690 [04:10<01:26,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 409/690 [04:10<01:26,  3.24it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 410/690 [04:10<01:26,  3.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 411/690 [04:11<01:26,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 412/690 [04:11<01:26,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 413/690 [04:11<01:25,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 414/690 [04:12<01:20,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.90it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.50it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.17it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.22it/s][A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 414/690 [04:13<01:20,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-414
Configuration saved in sst_model/checkpoint-414/config.json
Model weights saved in sst_model/checkpoint-414/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-345] due to args.save_total_limit
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 415/690 [04:31<27:33,  6.01s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 416/690 [04:31<19:38,  4.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 417/690 [04:32<14:07,  3.11s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 418/690 [04:32<10:16,  2.27s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 419/690 [04:32<07:34,  1.68s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 420/690 [04:33<05:41,  1.27s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 421/690 [04:33<04:23,  1.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 422/690 [04:33<03:28,  1.29it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 423/690 [04:33<02:49,  1.57it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 424/690 [04:34<02:22,  1.86it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 425/690 [04:34<02:04,  2.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 426/690 [04:34<01:50,  2.38it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 427/690 [04:35<01:41,  2.60it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 428/690 [04:35<01:34,  2.77it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 429/690 [04:35<01:29,  2.91it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 430/690 [04:36<01:26,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 431/690 [04:36<01:24,  3.08it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 432/690 [04:36<01:22,  3.14it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 433/690 [04:36<01:21,  3.17it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 434/690 [04:37<01:20,  3.18it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 435/690 [04:37<01:19,  3.20it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 436/690 [04:37<01:19,  3.21it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 437/690 [04:38<01:18,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 438/690 [04:38<01:17,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 439/690 [04:38<01:17,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 440/690 [04:39<01:16,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 441/690 [04:39<01:16,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 442/690 [04:39<01:16,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 443/690 [04:40<01:15,  3.26it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 444/690 [04:40<01:15,  3.27it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 445/690 [04:40<01:14,  3.27it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 446/690 [04:40<01:14,  3.27it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 447/690 [04:41<01:14,  3.27it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 448/690 [04:41<01:14,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 449/690 [04:41<01:14,  3.26it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 450/690 [04:42<01:13,  3.26it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 451/690 [04:42<01:13,  3.26it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 452/690 [04:42<01:13,  3.26it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 453/690 [04:43<01:12,  3.26it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 454/690 [04:43<01:12,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 455/690 [04:43<01:12,  3.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 456/690 [04:44<01:12,  3.25it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 457/690 [04:44<01:11,  3.26it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 458/690 [04:44<01:11,  3.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 459/690 [04:44<01:11,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 460/690 [04:45<01:10,  3.24it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 461/690 [04:45<01:10,  3.26it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 462/690 [04:45<01:09,  3.26it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 463/690 [04:46<01:09,  3.26it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 464/690 [04:46<01:09,  3.26it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 465/690 [04:46<01:09,  3.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 466/690 [04:47<01:08,  3.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 467/690 [04:47<01:08,  3.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 468/690 [04:47<01:08,  3.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 469/690 [04:48<01:07,  3.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 470/690 [04:48<01:07,  3.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 471/690 [04:48<01:07,  3.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 472/690 [04:48<01:07,  3.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 473/690 [04:49<01:06,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 474/690 [04:49<01:06,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 475/690 [04:49<01:06,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 476/690 [04:50<01:06,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 477/690 [04:50<01:05,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 478/690 [04:50<01:05,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 479/690 [04:51<01:05,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 480/690 [04:51<01:04,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 481/690 [04:51<01:04,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 482/690 [04:52<01:03,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 483/690 [04:52<00:59,  3.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.90it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.56it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.23it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.44it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.29it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.29it/s][A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 483/690 [04:53<00:59,  3.46it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-483
Configuration saved in sst_model/checkpoint-483/config.json
Model weights saved in sst_model/checkpoint-483/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-414] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 484/690 [05:44<54:13, 15.79s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 485/690 [05:44<38:05, 11.15s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 486/690 [05:44<26:50,  7.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 487/690 [05:45<19:00,  5.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 488/690 [05:45<13:32,  4.02s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 489/690 [05:45<09:44,  2.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 490/690 [05:46<07:04,  2.12s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 491/690 [05:46<05:14,  1.58s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 492/690 [05:46<03:56,  1.20s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 493/690 [05:46<03:02,  1.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 494/690 [05:47<02:25,  1.35it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 495/690 [05:47<01:59,  1.64it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 496/690 [05:47<01:40,  1.93it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 497/690 [05:48<01:27,  2.20it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 498/690 [05:48<01:18,  2.44it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 499/690 [05:48<01:12,  2.65it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 500/690 [05:49<01:07,  2.80it/s]                                                  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 500/690 [05:49<01:07,  2.80it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 501/690 [05:49<01:04,  2.92it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 502/690 [05:49<01:02,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 503/690 [05:50<01:00,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 504/690 [05:50<01:01,  3.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 505/690 [05:50<00:59,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 506/690 [05:51<00:58,  3.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 507/690 [05:51<00:57,  3.19it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 508/690 [05:51<00:56,  3.22it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 509/690 [05:51<00:55,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 510/690 [05:52<00:55,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 511/690 [05:52<00:54,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 512/690 [05:52<00:54,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 513/690 [05:53<00:54,  3.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 514/690 [05:53<00:53,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 515/690 [05:53<00:53,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 516/690 [05:54<00:53,  3.27it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 517/690 [05:54<00:52,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 518/690 [05:54<00:52,  3.27it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 519/690 [05:54<00:52,  3.28it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 520/690 [05:55<00:51,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 521/690 [05:55<00:51,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 522/690 [05:55<00:51,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 523/690 [05:56<00:50,  3.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 524/690 [05:56<00:50,  3.28it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 525/690 [05:56<00:50,  3.28it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 526/690 [05:57<00:50,  3.27it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 527/690 [05:57<00:49,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 528/690 [05:57<00:49,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 529/690 [05:58<00:49,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 530/690 [05:58<00:48,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 531/690 [05:58<00:48,  3.28it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 532/690 [05:58<00:48,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 533/690 [05:59<00:47,  3.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 534/690 [05:59<00:47,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 535/690 [05:59<00:47,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 536/690 [06:00<00:46,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 537/690 [06:00<00:46,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 538/690 [06:00<00:46,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 539/690 [06:01<00:46,  3.28it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 540/690 [06:01<00:45,  3.27it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 541/690 [06:01<00:45,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 542/690 [06:01<00:45,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 543/690 [06:02<00:45,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 544/690 [06:02<00:44,  3.26it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 545/690 [06:02<00:44,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 546/690 [06:03<00:43,  3.28it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 547/690 [06:03<00:43,  3.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 548/690 [06:03<00:43,  3.27it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 549/690 [06:04<00:43,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 550/690 [06:04<00:42,  3.26it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 551/690 [06:04<00:42,  3.25it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 552/690 [06:04<00:39,  3.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.94it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.62it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.26it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.46it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.32it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.32it/s][A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 552/690 [06:06<00:39,  3.46it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-552
Configuration saved in sst_model/checkpoint-552/config.json
Model weights saved in sst_model/checkpoint-552/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-483] due to args.save_total_limit
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 553/690 [06:29<17:32,  7.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 554/690 [06:30<12:23,  5.47s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 555/690 [06:30<08:48,  3.92s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 556/690 [06:30<06:19,  2.84s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 557/690 [06:31<04:36,  2.08s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 558/690 [06:31<03:23,  1.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 559/690 [06:31<02:33,  1.17s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 560/690 [06:32<01:58,  1.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 561/690 [06:32<01:34,  1.37it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 562/690 [06:32<01:17,  1.66it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 563/690 [06:32<01:05,  1.94it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 564/690 [06:33<00:57,  2.21it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 565/690 [06:33<00:51,  2.44it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 566/690 [06:33<00:47,  2.63it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 567/690 [06:34<00:43,  2.80it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 568/690 [06:34<00:41,  2.92it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 569/690 [06:34<00:40,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 570/690 [06:35<00:38,  3.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 571/690 [06:35<00:37,  3.15it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 572/690 [06:35<00:37,  3.19it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 573/690 [06:36<00:36,  3.20it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 574/690 [06:36<00:35,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 575/690 [06:36<00:35,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 576/690 [06:36<00:35,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 577/690 [06:37<00:34,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 578/690 [06:37<00:34,  3.26it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 579/690 [06:40<01:53,  1.02s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 580/690 [06:40<01:28,  1.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 581/690 [06:40<01:13,  1.48it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 582/690 [06:41<01:01,  1.76it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 583/690 [06:41<00:52,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 584/690 [06:41<00:46,  2.28it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 585/690 [06:42<00:42,  2.49it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 586/690 [06:42<00:38,  2.67it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 587/690 [06:42<00:36,  2.81it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 588/690 [06:43<00:35,  2.89it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 589/690 [06:43<00:33,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 590/690 [06:43<00:32,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 591/690 [06:44<00:33,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 592/690 [06:44<00:32,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 593/690 [06:44<00:31,  3.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 594/690 [06:45<00:30,  3.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 595/690 [06:45<00:29,  3.17it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 596/690 [06:45<00:29,  3.19it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 597/690 [06:45<00:28,  3.21it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 598/690 [06:46<00:28,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 599/690 [06:46<00:28,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 600/690 [06:46<00:27,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 601/690 [06:47<00:27,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 602/690 [06:47<00:27,  3.26it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 603/690 [06:47<00:26,  3.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 604/690 [06:48<00:26,  3.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 605/690 [06:48<00:26,  3.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 606/690 [06:48<00:25,  3.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 607/690 [06:49<00:25,  3.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 608/690 [06:49<00:25,  3.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 609/690 [06:49<00:24,  3.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 610/690 [06:49<00:24,  3.26it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 611/690 [06:50<00:24,  3.25it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 612/690 [06:50<00:23,  3.25it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 613/690 [06:50<00:23,  3.26it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 614/690 [06:51<00:23,  3.27it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 615/690 [06:51<00:22,  3.27it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 616/690 [06:51<00:22,  3.28it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 617/690 [06:52<00:22,  3.26it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 618/690 [06:52<00:22,  3.26it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 619/690 [06:52<00:21,  3.27it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 620/690 [06:53<00:21,  3.27it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 621/690 [06:53<00:19,  3.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.06it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.10it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.15it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.71it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.46it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.22it/s][A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 621/690 [06:54<00:19,  3.47it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-621
Configuration saved in sst_model/checkpoint-621/config.json
Model weights saved in sst_model/checkpoint-621/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-552] due to args.save_total_limit
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 622/690 [07:08<05:25,  4.79s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 623/690 [07:08<03:50,  3.44s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 624/690 [07:09<02:45,  2.50s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 625/690 [07:09<01:59,  1.84s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 626/690 [07:09<01:28,  1.38s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 627/690 [07:10<01:06,  1.06s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 628/690 [07:10<00:51,  1.20it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 629/690 [07:10<00:41,  1.48it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 630/690 [07:10<00:33,  1.77it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 631/690 [07:11<00:28,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 632/690 [07:11<00:25,  2.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 633/690 [07:11<00:22,  2.54it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 634/690 [07:12<00:20,  2.72it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 635/690 [07:12<00:19,  2.87it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 636/690 [07:12<00:18,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 637/690 [07:13<00:17,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 638/690 [07:13<00:16,  3.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 639/690 [07:13<00:16,  3.15it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 640/690 [07:14<00:15,  3.17it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 641/690 [07:14<00:15,  3.21it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 642/690 [07:14<00:14,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 643/690 [07:14<00:14,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 644/690 [07:15<00:14,  3.25it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 645/690 [07:15<00:13,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 646/690 [07:15<00:13,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 647/690 [07:16<00:13,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 648/690 [07:16<00:12,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 649/690 [07:16<00:12,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 650/690 [07:17<00:12,  3.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 651/690 [07:17<00:12,  3.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 652/690 [07:17<00:11,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 653/690 [07:18<00:11,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 654/690 [07:18<00:11,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 655/690 [07:18<00:10,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 656/690 [07:18<00:10,  3.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 657/690 [07:19<00:10,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 658/690 [07:19<00:09,  3.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 659/690 [07:19<00:09,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 660/690 [07:20<00:09,  3.27it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 661/690 [07:20<00:08,  3.27it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 662/690 [07:20<00:08,  3.27it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 663/690 [07:21<00:08,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 664/690 [07:21<00:07,  3.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 665/690 [07:21<00:07,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 666/690 [07:22<00:07,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 667/690 [07:22<00:07,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 668/690 [07:22<00:06,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 669/690 [07:22<00:06,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 670/690 [07:23<00:06,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 671/690 [07:23<00:05,  3.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 672/690 [07:23<00:05,  3.26it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 673/690 [07:24<00:05,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 674/690 [07:24<00:04,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 675/690 [07:24<00:04,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 676/690 [07:25<00:04,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 677/690 [07:25<00:03,  3.28it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 678/690 [07:25<00:03,  3.27it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 679/690 [07:26<00:03,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 680/690 [07:26<00:03,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 681/690 [07:26<00:02,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 682/690 [07:26<00:02,  3.25it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 683/690 [07:27<00:02,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 684/690 [07:27<00:01,  3.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 685/690 [07:27<00:01,  3.25it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 686/690 [07:28<00:01,  3.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 687/690 [07:28<00:00,  3.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 688/690 [07:28<00:00,  3.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 689/690 [07:29<00:00,  3.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [07:29<00:00,  3.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.97it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.58it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.25it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.70it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.41it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.27it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.27it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [07:30<00:00,  3.46it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-690
Configuration saved in sst_model/checkpoint-690/config.json
Model weights saved in sst_model/checkpoint-690/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-621] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from sst_model/checkpoint-69 (score: 0.75).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [08:11<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [08:11<00:00,  1.40it/s]
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Using custom data configuration default-4f9950c79ba7bfc8
0 tables [00:00, ? tables/s]                            loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.43ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.42ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-35bfd9f04e6658c3.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-04edea8e5deaac23.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.34ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.34ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-80dea3fb3755f005.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-1f098d744ad3e451.arrow
  0%|          | 0/1 [00:00<?, ?ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.62ba/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.62ba/s]
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-523194a38c7f88f6.arrow
Loading cached processed dataset at /home/yandex/AMNLP2021/shlomotannor/data/sst/default-bffd5994dba40be2/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-487f6c90d30222c9.arrow
PyTorch: setting up devices
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.8.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /a/home/cc/students/cs/shlomotannor/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running training *****
  Num examples = 726
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 910
  0%|          | 0/910 [00:00<?, ?it/s]  0%|          | 1/910 [00:00<06:04,  2.49it/s]  0%|          | 2/910 [00:00<05:11,  2.92it/s]  0%|          | 3/910 [00:01<04:54,  3.08it/s]  0%|          | 4/910 [00:01<04:46,  3.17it/s]  1%|          | 5/910 [00:01<04:41,  3.22it/s]  1%|          | 6/910 [00:01<04:38,  3.24it/s]  1%|          | 7/910 [00:02<04:36,  3.26it/s]  1%|          | 8/910 [00:02<04:36,  3.26it/s]  1%|          | 9/910 [00:02<04:34,  3.28it/s]  1%|          | 10/910 [00:03<04:33,  3.29it/s]  1%|          | 11/910 [00:03<04:32,  3.29it/s]  1%|â–         | 12/910 [00:03<04:32,  3.29it/s]  1%|â–         | 13/910 [00:04<04:32,  3.29it/s]  2%|â–         | 14/910 [00:04<04:32,  3.29it/s]  2%|â–         | 15/910 [00:04<04:31,  3.29it/s]  2%|â–         | 16/910 [00:04<04:31,  3.30it/s]  2%|â–         | 17/910 [00:05<04:30,  3.30it/s]  2%|â–         | 18/910 [00:05<04:30,  3.30it/s]  2%|â–         | 19/910 [00:05<04:30,  3.30it/s]  2%|â–         | 20/910 [00:06<04:30,  3.30it/s]  2%|â–         | 21/910 [00:06<04:29,  3.30it/s]  2%|â–         | 22/910 [00:06<04:29,  3.30it/s]  3%|â–Ž         | 23/910 [00:07<04:29,  3.30it/s]  3%|â–Ž         | 24/910 [00:07<04:28,  3.30it/s]  3%|â–Ž         | 25/910 [00:07<04:28,  3.30it/s]  3%|â–Ž         | 26/910 [00:07<04:28,  3.30it/s]  3%|â–Ž         | 27/910 [00:08<04:28,  3.29it/s]  3%|â–Ž         | 28/910 [00:08<04:28,  3.29it/s]  3%|â–Ž         | 29/910 [00:08<04:27,  3.29it/s]  3%|â–Ž         | 30/910 [00:09<04:27,  3.29it/s]  3%|â–Ž         | 31/910 [00:09<04:27,  3.29it/s]  4%|â–Ž         | 32/910 [00:09<04:27,  3.29it/s]  4%|â–Ž         | 33/910 [00:10<04:27,  3.28it/s]  4%|â–Ž         | 34/910 [00:10<04:26,  3.28it/s]  4%|â–         | 35/910 [00:10<04:26,  3.28it/s]  4%|â–         | 36/910 [00:11<04:26,  3.28it/s]  4%|â–         | 37/910 [00:11<04:26,  3.28it/s]  4%|â–         | 38/910 [00:11<04:25,  3.28it/s]  4%|â–         | 39/910 [00:11<04:25,  3.29it/s]  4%|â–         | 40/910 [00:12<04:24,  3.28it/s]  5%|â–         | 41/910 [00:12<04:24,  3.28it/s]  5%|â–         | 42/910 [00:12<04:24,  3.28it/s]  5%|â–         | 43/910 [00:13<04:24,  3.28it/s]  5%|â–         | 44/910 [00:13<04:23,  3.28it/s]  5%|â–         | 45/910 [00:13<04:26,  3.24it/s]  5%|â–Œ         | 46/910 [00:14<04:25,  3.25it/s]  5%|â–Œ         | 47/910 [00:14<04:25,  3.26it/s]  5%|â–Œ         | 48/910 [00:14<04:24,  3.26it/s]  5%|â–Œ         | 49/910 [00:15<04:23,  3.27it/s]  5%|â–Œ         | 50/910 [00:15<04:23,  3.27it/s]  6%|â–Œ         | 51/910 [00:15<04:23,  3.26it/s]  6%|â–Œ         | 52/910 [00:15<04:24,  3.24it/s]  6%|â–Œ         | 53/910 [00:16<04:24,  3.24it/s]  6%|â–Œ         | 54/910 [00:16<04:24,  3.23it/s]  6%|â–Œ         | 55/910 [00:16<04:23,  3.24it/s]  6%|â–Œ         | 56/910 [00:17<04:22,  3.25it/s]  6%|â–‹         | 57/910 [00:17<04:23,  3.24it/s]  6%|â–‹         | 58/910 [00:17<04:24,  3.22it/s]  6%|â–‹         | 59/910 [00:18<04:24,  3.22it/s]  7%|â–‹         | 60/910 [00:18<04:23,  3.22it/s]  7%|â–‹         | 61/910 [00:18<04:22,  3.24it/s]  7%|â–‹         | 62/910 [00:19<04:21,  3.25it/s]  7%|â–‹         | 63/910 [00:19<04:20,  3.25it/s]  7%|â–‹         | 64/910 [00:19<04:22,  3.22it/s]  7%|â–‹         | 65/910 [00:19<04:21,  3.23it/s]  7%|â–‹         | 66/910 [00:20<04:20,  3.24it/s]  7%|â–‹         | 67/910 [00:20<04:19,  3.25it/s]  7%|â–‹         | 68/910 [00:20<04:18,  3.26it/s]  8%|â–Š         | 69/910 [00:21<04:18,  3.25it/s]  8%|â–Š         | 70/910 [00:21<04:17,  3.26it/s]  8%|â–Š         | 71/910 [00:21<04:17,  3.26it/s]  8%|â–Š         | 72/910 [00:22<04:17,  3.26it/s]  8%|â–Š         | 73/910 [00:22<04:16,  3.26it/s]  8%|â–Š         | 74/910 [00:22<04:16,  3.26it/s]  8%|â–Š         | 75/910 [00:23<04:15,  3.26it/s]  8%|â–Š         | 76/910 [00:23<04:15,  3.26it/s]  8%|â–Š         | 77/910 [00:23<04:15,  3.25it/s]  9%|â–Š         | 78/910 [00:23<04:16,  3.24it/s]  9%|â–Š         | 79/910 [00:24<04:16,  3.24it/s]  9%|â–‰         | 80/910 [00:24<04:15,  3.24it/s]  9%|â–‰         | 81/910 [00:24<04:17,  3.21it/s]  9%|â–‰         | 82/910 [00:25<04:16,  3.22it/s]  9%|â–‰         | 83/910 [00:25<04:16,  3.23it/s]  9%|â–‰         | 84/910 [00:25<04:14,  3.24it/s]  9%|â–‰         | 85/910 [00:26<04:17,  3.20it/s]  9%|â–‰         | 86/910 [00:26<04:17,  3.20it/s] 10%|â–‰         | 87/910 [00:26<04:15,  3.22it/s] 10%|â–‰         | 88/910 [00:27<04:14,  3.23it/s] 10%|â–‰         | 89/910 [00:27<04:13,  3.24it/s] 10%|â–‰         | 90/910 [00:27<04:13,  3.24it/s] 10%|â–ˆ         | 91/910 [00:27<03:57,  3.45it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 14.55it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 11.26it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 10.67it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.42it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.28it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.20it/s][A
                                               [A                                                
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.20it/s][A 10%|â–ˆ         | 91/910 [00:33<03:57,  3.45it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-91
Configuration saved in sst_model/checkpoint-91/config.json
Model weights saved in sst_model/checkpoint-91/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-69] due to args.save_total_limit
 10%|â–ˆ         | 92/910 [02:05<6:43:17, 29.58s/it] 10%|â–ˆ         | 93/910 [02:06<4:43:12, 20.80s/it] 10%|â–ˆ         | 94/910 [02:06<3:19:14, 14.65s/it] 10%|â–ˆ         | 95/910 [02:06<2:20:32, 10.35s/it] 11%|â–ˆ         | 96/910 [02:07<1:39:32,  7.34s/it] 11%|â–ˆ         | 97/910 [02:07<1:10:49,  5.23s/it] 11%|â–ˆ         | 98/910 [02:07<50:45,  3.75s/it]   11%|â–ˆ         | 99/910 [02:07<36:43,  2.72s/it] 11%|â–ˆ         | 100/910 [02:08<26:54,  1.99s/it] 11%|â–ˆ         | 101/910 [02:08<20:04,  1.49s/it] 11%|â–ˆ         | 102/910 [02:08<15:16,  1.13s/it] 11%|â–ˆâ–        | 103/910 [02:09<11:54,  1.13it/s] 11%|â–ˆâ–        | 104/910 [02:09<09:33,  1.41it/s] 12%|â–ˆâ–        | 105/910 [02:09<07:54,  1.70it/s] 12%|â–ˆâ–        | 106/910 [02:10<06:48,  1.97it/s] 12%|â–ˆâ–        | 107/910 [02:10<05:59,  2.24it/s] 12%|â–ˆâ–        | 108/910 [02:10<05:24,  2.47it/s] 12%|â–ˆâ–        | 109/910 [02:11<05:00,  2.67it/s] 12%|â–ˆâ–        | 110/910 [02:11<04:43,  2.82it/s] 12%|â–ˆâ–        | 111/910 [02:11<04:32,  2.93it/s] 12%|â–ˆâ–        | 112/910 [02:11<04:23,  3.02it/s] 12%|â–ˆâ–        | 113/910 [02:12<04:23,  3.03it/s] 13%|â–ˆâ–Ž        | 114/910 [02:12<04:17,  3.09it/s] 13%|â–ˆâ–Ž        | 115/910 [02:12<04:12,  3.15it/s] 13%|â–ˆâ–Ž        | 116/910 [02:13<04:09,  3.19it/s] 13%|â–ˆâ–Ž        | 117/910 [02:13<04:06,  3.21it/s] 13%|â–ˆâ–Ž        | 118/910 [02:13<04:05,  3.23it/s] 13%|â–ˆâ–Ž        | 119/910 [02:14<04:07,  3.19it/s] 13%|â–ˆâ–Ž        | 120/910 [02:14<04:05,  3.21it/s] 13%|â–ˆâ–Ž        | 121/910 [02:14<04:04,  3.23it/s] 13%|â–ˆâ–Ž        | 122/910 [02:15<04:05,  3.21it/s] 14%|â–ˆâ–Ž        | 123/910 [02:15<04:04,  3.22it/s] 14%|â–ˆâ–Ž        | 124/910 [02:15<04:03,  3.23it/s] 14%|â–ˆâ–Ž        | 125/910 [02:16<04:02,  3.24it/s] 14%|â–ˆâ–        | 126/910 [02:16<04:01,  3.24it/s] 14%|â–ˆâ–        | 127/910 [02:16<04:01,  3.25it/s] 14%|â–ˆâ–        | 128/910 [02:16<04:01,  3.24it/s] 14%|â–ˆâ–        | 129/910 [02:17<04:00,  3.25it/s] 14%|â–ˆâ–        | 130/910 [02:17<04:00,  3.25it/s] 14%|â–ˆâ–        | 131/910 [02:17<04:00,  3.24it/s] 15%|â–ˆâ–        | 132/910 [02:18<04:00,  3.23it/s] 15%|â–ˆâ–        | 133/910 [02:18<04:00,  3.23it/s] 15%|â–ˆâ–        | 134/910 [02:18<03:59,  3.24it/s] 15%|â–ˆâ–        | 135/910 [02:19<03:59,  3.23it/s] 15%|â–ˆâ–        | 136/910 [02:19<04:02,  3.20it/s] 15%|â–ˆâ–Œ        | 137/910 [02:19<04:04,  3.16it/s] 15%|â–ˆâ–Œ        | 138/910 [02:20<04:02,  3.19it/s] 15%|â–ˆâ–Œ        | 139/910 [02:20<04:00,  3.21it/s] 15%|â–ˆâ–Œ        | 140/910 [02:20<03:59,  3.21it/s] 15%|â–ˆâ–Œ        | 141/910 [02:20<03:58,  3.22it/s] 16%|â–ˆâ–Œ        | 142/910 [02:21<03:58,  3.22it/s] 16%|â–ˆâ–Œ        | 143/910 [02:21<03:57,  3.23it/s] 16%|â–ˆâ–Œ        | 144/910 [02:21<03:56,  3.24it/s] 16%|â–ˆâ–Œ        | 145/910 [02:22<03:58,  3.20it/s] 16%|â–ˆâ–Œ        | 146/910 [02:22<03:57,  3.22it/s] 16%|â–ˆâ–Œ        | 147/910 [02:22<03:56,  3.23it/s] 16%|â–ˆâ–‹        | 148/910 [02:23<03:55,  3.23it/s] 16%|â–ˆâ–‹        | 149/910 [02:23<03:55,  3.24it/s] 16%|â–ˆâ–‹        | 150/910 [02:23<03:54,  3.23it/s] 17%|â–ˆâ–‹        | 151/910 [02:24<03:55,  3.23it/s] 17%|â–ˆâ–‹        | 152/910 [02:24<03:55,  3.22it/s] 17%|â–ˆâ–‹        | 153/910 [02:24<03:54,  3.23it/s] 17%|â–ˆâ–‹        | 154/910 [02:25<03:54,  3.22it/s] 17%|â–ˆâ–‹        | 155/910 [02:25<03:53,  3.23it/s] 17%|â–ˆâ–‹        | 156/910 [02:25<03:52,  3.24it/s] 17%|â–ˆâ–‹        | 157/910 [02:25<03:52,  3.24it/s] 17%|â–ˆâ–‹        | 158/910 [02:26<03:53,  3.22it/s] 17%|â–ˆâ–‹        | 159/910 [02:26<03:53,  3.21it/s] 18%|â–ˆâ–Š        | 160/910 [02:26<03:52,  3.23it/s] 18%|â–ˆâ–Š        | 161/910 [02:27<03:51,  3.23it/s] 18%|â–ˆâ–Š        | 162/910 [02:27<03:51,  3.24it/s] 18%|â–ˆâ–Š        | 163/910 [02:27<03:52,  3.22it/s] 18%|â–ˆâ–Š        | 164/910 [02:28<03:50,  3.23it/s] 18%|â–ˆâ–Š        | 165/910 [02:28<03:50,  3.23it/s] 18%|â–ˆâ–Š        | 166/910 [02:28<03:49,  3.24it/s] 18%|â–ˆâ–Š        | 167/910 [02:29<03:49,  3.24it/s] 18%|â–ˆâ–Š        | 168/910 [02:29<03:49,  3.24it/s] 19%|â–ˆâ–Š        | 169/910 [02:29<03:48,  3.24it/s] 19%|â–ˆâ–Š        | 170/910 [02:29<03:48,  3.24it/s] 19%|â–ˆâ–‰        | 171/910 [02:30<03:48,  3.24it/s] 19%|â–ˆâ–‰        | 172/910 [02:30<03:48,  3.23it/s] 19%|â–ˆâ–‰        | 173/910 [02:30<03:48,  3.23it/s] 19%|â–ˆâ–‰        | 174/910 [02:31<03:47,  3.24it/s] 19%|â–ˆâ–‰        | 175/910 [02:31<03:47,  3.23it/s] 19%|â–ˆâ–‰        | 176/910 [02:31<03:48,  3.21it/s] 19%|â–ˆâ–‰        | 177/910 [02:32<03:48,  3.21it/s] 20%|â–ˆâ–‰        | 178/910 [02:32<03:47,  3.22it/s] 20%|â–ˆâ–‰        | 179/910 [02:32<03:46,  3.23it/s] 20%|â–ˆâ–‰        | 180/910 [02:33<03:45,  3.23it/s] 20%|â–ˆâ–‰        | 181/910 [02:33<03:45,  3.23it/s] 20%|â–ˆâ–ˆ        | 182/910 [02:33<03:31,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.03it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.12it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.16it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.69it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:00<00:00, 10.46it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.19it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.19it/s][A 20%|â–ˆâ–ˆ        | 182/910 [02:34<03:31,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-182
Configuration saved in sst_model/checkpoint-182/config.json
Model weights saved in sst_model/checkpoint-182/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-690] due to args.save_total_limit
 20%|â–ˆâ–ˆ        | 183/910 [03:22<2:59:03, 14.78s/it] 20%|â–ˆâ–ˆ        | 184/910 [03:22<2:06:17, 10.44s/it] 20%|â–ˆâ–ˆ        | 185/910 [03:22<1:29:23,  7.40s/it] 20%|â–ˆâ–ˆ        | 186/910 [03:23<1:03:35,  5.27s/it] 21%|â–ˆâ–ˆ        | 187/910 [03:23<45:33,  3.78s/it]   21%|â–ˆâ–ˆ        | 188/910 [03:23<32:57,  2.74s/it] 21%|â–ˆâ–ˆ        | 189/910 [03:24<24:09,  2.01s/it] 21%|â–ˆâ–ˆ        | 190/910 [03:24<17:58,  1.50s/it] 21%|â–ˆâ–ˆ        | 191/910 [03:24<13:40,  1.14s/it] 21%|â–ˆâ–ˆ        | 192/910 [03:24<10:39,  1.12it/s] 21%|â–ˆâ–ˆ        | 193/910 [03:25<08:34,  1.39it/s] 21%|â–ˆâ–ˆâ–       | 194/910 [03:25<07:05,  1.68it/s] 21%|â–ˆâ–ˆâ–       | 195/910 [03:25<06:02,  1.97it/s] 22%|â–ˆâ–ˆâ–       | 196/910 [03:26<05:19,  2.24it/s] 22%|â–ˆâ–ˆâ–       | 197/910 [03:26<04:48,  2.47it/s] 22%|â–ˆâ–ˆâ–       | 198/910 [03:26<04:28,  2.65it/s] 22%|â–ˆâ–ˆâ–       | 199/910 [03:27<04:13,  2.81it/s] 22%|â–ˆâ–ˆâ–       | 200/910 [03:27<04:02,  2.93it/s] 22%|â–ˆâ–ˆâ–       | 201/910 [03:27<03:54,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 202/910 [03:28<03:49,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 203/910 [03:28<03:46,  3.12it/s] 22%|â–ˆâ–ˆâ–       | 204/910 [03:28<03:43,  3.16it/s] 23%|â–ˆâ–ˆâ–Ž       | 205/910 [03:28<03:40,  3.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 206/910 [03:29<03:39,  3.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 207/910 [03:29<03:37,  3.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 208/910 [03:29<03:37,  3.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 209/910 [03:30<03:36,  3.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 210/910 [03:30<03:35,  3.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 211/910 [03:30<03:35,  3.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 212/910 [03:31<03:34,  3.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 213/910 [03:31<03:34,  3.25it/s] 24%|â–ˆâ–ˆâ–Ž       | 214/910 [03:31<03:33,  3.25it/s] 24%|â–ˆâ–ˆâ–Ž       | 215/910 [03:32<03:33,  3.25it/s] 24%|â–ˆâ–ˆâ–Ž       | 216/910 [03:32<03:33,  3.26it/s] 24%|â–ˆâ–ˆâ–       | 217/910 [03:32<03:33,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 218/910 [03:32<03:33,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 219/910 [03:33<03:32,  3.24it/s] 24%|â–ˆâ–ˆâ–       | 220/910 [03:33<03:32,  3.25it/s] 24%|â–ˆâ–ˆâ–       | 221/910 [03:33<03:34,  3.21it/s] 24%|â–ˆâ–ˆâ–       | 222/910 [03:34<03:33,  3.23it/s] 25%|â–ˆâ–ˆâ–       | 223/910 [03:34<03:32,  3.23it/s] 25%|â–ˆâ–ˆâ–       | 224/910 [03:34<03:31,  3.24it/s] 25%|â–ˆâ–ˆâ–       | 225/910 [03:35<03:31,  3.25it/s] 25%|â–ˆâ–ˆâ–       | 226/910 [03:35<03:30,  3.25it/s] 25%|â–ˆâ–ˆâ–       | 227/910 [03:35<03:30,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 228/910 [03:36<03:30,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 229/910 [03:36<03:29,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 230/910 [03:36<03:29,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 231/910 [03:36<03:28,  3.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 232/910 [03:37<03:28,  3.25it/s] 26%|â–ˆâ–ˆâ–Œ       | 233/910 [03:37<03:29,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 234/910 [03:37<03:28,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 235/910 [03:38<03:28,  3.24it/s] 26%|â–ˆâ–ˆâ–Œ       | 236/910 [03:38<03:29,  3.22it/s] 26%|â–ˆâ–ˆâ–Œ       | 237/910 [03:38<03:28,  3.22it/s] 26%|â–ˆâ–ˆâ–Œ       | 238/910 [03:39<03:28,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 239/910 [03:39<03:27,  3.23it/s] 26%|â–ˆâ–ˆâ–‹       | 240/910 [03:39<03:27,  3.24it/s] 26%|â–ˆâ–ˆâ–‹       | 241/910 [03:40<03:26,  3.24it/s] 27%|â–ˆâ–ˆâ–‹       | 242/910 [03:40<03:26,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 243/910 [03:40<03:26,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 244/910 [03:40<03:27,  3.21it/s] 27%|â–ˆâ–ˆâ–‹       | 245/910 [03:41<03:26,  3.21it/s] 27%|â–ˆâ–ˆâ–‹       | 246/910 [03:41<03:26,  3.22it/s] 27%|â–ˆâ–ˆâ–‹       | 247/910 [03:41<03:25,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 248/910 [03:42<03:24,  3.23it/s] 27%|â–ˆâ–ˆâ–‹       | 249/910 [03:42<03:26,  3.20it/s] 27%|â–ˆâ–ˆâ–‹       | 250/910 [03:42<03:25,  3.21it/s] 28%|â–ˆâ–ˆâ–Š       | 251/910 [03:43<03:24,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 252/910 [03:43<03:24,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 253/910 [03:43<03:24,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 254/910 [03:44<03:24,  3.21it/s] 28%|â–ˆâ–ˆâ–Š       | 255/910 [03:44<03:23,  3.22it/s] 28%|â–ˆâ–ˆâ–Š       | 256/910 [03:44<03:22,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 257/910 [03:45<03:22,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 258/910 [03:45<03:21,  3.23it/s] 28%|â–ˆâ–ˆâ–Š       | 259/910 [03:45<03:21,  3.23it/s] 29%|â–ˆâ–ˆâ–Š       | 260/910 [03:45<03:21,  3.23it/s] 29%|â–ˆâ–ˆâ–Š       | 261/910 [03:46<03:21,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 262/910 [03:46<03:22,  3.20it/s] 29%|â–ˆâ–ˆâ–‰       | 263/910 [03:46<03:21,  3.21it/s] 29%|â–ˆâ–ˆâ–‰       | 264/910 [03:47<03:20,  3.22it/s] 29%|â–ˆâ–ˆâ–‰       | 265/910 [03:47<03:19,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 266/910 [03:47<03:19,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 267/910 [03:48<03:19,  3.23it/s] 29%|â–ˆâ–ˆâ–‰       | 268/910 [03:48<03:18,  3.23it/s] 30%|â–ˆâ–ˆâ–‰       | 269/910 [03:48<03:18,  3.23it/s] 30%|â–ˆâ–ˆâ–‰       | 270/910 [03:49<03:18,  3.23it/s] 30%|â–ˆâ–ˆâ–‰       | 271/910 [03:49<03:17,  3.23it/s] 30%|â–ˆâ–ˆâ–‰       | 272/910 [03:49<03:17,  3.23it/s] 30%|â–ˆâ–ˆâ–ˆ       | 273/910 [03:49<03:05,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.94it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.60it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.30it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.74it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.47it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.31it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.31it/s][A 30%|â–ˆâ–ˆâ–ˆ       | 273/910 [03:51<03:05,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-273
Configuration saved in sst_model/checkpoint-273/config.json
Model weights saved in sst_model/checkpoint-273/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-91] due to args.save_total_limit
 30%|â–ˆâ–ˆâ–ˆ       | 274/910 [04:30<2:09:54, 12.26s/it] 30%|â–ˆâ–ˆâ–ˆ       | 275/910 [04:30<1:32:40,  8.76s/it] 30%|â–ˆâ–ˆâ–ˆ       | 276/910 [04:30<1:05:44,  6.22s/it] 30%|â–ˆâ–ˆâ–ˆ       | 277/910 [04:31<46:55,  4.45s/it]   31%|â–ˆâ–ˆâ–ˆ       | 278/910 [04:31<33:45,  3.21s/it] 31%|â–ˆâ–ˆâ–ˆ       | 279/910 [04:31<24:34,  2.34s/it] 31%|â–ˆâ–ˆâ–ˆ       | 280/910 [04:32<18:08,  1.73s/it] 31%|â–ˆâ–ˆâ–ˆ       | 281/910 [04:32<13:40,  1.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 282/910 [04:32<10:31,  1.01s/it] 31%|â–ˆâ–ˆâ–ˆ       | 283/910 [04:33<08:19,  1.26it/s] 31%|â–ˆâ–ˆâ–ˆ       | 284/910 [04:33<06:54,  1.51it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 285/910 [04:33<05:47,  1.80it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 286/910 [04:34<05:00,  2.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 287/910 [04:34<04:27,  2.33it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 288/910 [04:34<04:04,  2.55it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 289/910 [04:35<03:49,  2.70it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 290/910 [04:35<03:38,  2.84it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 291/910 [04:35<03:29,  2.95it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 292/910 [04:35<03:23,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 293/910 [04:36<03:19,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 294/910 [04:36<03:20,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 295/910 [04:36<03:16,  3.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 296/910 [04:37<03:14,  3.16it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 297/910 [04:37<03:12,  3.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 298/910 [04:37<03:10,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 299/910 [04:38<03:10,  3.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 300/910 [04:38<03:09,  3.23it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 301/910 [04:38<03:08,  3.23it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 302/910 [04:39<03:09,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 303/910 [04:39<03:08,  3.21it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 304/910 [04:39<03:08,  3.22it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 305/910 [04:40<03:07,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 306/910 [04:40<03:06,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 307/910 [04:40<03:06,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 308/910 [04:40<03:06,  3.23it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 309/910 [04:41<03:05,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 310/910 [04:41<03:05,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 311/910 [04:41<03:04,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 312/910 [04:42<03:04,  3.24it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 313/910 [04:42<03:03,  3.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 314/910 [04:42<03:03,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 315/910 [04:43<03:03,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 316/910 [04:43<03:03,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 317/910 [04:43<03:03,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 318/910 [04:44<03:03,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 319/910 [04:44<03:02,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 320/910 [04:44<03:02,  3.24it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 321/910 [04:44<03:02,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 322/910 [04:45<03:01,  3.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 323/910 [04:45<03:01,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 324/910 [04:45<03:01,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 325/910 [04:46<03:02,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 326/910 [04:46<03:01,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 327/910 [04:46<03:01,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 328/910 [04:47<03:00,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 329/910 [04:47<02:59,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 330/910 [04:47<02:59,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 331/910 [04:48<02:59,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 332/910 [04:48<02:58,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 333/910 [04:48<02:59,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 334/910 [04:48<02:59,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 335/910 [04:49<02:58,  3.21it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 336/910 [04:49<02:58,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 337/910 [04:49<02:57,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 338/910 [04:50<02:57,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 339/910 [04:50<02:57,  3.22it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 340/910 [04:50<02:56,  3.23it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 341/910 [04:51<02:56,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 342/910 [04:51<02:55,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 343/910 [04:51<02:55,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 344/910 [04:52<02:55,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 345/910 [04:52<02:54,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 346/910 [04:52<02:54,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 347/910 [04:53<02:54,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 348/910 [04:53<02:54,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 349/910 [04:53<02:53,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 350/910 [04:53<02:53,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 351/910 [04:54<02:55,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 352/910 [04:54<02:54,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 353/910 [04:54<02:53,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 354/910 [04:55<02:52,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 355/910 [04:55<02:52,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 356/910 [04:55<02:52,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 357/910 [04:56<02:51,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 358/910 [04:56<02:51,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 359/910 [04:56<02:52,  3.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 360/910 [04:57<02:52,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 361/910 [04:57<02:51,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 362/910 [04:57<02:50,  3.21it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 363/910 [04:58<02:50,  3.21it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 364/910 [04:58<02:39,  3.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 15.05it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:00<00:00, 12.09it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 7/13 [00:00<00:00, 11.12it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 9/13 [00:00<00:00, 10.68it/s][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 11/13 [00:01<00:00, 10.42it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.18it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 11.18it/s][A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 364/910 [04:59<02:39,  3.42it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-364
Configuration saved in sst_model/checkpoint-364/config.json
Model weights saved in sst_model/checkpoint-364/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-182] due to args.save_total_limit
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 365/910 [05:13<42:53,  4.72s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 366/910 [05:13<30:48,  3.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 367/910 [05:13<22:21,  2.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 368/910 [05:14<16:27,  1.82s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 369/910 [05:14<12:20,  1.37s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 370/910 [05:14<09:27,  1.05s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 371/910 [05:15<07:26,  1.21it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 372/910 [05:15<06:01,  1.49it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 373/910 [05:15<05:02,  1.77it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 374/910 [05:16<04:21,  2.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 375/910 [05:16<03:51,  2.31it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 376/910 [05:16<03:31,  2.52it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 377/910 [05:17<03:17,  2.70it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 378/910 [05:17<03:06,  2.85it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 379/910 [05:17<02:59,  2.95it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 380/910 [05:17<02:54,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 381/910 [05:18<02:51,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 382/910 [05:18<02:48,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 383/910 [05:18<02:47,  3.15it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 384/910 [05:19<02:45,  3.17it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 385/910 [05:19<02:44,  3.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 386/910 [05:19<02:43,  3.20it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 387/910 [05:20<02:44,  3.19it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 388/910 [05:20<02:42,  3.21it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 389/910 [05:20<02:41,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 390/910 [05:21<02:41,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 391/910 [05:21<02:40,  3.23it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 392/910 [05:21<02:40,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 393/910 [05:21<02:40,  3.23it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 394/910 [05:22<02:40,  3.22it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 395/910 [05:22<02:40,  3.22it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 396/910 [05:22<02:38,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 397/910 [05:23<02:37,  3.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 398/910 [05:23<02:37,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 399/910 [05:23<02:37,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 400/910 [05:24<02:37,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 401/910 [05:24<02:37,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 402/910 [05:24<02:36,  3.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 403/910 [05:25<02:37,  3.22it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 404/910 [05:25<02:36,  3.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 405/910 [05:25<02:36,  3.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 406/910 [05:25<02:35,  3.23it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 407/910 [05:26<02:37,  3.19it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 408/910 [05:26<02:36,  3.20it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 409/910 [05:26<02:35,  3.21it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 410/910 [05:27<02:35,  3.22it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 411/910 [05:27<02:34,  3.22it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 412/910 [05:27<02:34,  3.22it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 413/910 [05:28<02:34,  3.22it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 414/910 [05:28<02:34,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 415/910 [05:28<02:33,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 416/910 [05:29<02:33,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 417/910 [05:29<02:32,  3.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 418/910 [05:29<02:32,  3.22it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 419/910 [05:30<02:31,  3.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 420/910 [05:30<02:31,  3.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 421/910 [05:30<02:31,  3.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 422/910 [05:30<02:31,  3.23it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 423/910 [05:31<02:30,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 424/910 [05:31<02:30,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 425/910 [05:31<02:30,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 426/910 [05:32<02:30,  3.22it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 427/910 [05:32<02:29,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 428/910 [05:32<02:29,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 429/910 [05:33<02:28,  3.23it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 430/910 [05:33<02:28,  3.24it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 431/910 [05:33<02:28,  3.24it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 432/910 [05:34<02:27,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 433/910 [05:34<02:29,  3.19it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 434/910 [05:34<02:28,  3.20it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 435/910 [05:35<02:28,  3.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 436/910 [05:35<02:27,  3.21it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 437/910 [05:35<02:26,  3.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 438/910 [05:35<02:26,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 439/910 [05:36<02:26,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 440/910 [05:36<02:25,  3.22it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 441/910 [05:36<02:26,  3.20it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 442/910 [05:37<02:26,  3.20it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 443/910 [05:37<02:25,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 444/910 [05:37<02:25,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 445/910 [05:38<02:24,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 446/910 [05:38<02:23,  3.22it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 447/910 [05:38<02:24,  3.19it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 448/910 [05:39<02:23,  3.21it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 449/910 [05:39<02:22,  3.23it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 450/910 [05:39<02:22,  3.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 451/910 [05:39<02:21,  3.24it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 452/910 [05:40<02:21,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 453/910 [05:40<02:21,  3.23it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 454/910 [05:40<02:23,  3.19it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 455/910 [05:41<02:14,  3.39it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.89it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.44it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.15it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.55it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.33it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.17it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.17it/s][A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 455/910 [05:42<02:14,  3.39it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-455
Configuration saved in sst_model/checkpoint-455/config.json
Model weights saved in sst_model/checkpoint-455/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-273] due to args.save_total_limit
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 456/910 [06:08<1:04:34,  8.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 457/910 [06:09<45:50,  6.07s/it]   50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 458/910 [06:09<32:43,  4.34s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 459/910 [06:09<23:35,  3.14s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 460/910 [06:10<17:10,  2.29s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 461/910 [06:10<12:41,  1.70s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 462/910 [06:10<09:32,  1.28s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 463/910 [06:11<07:21,  1.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 464/910 [06:11<05:48,  1.28it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 465/910 [06:11<04:44,  1.56it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 466/910 [06:12<04:00,  1.85it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 467/910 [06:12<03:28,  2.12it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 468/910 [06:12<03:06,  2.38it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 469/910 [06:12<02:50,  2.59it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 470/910 [06:13<02:39,  2.76it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 471/910 [06:13<02:32,  2.88it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 472/910 [06:13<02:26,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473/910 [06:14<02:22,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/910 [06:14<02:19,  3.13it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 475/910 [06:15<03:29,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 476/910 [06:15<03:06,  2.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 477/910 [06:15<02:49,  2.55it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 478/910 [06:16<02:39,  2.70it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 479/910 [06:16<02:31,  2.85it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 480/910 [06:16<02:24,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 481/910 [06:17<02:20,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 482/910 [06:17<02:21,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 483/910 [06:17<02:19,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 484/910 [06:18<02:16,  3.13it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 485/910 [06:18<02:14,  3.16it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 486/910 [06:18<02:12,  3.21it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 487/910 [06:19<02:12,  3.18it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 488/910 [06:19<02:12,  3.19it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 489/910 [06:19<02:11,  3.20it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 490/910 [06:20<02:11,  3.20it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 491/910 [06:20<02:10,  3.21it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 492/910 [06:20<02:10,  3.21it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 493/910 [06:20<02:09,  3.22it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 494/910 [06:21<02:08,  3.24it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 495/910 [06:21<02:08,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 496/910 [06:21<02:07,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 497/910 [06:22<02:07,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 498/910 [06:22<02:07,  3.23it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 499/910 [06:22<02:07,  3.23it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 500/910 [06:23<02:07,  3.22it/s]                                                  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 500/910 [06:23<02:07,  3.22it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 501/910 [06:23<02:06,  3.23it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 502/910 [06:23<02:05,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 503/910 [06:24<02:05,  3.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 504/910 [06:24<02:04,  3.25it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 505/910 [06:24<02:04,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 506/910 [06:24<02:03,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 507/910 [06:25<02:03,  3.26it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 508/910 [06:25<02:03,  3.25it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 509/910 [06:25<02:03,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 510/910 [06:26<02:04,  3.21it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 511/910 [06:26<02:04,  3.21it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 512/910 [06:26<02:03,  3.22it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 513/910 [06:27<02:02,  3.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 514/910 [06:27<02:02,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 515/910 [06:27<02:01,  3.24it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 516/910 [06:28<02:01,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 517/910 [06:28<02:01,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 518/910 [06:28<02:02,  3.19it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 519/910 [06:28<02:02,  3.20it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 520/910 [06:29<02:01,  3.22it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 521/910 [06:29<02:00,  3.23it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 522/910 [06:29<02:00,  3.22it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 523/910 [06:30<02:02,  3.16it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 524/910 [06:30<02:01,  3.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 525/910 [06:30<02:00,  3.20it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 526/910 [06:31<01:59,  3.20it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 527/910 [06:31<01:59,  3.21it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 528/910 [06:31<01:58,  3.22it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 529/910 [06:32<01:57,  3.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 530/910 [06:32<01:59,  3.19it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 531/910 [06:32<01:58,  3.20it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 532/910 [06:33<01:57,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 533/910 [06:33<01:57,  3.21it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 534/910 [06:33<01:56,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 535/910 [06:33<01:56,  3.22it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 536/910 [06:34<01:55,  3.23it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 537/910 [06:34<01:55,  3.24it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 538/910 [06:34<01:54,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 539/910 [06:35<01:54,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 540/910 [06:35<01:53,  3.25it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 541/910 [06:35<01:53,  3.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 542/910 [06:36<01:53,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 543/910 [06:36<01:53,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 544/910 [06:36<01:53,  3.24it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 545/910 [06:37<01:53,  3.23it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 546/910 [06:37<01:46,  3.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.85it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.54it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.21it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.67it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.39it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.23it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.23it/s][A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 546/910 [06:38<01:46,  3.42it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-546
Configuration saved in sst_model/checkpoint-546/config.json
Model weights saved in sst_model/checkpoint-546/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-455] due to args.save_total_limit
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 547/910 [06:52<28:30,  4.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 548/910 [06:52<20:28,  3.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 549/910 [06:52<14:50,  2.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 550/910 [06:53<10:55,  1.82s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 551/910 [06:53<08:11,  1.37s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 552/910 [06:53<06:15,  1.05s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 553/910 [06:54<04:55,  1.21it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 554/910 [06:54<03:59,  1.49it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 555/910 [06:54<03:19,  1.78it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 556/910 [06:55<02:51,  2.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 557/910 [06:55<02:32,  2.31it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 558/910 [06:55<02:19,  2.52it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 559/910 [06:56<02:10,  2.70it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 560/910 [06:56<02:02,  2.85it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 561/910 [06:56<01:57,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 562/910 [06:56<01:54,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 563/910 [06:57<01:52,  3.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 564/910 [06:57<01:50,  3.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 565/910 [06:57<01:48,  3.17it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 566/910 [06:58<01:48,  3.18it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 567/910 [06:58<01:47,  3.21it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 568/910 [06:58<01:45,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 569/910 [06:59<01:45,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 570/910 [06:59<01:45,  3.24it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 571/910 [06:59<01:44,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 572/910 [07:00<01:44,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 573/910 [07:00<01:44,  3.22it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 574/910 [07:00<01:43,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 575/910 [07:00<01:43,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 576/910 [07:01<01:43,  3.23it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 577/910 [07:01<01:42,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 578/910 [07:01<01:42,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 579/910 [07:02<01:42,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 580/910 [07:02<01:41,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 581/910 [07:02<01:41,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 582/910 [07:03<01:41,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 583/910 [07:03<01:41,  3.23it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 584/910 [07:03<01:40,  3.24it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 585/910 [07:04<01:40,  3.25it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 586/910 [07:04<01:40,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 587/910 [07:04<01:39,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 588/910 [07:05<01:39,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 589/910 [07:05<01:39,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 590/910 [07:05<01:38,  3.25it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 591/910 [07:05<01:38,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 592/910 [07:06<01:38,  3.24it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 593/910 [07:06<01:38,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 594/910 [07:06<01:38,  3.22it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 595/910 [07:07<01:37,  3.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 596/910 [07:07<01:38,  3.20it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 597/910 [07:07<01:37,  3.21it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 598/910 [07:08<01:38,  3.18it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 599/910 [07:08<01:37,  3.17it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 600/910 [07:08<01:38,  3.16it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 601/910 [07:09<01:37,  3.17it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 602/910 [07:09<01:36,  3.18it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 603/910 [07:09<01:36,  3.18it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 604/910 [07:10<01:36,  3.19it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 605/910 [07:10<01:35,  3.21it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 606/910 [07:10<01:34,  3.21it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 607/910 [07:10<01:34,  3.21it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 608/910 [07:11<01:34,  3.21it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 609/910 [07:11<01:33,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 610/910 [07:11<01:32,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 611/910 [07:12<01:32,  3.22it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 612/910 [07:12<01:32,  3.22it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 613/910 [07:12<01:31,  3.23it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 614/910 [07:13<01:31,  3.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 615/910 [07:13<01:31,  3.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 616/910 [07:13<01:31,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 617/910 [07:14<01:30,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 618/910 [07:14<01:30,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 619/910 [07:14<01:30,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 620/910 [07:14<01:29,  3.23it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 621/910 [07:15<01:29,  3.22it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 622/910 [07:15<01:29,  3.24it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 623/910 [07:15<01:28,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 624/910 [07:16<01:28,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 625/910 [07:16<01:28,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 626/910 [07:16<01:27,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 627/910 [07:17<01:27,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 628/910 [07:17<01:27,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 629/910 [07:17<01:27,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 630/910 [07:18<01:26,  3.23it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 631/910 [07:18<01:26,  3.22it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 632/910 [07:18<01:26,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 633/910 [07:18<01:26,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 634/910 [07:19<01:25,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 635/910 [07:19<01:25,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 636/910 [07:19<01:24,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 637/910 [07:20<01:19,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.80it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.49it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.17it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.64it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.21it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s][A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 637/910 [07:21<01:19,  3.44it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-637
Configuration saved in sst_model/checkpoint-637/config.json
Model weights saved in sst_model/checkpoint-637/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-546] due to args.save_total_limit
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 638/910 [07:35<21:25,  4.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 639/910 [07:35<15:21,  3.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 640/910 [07:35<11:07,  2.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 641/910 [07:36<08:10,  1.82s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 642/910 [07:36<06:06,  1.37s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 643/910 [07:36<04:40,  1.05s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 644/910 [07:37<03:40,  1.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 645/910 [07:37<02:57,  1.49it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 646/910 [07:37<02:28,  1.78it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 647/910 [07:38<02:07,  2.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 648/910 [07:38<01:53,  2.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 649/910 [07:38<01:43,  2.53it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 650/910 [07:38<01:36,  2.71it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 651/910 [07:39<01:30,  2.86it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 652/910 [07:39<01:26,  2.97it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 653/910 [07:39<01:24,  3.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 654/910 [07:40<01:22,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 655/910 [07:40<01:21,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 656/910 [07:40<01:19,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 657/910 [07:41<01:21,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 658/910 [07:41<01:19,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 659/910 [07:41<01:18,  3.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 660/910 [07:42<01:18,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 661/910 [07:42<01:16,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 662/910 [07:42<01:16,  3.23it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 663/910 [07:42<01:16,  3.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 664/910 [07:43<01:16,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 665/910 [07:43<01:16,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 666/910 [07:43<01:15,  3.22it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 667/910 [07:44<01:15,  3.23it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 668/910 [07:44<01:15,  3.20it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 669/910 [07:44<01:15,  3.21it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 670/910 [07:45<01:14,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 671/910 [07:45<01:14,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 672/910 [07:45<01:13,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 673/910 [07:46<01:13,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 674/910 [07:46<01:13,  3.23it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 675/910 [07:46<01:12,  3.24it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 676/910 [07:46<01:12,  3.25it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 677/910 [07:47<01:11,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 678/910 [07:47<01:11,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 679/910 [07:47<01:10,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 680/910 [07:48<01:10,  3.24it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 681/910 [07:48<01:11,  3.20it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 682/910 [07:48<01:10,  3.22it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 683/910 [07:49<01:10,  3.23it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 684/910 [07:49<01:09,  3.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 685/910 [07:49<01:09,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 686/910 [07:50<01:09,  3.25it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 687/910 [07:50<01:08,  3.25it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 688/910 [07:50<01:08,  3.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 689/910 [07:51<01:08,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 690/910 [07:51<01:08,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 691/910 [07:51<01:08,  3.21it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 692/910 [07:51<01:07,  3.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 693/910 [07:52<01:07,  3.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 694/910 [07:52<01:06,  3.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 695/910 [07:52<01:06,  3.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 696/910 [07:53<01:06,  3.21it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 697/910 [07:53<01:06,  3.22it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 698/910 [07:53<01:05,  3.21it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 699/910 [07:54<01:05,  3.22it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 700/910 [07:54<01:04,  3.23it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 701/910 [07:54<01:04,  3.24it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 702/910 [07:55<01:04,  3.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 703/910 [07:55<01:04,  3.21it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 704/910 [07:55<01:03,  3.22it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 705/910 [07:55<01:03,  3.23it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 706/910 [07:56<01:03,  3.24it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 707/910 [07:56<01:02,  3.24it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 708/910 [07:56<01:02,  3.22it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 709/910 [07:57<01:02,  3.22it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 710/910 [07:57<01:02,  3.21it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 711/910 [07:57<01:01,  3.23it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 712/910 [07:58<01:01,  3.22it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 713/910 [07:58<01:01,  3.22it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 714/910 [07:58<01:00,  3.22it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 715/910 [07:59<01:00,  3.22it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 716/910 [07:59<01:00,  3.23it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 717/910 [07:59<01:00,  3.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 718/910 [08:00<01:00,  3.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 719/910 [08:00<00:59,  3.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 720/910 [08:00<00:59,  3.20it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 721/910 [08:00<00:59,  3.20it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 722/910 [08:01<00:58,  3.19it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 723/910 [08:01<00:58,  3.20it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 724/910 [08:01<00:58,  3.21it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 725/910 [08:02<00:57,  3.21it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 726/910 [08:02<00:57,  3.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 727/910 [08:02<00:57,  3.19it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 728/910 [08:03<00:53,  3.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.77it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.49it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.20it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.38it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.22it/s][A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 728/910 [08:04<00:53,  3.42it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-728
Configuration saved in sst_model/checkpoint-728/config.json
Model weights saved in sst_model/checkpoint-728/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-637] due to args.save_total_limit
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 729/910 [08:20<16:42,  5.54s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 730/910 [08:21<11:54,  3.97s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 731/910 [08:21<08:33,  2.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 732/910 [08:21<06:13,  2.10s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 733/910 [08:22<04:36,  1.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 734/910 [08:22<03:29,  1.19s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 735/910 [08:22<02:42,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 736/910 [08:23<02:08,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 737/910 [08:23<01:45,  1.64it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 738/910 [08:23<01:29,  1.92it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 739/910 [08:23<01:18,  2.19it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 740/910 [08:24<01:09,  2.43it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 741/910 [08:24<01:04,  2.63it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 742/910 [08:24<01:00,  2.79it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 743/910 [08:25<00:57,  2.91it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 744/910 [08:25<00:55,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 745/910 [08:25<00:53,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 746/910 [08:26<00:52,  3.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 747/910 [08:26<00:51,  3.14it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 748/910 [08:26<00:51,  3.17it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 749/910 [08:27<00:50,  3.19it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 750/910 [08:27<00:49,  3.20it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 751/910 [08:27<00:49,  3.22it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 752/910 [08:27<00:48,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 753/910 [08:28<00:48,  3.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 754/910 [08:28<00:48,  3.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 755/910 [08:28<00:47,  3.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 756/910 [08:29<00:47,  3.24it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 757/910 [08:29<00:46,  3.26it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 758/910 [08:29<00:46,  3.25it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 759/910 [08:30<00:46,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 760/910 [08:30<00:46,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 761/910 [08:30<00:46,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 762/910 [08:31<00:45,  3.25it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 763/910 [08:31<00:45,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 764/910 [08:31<00:45,  3.22it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 765/910 [08:31<00:44,  3.22it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 766/910 [08:32<00:44,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 767/910 [08:32<00:44,  3.24it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 768/910 [08:32<00:43,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 769/910 [08:33<00:43,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 770/910 [08:33<00:43,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 771/910 [08:33<00:43,  3.23it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 772/910 [08:34<00:42,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 773/910 [08:34<00:42,  3.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 774/910 [08:34<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 775/910 [08:35<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 776/910 [08:35<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 777/910 [08:35<00:41,  3.24it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 778/910 [08:35<00:40,  3.23it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 779/910 [08:36<00:40,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 780/910 [08:36<00:40,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 781/910 [08:36<00:39,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 782/910 [08:37<00:39,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 783/910 [08:37<00:39,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 784/910 [08:37<00:38,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 785/910 [08:38<00:38,  3.23it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 786/910 [08:38<00:38,  3.24it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 787/910 [08:38<00:37,  3.25it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 788/910 [08:39<00:37,  3.24it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 789/910 [08:39<00:37,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 790/910 [08:39<00:37,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 791/910 [08:39<00:36,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 792/910 [08:40<00:36,  3.22it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 793/910 [08:40<00:36,  3.22it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 794/910 [08:40<00:35,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 795/910 [08:41<00:35,  3.23it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 796/910 [08:41<00:35,  3.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 797/910 [08:41<00:35,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 798/910 [08:42<00:34,  3.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 799/910 [08:42<00:34,  3.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 800/910 [08:42<00:34,  3.17it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 801/910 [08:43<00:34,  3.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 802/910 [08:43<00:33,  3.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 803/910 [08:43<00:33,  3.21it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 804/910 [08:44<00:32,  3.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 805/910 [08:44<00:32,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 806/910 [08:44<00:32,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 807/910 [08:44<00:31,  3.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 808/910 [08:45<00:31,  3.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 809/910 [08:45<00:31,  3.20it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 810/910 [08:45<00:31,  3.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 811/910 [08:46<00:30,  3.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 812/910 [08:46<00:30,  3.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 813/910 [08:46<00:30,  3.22it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 814/910 [08:47<00:29,  3.21it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 815/910 [08:47<00:29,  3.22it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 816/910 [08:47<00:29,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 817/910 [08:48<00:28,  3.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 818/910 [08:48<00:28,  3.21it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 819/910 [08:48<00:26,  3.43it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.84it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.47it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.17it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.64it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.22it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.22it/s][A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 819/910 [08:49<00:26,  3.43it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-819
Configuration saved in sst_model/checkpoint-819/config.json
Model weights saved in sst_model/checkpoint-819/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-728] due to args.save_total_limit
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 820/910 [09:05<07:55,  5.29s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 821/910 [09:05<05:37,  3.79s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 822/910 [09:06<04:01,  2.75s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 823/910 [09:06<02:55,  2.02s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 824/910 [09:06<02:09,  1.50s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 825/910 [09:07<01:37,  1.14s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 826/910 [09:07<01:15,  1.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 827/910 [09:07<00:59,  1.39it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 828/910 [09:08<00:48,  1.68it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 829/910 [09:08<00:41,  1.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 830/910 [09:08<00:36,  2.22it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 831/910 [09:08<00:32,  2.45it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 832/910 [09:09<00:29,  2.64it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 833/910 [09:09<00:27,  2.80it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 834/910 [09:09<00:26,  2.92it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 835/910 [09:10<00:25,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 836/910 [09:10<00:24,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 837/910 [09:10<00:23,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 838/910 [09:11<00:22,  3.16it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 839/910 [09:11<00:22,  3.19it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 840/910 [09:11<00:21,  3.19it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 841/910 [09:12<00:21,  3.21it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 842/910 [09:12<00:21,  3.21it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 843/910 [09:12<00:20,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 844/910 [09:12<00:20,  3.22it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 845/910 [09:13<00:20,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 846/910 [09:13<00:19,  3.24it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 847/910 [09:13<00:19,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 848/910 [09:14<00:19,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 849/910 [09:14<00:18,  3.23it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 850/910 [09:14<00:18,  3.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 851/910 [09:15<00:18,  3.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 852/910 [09:15<00:17,  3.23it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 853/910 [09:15<00:17,  3.21it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 854/910 [09:16<00:17,  3.20it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 855/910 [09:16<00:17,  3.21it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 856/910 [09:16<00:16,  3.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 857/910 [09:17<00:16,  3.23it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 858/910 [09:17<00:16,  3.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 859/910 [09:17<00:15,  3.22it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 860/910 [09:17<00:15,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 861/910 [09:18<00:15,  3.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 862/910 [09:18<00:14,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 863/910 [09:18<00:14,  3.22it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 864/910 [09:19<00:14,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 865/910 [09:19<00:13,  3.24it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 866/910 [09:19<00:13,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 867/910 [09:20<00:13,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 868/910 [09:20<00:13,  3.23it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 869/910 [09:20<00:12,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 870/910 [09:21<00:12,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 871/910 [09:21<00:12,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 872/910 [09:21<00:11,  3.23it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 873/910 [09:21<00:11,  3.22it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 874/910 [09:22<00:11,  3.23it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 875/910 [09:22<00:10,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 876/910 [09:22<00:10,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 877/910 [09:23<00:10,  3.24it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 878/910 [09:23<00:09,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 879/910 [09:23<00:09,  3.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 880/910 [09:24<00:09,  3.24it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 881/910 [09:24<00:08,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 882/910 [09:24<00:08,  3.22it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 883/910 [09:25<00:08,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 884/910 [09:25<00:08,  3.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 885/910 [09:25<00:07,  3.22it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 886/910 [09:26<00:07,  3.21it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 887/910 [09:26<00:07,  3.21it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 888/910 [09:26<00:06,  3.21it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 889/910 [09:26<00:06,  3.22it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 890/910 [09:27<00:06,  3.22it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 891/910 [09:27<00:05,  3.23it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 892/910 [09:27<00:05,  3.22it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 893/910 [09:28<00:05,  3.22it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 894/910 [09:28<00:04,  3.20it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 895/910 [09:28<00:04,  3.19it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 896/910 [09:29<00:04,  3.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 897/910 [09:29<00:04,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 898/910 [09:29<00:03,  3.17it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 899/910 [09:30<00:03,  3.19it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 900/910 [09:30<00:03,  3.20it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 901/910 [09:30<00:02,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 902/910 [09:30<00:02,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 903/910 [09:31<00:02,  3.21it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 904/910 [09:31<00:01,  3.22it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 905/910 [09:31<00:01,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 906/910 [09:32<00:01,  3.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 907/910 [09:32<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 908/910 [09:32<00:00,  3.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 909/910 [09:33<00:00,  3.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [09:33<00:00,  3.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.
***** Running Evaluation *****
  Num examples = 100
  Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|â–ˆâ–Œ        | 2/13 [00:00<00:00, 19.79it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 4/13 [00:00<00:00, 12.49it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 11.18it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 10.64it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 10.37it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:01<00:00, 10.21it/s][A
                                               [A                                                 
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:01<00:00, 10.21it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [09:34<00:00,  3.42it/s]
                                               [ASaving model checkpoint to sst_model/checkpoint-910
Configuration saved in sst_model/checkpoint-910/config.json
Model weights saved in sst_model/checkpoint-910/pytorch_model.bin
Deleting older checkpoint [sst_model/checkpoint-819] due to args.save_total_limit


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from sst_model/checkpoint-364 (score: 0.78).
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [10:45<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 910/910 [10:45<00:00,  1.41it/s]
Configuration saved in /home/yandex/AMNLP2021/shlomotannor/amnlp/outputs/t_b_m_5_e_10_n_100_s_True_i_5.model/config.json
Model weights saved in /home/yandex/AMNLP2021/shlomotannor/amnlp/outputs/t_b_m_5_e_10_n_100_s_True_i_5.model/pytorch_model.bin
